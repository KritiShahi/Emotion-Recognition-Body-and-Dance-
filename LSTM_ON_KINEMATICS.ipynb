{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYR0hENfSgkF"
      },
      "source": [
        "Connecting to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3-8l15kwacn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec4d7bb-c27a-476c-d584-4690d52ed8a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9rStaa5TRkA"
      },
      "source": [
        "# SECTION 1: Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lTU_h6exLS9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2 : Dataset"
      ],
      "metadata": {
        "id": "6ra1cSmrTNju"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ3wdRfuSlXI"
      },
      "source": [
        "## Preparing the dataset (Kinematic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keCvpUfwwccX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3cd83dc-c5cf-457e-b2dc-c0573e9248a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data: (932, 3, 100, 59)\n",
            "Loaded labels: (932,)\n",
            "Meta keys: dict_keys(['joint_names', 'edge_list', 'label2idx', 'target_frames', 'center_root', 'normalize'])\n",
            "N=932, C=3, T=100, V=59\n",
            "LSTM-ready X shape: (932, 100, 177)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# -----------------------------\n",
        "# 1. LOAD DATA\n",
        "# -----------------------------\n",
        "DATA_DIR = \"/content/drive/MyDrive/kinematic_dataset_final/stgcn_input/\"\n",
        "\n",
        "data_arr = np.load(DATA_DIR + \"data.npy\")       # (N, 9, T, V)\n",
        "labels_arr = np.load(DATA_DIR + \"labels.npy\")   # (N,)\n",
        "\n",
        "with open(DATA_DIR + \"meta.json\", 'r') as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "print(\"Loaded data:\", data_arr.shape)\n",
        "print(\"Loaded labels:\", labels_arr.shape)\n",
        "print(\"Meta keys:\", meta.keys())\n",
        "\n",
        "# -----------------------------\n",
        "# 2. EXTRACT DIMENSIONS\n",
        "# -----------------------------\n",
        "N, C, T, V = data_arr.shape\n",
        "print(f\"N={N}, C={C}, T={T}, V={V}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3. PREPARE LSTM INPUT FORMAT\n",
        "# -----------------------------\n",
        "# Convert (N, C, T, V) â†’ (N, T, C*V)\n",
        "X = data_arr.transpose(0, 2, 1, 3).reshape(N, T, C * V)\n",
        "\n",
        "print(\"LSTM-ready X shape:\", X.shape)  # Expected: (N, T, 9*V)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo0bFtnLS3eq"
      },
      "source": [
        "## Reshaping the dataset for LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX0NtEiFwgRg"
      },
      "outputs": [],
      "source": [
        "X = data_arr.transpose(0, 2, 1, 3).reshape(N, T, 3*V)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Working with motion Features"
      ],
      "metadata": {
        "id": "X9jq-6VeTbVd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3T2Q_C8S8fq"
      },
      "source": [
        "## Adding motion features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7WXlWMPw4qd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def add_motion_features_batch(X):\n",
        "    \"\"\"\n",
        "    X shape: (N, 3, T, V)\n",
        "    Returns: (N, 9, T, V)\n",
        "    \"\"\"\n",
        "    N, C, T, V = X.shape\n",
        "    assert C == 3, \"Expected 3 channels (x,y,z) before motion features\"\n",
        "\n",
        "    X_new = np.zeros((N, 9, T, V), dtype=np.float32)\n",
        "\n",
        "    for i in range(N):\n",
        "        pos = X[i]                       # (3, T, V)\n",
        "\n",
        "        # Velocity\n",
        "        vel = np.zeros_like(pos)\n",
        "        vel[:, 1:] = pos[:, 1:] - pos[:, :-1]\n",
        "\n",
        "        # Acceleration\n",
        "        acc = np.zeros_like(pos)\n",
        "        acc[:, 1:] = vel[:, 1:] - vel[:, :-1]\n",
        "\n",
        "        # Concatenate: [pos, vel, acc]\n",
        "        X_new[i, 0:3] = pos\n",
        "        X_new[i, 3:6] = vel\n",
        "        X_new[i, 6:9] = acc\n",
        "\n",
        "    return X_new\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMQTtgSuS-5e"
      },
      "source": [
        "## reshaping the motion features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cs7anDZzxDP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c04207-282e-4ab7-e793-e3fe1fe322e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape with motion features: (932, 9, 100, 59)\n"
          ]
        }
      ],
      "source": [
        "X_mf = add_motion_features_batch(data_arr)\n",
        "\n",
        "print(\"New shape with motion features:\", X_mf.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaEDpFEITIUb"
      },
      "source": [
        "## Convert for LSTM input (now using 9 channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "io-sy5B6xExx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11cd8ddf-1d18-482c-cab5-c76551786417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final LSTM input shape: (932, 100, 531)\n"
          ]
        }
      ],
      "source": [
        "N, C, T, V = X_mf.shape   # C should now be 9\n",
        "\n",
        "X_lstm = X_mf.transpose(0, 2, 1, 3).reshape(N, T, C * V)\n",
        "\n",
        "print(\"Final LSTM input shape:\", X_lstm.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7zV83aNTO5G"
      },
      "source": [
        "## Saving the motion-feature version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Bm-E_5xHfr"
      },
      "outputs": [],
      "source": [
        "np.save(DATA_DIR + \"data_with_motion.npy\", X_mf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oYeaG-dTYl8"
      },
      "source": [
        "# SECTION 4: Augmentations for LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvPNOLE3xZv0"
      },
      "outputs": [],
      "source": [
        "def augment_lstm_sample(x, V, p=0.5):\n",
        "    # x: (T, 9*V)\n",
        "    T, F = x.shape\n",
        "    sample = x.reshape(T, V, 9)\n",
        "\n",
        "    # Gaussian noise\n",
        "    if np.random.rand() < p:\n",
        "        sample += np.random.normal(0, 0.01, sample.shape)\n",
        "\n",
        "    return sample.reshape(T, F)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MubSf1JuTjyN"
      },
      "source": [
        "# SECTION 5: Mixup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5cEVuskxe0N"
      },
      "outputs": [],
      "source": [
        "def mixup_data(x, y, alpha=0.2):\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(x.size(0)).to(x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[idx]\n",
        "    return mixed_x, y, y[idx], lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm9SX2VnTmpt"
      },
      "source": [
        "# SECTION 6: PyTorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjCzT3zrxgT0"
      },
      "outputs": [],
      "source": [
        "class LSTMDataset(Dataset):\n",
        "    def __init__(self, X, y, V, training=False):\n",
        "        self.X = X.astype(np.float32)\n",
        "        self.y = y.astype(np.int64)\n",
        "        self.training = training\n",
        "        self.V = V\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]\n",
        "        y = self.y[idx]\n",
        "\n",
        "        if self.training:\n",
        "            x = augment_lstm_sample(x, self.V)\n",
        "\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoKZ5mhxTprj"
      },
      "source": [
        "# SECTION 7: Attention-Based LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUOGDS9KTtcu"
      },
      "source": [
        "Channel Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8vLhYWsxhxk"
      },
      "outputs": [],
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, dim, reduction=8):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(dim, dim // reduction),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim // reduction, dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        w = self.fc(x.mean(1))  # (N,F)\n",
        "        return x * w.unsqueeze(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuqnNW3vTumJ"
      },
      "source": [
        "Temporal Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EzrZXDCxjSI"
      },
      "outputs": [],
      "source": [
        "class TemporalAttention(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = torch.softmax(self.fc(x), dim=1)\n",
        "        out = torch.sum(weights * x, dim=1)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEnJkP4TTzRR"
      },
      "source": [
        "Final LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoLDK74Yxkzq"
      },
      "outputs": [],
      "source": [
        "class MotionLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes, dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.chan_att = ChannelAttention(input_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim,\n",
        "            hidden_dim,\n",
        "            batch_first=True,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.temp_att = TemporalAttention(hidden_dim * 2)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.chan_att(x)\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.temp_att(out)\n",
        "        logits = self.fc(out)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHF_H2J7T3B6"
      },
      "source": [
        "# SECTION 8: Train/Val Split + DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Owuy7QtkxmMO"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_lstm, labels_arr, test_size=0.2, stratify=labels_arr, random_state=42\n",
        ")\n",
        "\n",
        "train_ds = LSTMDataset(X_train, y_train, V, training=True)\n",
        "val_ds = LSTMDataset(X_val, y_val, V, training=False)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crsmmR-zT55Z"
      },
      "source": [
        "# SECTION 9: Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub_RYTG6xnoI"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = MotionLSTM(\n",
        "    input_dim=9*V,\n",
        "    hidden_dim=256,\n",
        "    num_layers=2,\n",
        "    num_classes=len(np.unique(labels_arr)),\n",
        "    dropout=0.5\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iebQyZifT9CR"
      },
      "source": [
        "# SECTION 10: Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSAy09ukxo_S"
      },
      "outputs": [],
      "source": [
        "def train_epoch():\n",
        "    model.train()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    for xb, yb in train_dl:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        # Mixup\n",
        "        xb_mix, y_a, y_b, lam = mixup_data(xb, yb)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb_mix)\n",
        "        loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    return running_loss / len(train_ds)\n",
        "\n",
        "\n",
        "def eval_epoch():\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            pred = torch.argmax(logits, dim=1)\n",
        "\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    acc = (np.array(preds) == np.array(labels)).mean()\n",
        "    return acc, preds, labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExE4UdPjUAp1"
      },
      "source": [
        "# SECTION 11: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7V1jocjxspM",
        "outputId": "ecb90ae2-65bc-4570-d555-8425f93524f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80 | Loss 1.9437 | Val Acc 0.2032\n",
            "Epoch 2/80 | Loss 1.9212 | Val Acc 0.2299\n",
            "Epoch 3/80 | Loss 1.8730 | Val Acc 0.2032\n",
            "Epoch 4/80 | Loss 1.9160 | Val Acc 0.2674\n",
            "Epoch 5/80 | Loss 1.8418 | Val Acc 0.2781\n",
            "Epoch 6/80 | Loss 1.7879 | Val Acc 0.2781\n",
            "Epoch 7/80 | Loss 1.7885 | Val Acc 0.2941\n",
            "Epoch 8/80 | Loss 1.7800 | Val Acc 0.3583\n",
            "Epoch 9/80 | Loss 1.6880 | Val Acc 0.4064\n",
            "Epoch 10/80 | Loss 1.6485 | Val Acc 0.3904\n",
            "Epoch 11/80 | Loss 1.5473 | Val Acc 0.4492\n",
            "Epoch 12/80 | Loss 1.4775 | Val Acc 0.4759\n",
            "Epoch 13/80 | Loss 1.4349 | Val Acc 0.4706\n",
            "Epoch 14/80 | Loss 1.5282 | Val Acc 0.4225\n",
            "Epoch 15/80 | Loss 1.5232 | Val Acc 0.4492\n",
            "Epoch 16/80 | Loss 1.4108 | Val Acc 0.4759\n",
            "Epoch 17/80 | Loss 1.3188 | Val Acc 0.4706\n",
            "Epoch 18/80 | Loss 1.2942 | Val Acc 0.4652\n",
            "Epoch 19/80 | Loss 1.2026 | Val Acc 0.4813\n",
            "Epoch 20/80 | Loss 1.1536 | Val Acc 0.5241\n",
            "Epoch 21/80 | Loss 1.0534 | Val Acc 0.5241\n",
            "Epoch 22/80 | Loss 1.0538 | Val Acc 0.5294\n",
            "Epoch 23/80 | Loss 0.9776 | Val Acc 0.5187\n",
            "Epoch 24/80 | Loss 0.9194 | Val Acc 0.5348\n",
            "Epoch 25/80 | Loss 0.8894 | Val Acc 0.5241\n",
            "Epoch 26/80 | Loss 1.0574 | Val Acc 0.5241\n",
            "Epoch 27/80 | Loss 0.8842 | Val Acc 0.4866\n",
            "Epoch 28/80 | Loss 1.1527 | Val Acc 0.5241\n",
            "Epoch 29/80 | Loss 0.9764 | Val Acc 0.4920\n",
            "Epoch 30/80 | Loss 0.9582 | Val Acc 0.5187\n",
            "Epoch 31/80 | Loss 1.0408 | Val Acc 0.5027\n",
            "Epoch 32/80 | Loss 0.9191 | Val Acc 0.5294\n",
            "Epoch 33/80 | Loss 0.8653 | Val Acc 0.5668\n",
            "Epoch 34/80 | Loss 0.7376 | Val Acc 0.5936\n",
            "Epoch 35/80 | Loss 0.7543 | Val Acc 0.5401\n",
            "Epoch 36/80 | Loss 0.7974 | Val Acc 0.4973\n",
            "Epoch 37/80 | Loss 0.8148 | Val Acc 0.5455\n",
            "Epoch 38/80 | Loss 0.5838 | Val Acc 0.5722\n",
            "Epoch 39/80 | Loss 0.5946 | Val Acc 0.5455\n",
            "Epoch 40/80 | Loss 0.5078 | Val Acc 0.5508\n",
            "Epoch 41/80 | Loss 0.4405 | Val Acc 0.5080\n",
            "Epoch 42/80 | Loss 0.4993 | Val Acc 0.5241\n",
            "Epoch 43/80 | Loss 0.3715 | Val Acc 0.5668\n",
            "Epoch 44/80 | Loss 0.4208 | Val Acc 0.5241\n",
            "Epoch 45/80 | Loss 0.4859 | Val Acc 0.5508\n",
            "Epoch 46/80 | Loss 0.4678 | Val Acc 0.5508\n",
            "Epoch 47/80 | Loss 0.5605 | Val Acc 0.5455\n",
            "Epoch 48/80 | Loss 0.7117 | Val Acc 0.5455\n",
            "Epoch 49/80 | Loss 0.2584 | Val Acc 0.5508\n",
            "Epoch 50/80 | Loss 0.6606 | Val Acc 0.5348\n",
            "Epoch 51/80 | Loss 0.7032 | Val Acc 0.5561\n",
            "Epoch 52/80 | Loss 0.4917 | Val Acc 0.5668\n",
            "Epoch 53/80 | Loss 0.6928 | Val Acc 0.5294\n",
            "Epoch 54/80 | Loss 0.6831 | Val Acc 0.5080\n",
            "Epoch 55/80 | Loss 0.4953 | Val Acc 0.5080\n",
            "Epoch 56/80 | Loss 0.6237 | Val Acc 0.5080\n",
            "Epoch 57/80 | Loss 0.4287 | Val Acc 0.5080\n",
            "Epoch 58/80 | Loss 0.5127 | Val Acc 0.4545\n",
            "Epoch 59/80 | Loss 0.4643 | Val Acc 0.5348\n",
            "Epoch 60/80 | Loss 0.5124 | Val Acc 0.5294\n",
            "Epoch 61/80 | Loss 0.6221 | Val Acc 0.5401\n",
            "Epoch 62/80 | Loss 0.3017 | Val Acc 0.5348\n",
            "Epoch 63/80 | Loss 0.7150 | Val Acc 0.4920\n",
            "Epoch 64/80 | Loss 0.6071 | Val Acc 0.5775\n",
            "Epoch 65/80 | Loss 0.6518 | Val Acc 0.5561\n",
            "Epoch 66/80 | Loss 0.3423 | Val Acc 0.5561\n",
            "Epoch 67/80 | Loss 0.4982 | Val Acc 0.5455\n",
            "Epoch 68/80 | Loss 0.2919 | Val Acc 0.5401\n",
            "Epoch 69/80 | Loss 0.3606 | Val Acc 0.5401\n",
            "Epoch 70/80 | Loss 0.5932 | Val Acc 0.5615\n",
            "Epoch 71/80 | Loss 0.6013 | Val Acc 0.5294\n",
            "Epoch 72/80 | Loss 0.3764 | Val Acc 0.5134\n",
            "Epoch 73/80 | Loss 0.3525 | Val Acc 0.5668\n",
            "Epoch 74/80 | Loss 0.3178 | Val Acc 0.5348\n",
            "Epoch 75/80 | Loss 0.3983 | Val Acc 0.5348\n",
            "Epoch 76/80 | Loss 0.2954 | Val Acc 0.5348\n",
            "Epoch 77/80 | Loss 0.3292 | Val Acc 0.5401\n",
            "Epoch 78/80 | Loss 0.3960 | Val Acc 0.5668\n",
            "Epoch 79/80 | Loss 0.4817 | Val Acc 0.5508\n",
            "Epoch 80/80 | Loss 0.3483 | Val Acc 0.5455\n",
            "Best Val Acc: 0.5935828877005348\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 80\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    loss = train_epoch()\n",
        "    acc, preds, labels = eval_epoch()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss {loss:.4f} | Val Acc {acc:.4f}\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        torch.save(model.state_dict(), \"best_lstm.pth\")\n",
        "\n",
        "print(\"Best Val Acc:\", best_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_XbdPY2UDdN"
      },
      "source": [
        "# SECTION 12: Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyz5U9lcxuUj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "outputId": "afff8fe9-c14b-4c04-9e3a-991161b20b87"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo0AAAIjCAYAAABmuyHTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAaYZJREFUeJzt3XlYVOX7BvB7QBgQWZQdFcQNVATNBfclzaU0UXPLEnczLJXUxNw3zF1yLTdyybRvkpU7KuaeKO6SIIoLIKCA7Ajz+8OfUxPgAWJ4j8z96TrX1Zw5c87NaQaenvc9ZxQqlUoFIiIiIqLX0BMdgIiIiIjkj0UjEREREUli0UhEREREklg0EhEREZEkFo1EREREJIlFIxERERFJYtFIRERERJJYNBIRERGRJBaNRERERCSJRSMRvdadO3fQpUsXmJubQ6FQICgoqFT3f+/ePSgUCmzdurVU9/sm69ChAzp06CA6BhGRBhaNRG+AyMhIjBkzBjVr1oSRkRHMzMzQunVrrFq1ChkZGVo9tre3N65du4YFCxZg27ZtaNq0qVaPV5aGDh0KhUIBMzOzAs/jnTt3oFAooFAosHTp0mLv//Hjx5g9ezbCwsJKIS0RkVgVRAcgotf7/fff0a9fPyiVSgwZMgRubm7Izs7GqVOnMHnyZNy4cQPffvutVo6dkZGBs2fP4quvvsK4ceO0cgwnJydkZGTAwMBAK/uXUqFCBaSnp+PXX39F//79NZ7bsWMHjIyMkJmZWaJ9P378GHPmzEGNGjXQqFGjIr/u8OHDJToeEZE2sWgkkrGoqCgMHDgQTk5OOHbsGOzt7dXP+fj4ICIiAr///rvWjh8fHw8AsLCw0NoxFAoFjIyMtLZ/KUqlEq1bt8YPP/yQr2jcuXMn3nvvPfzvf/8rkyzp6emoWLEiDA0Ny+R4RETFweFpIhlbvHgxUlNTsWnTJo2C8ZXatWtj/Pjx6scvXrzAvHnzUKtWLSiVStSoUQPTpk1DVlaWxutq1KiBHj164NSpU2jevDmMjIxQs2ZNfP/99+ptZs+eDScnJwDA5MmToVAoUKNGDQAvh3Vf/fs/zZ49GwqFQmPdkSNH0KZNG1hYWKBSpUpwcXHBtGnT1M8XNqfx2LFjaNu2LUxMTGBhYYFevXrh1q1bBR4vIiICQ4cOhYWFBczNzTFs2DCkp6cXfmL/5cMPP8SBAweQlJSkXvfnn3/izp07+PDDD/Nt//TpU0yaNAkNGzZEpUqVYGZmhu7du+PKlSvqbU6cOIFmzZoBAIYNG6Ye5n71c3bo0AFubm4IDQ1Fu3btULFiRfV5+fecRm9vbxgZGeX7+bt27YrKlSvj8ePHRf5ZiYhKikUjkYz9+uuvqFmzJlq1alWk7UeOHImZM2firbfewooVK9C+fXv4+/tj4MCB+baNiIjABx98gHfeeQfLli1D5cqVMXToUNy4cQMA0KdPH6xYsQIAMGjQIGzbtg0rV64sVv4bN26gR48eyMrKwty5c7Fs2TK8//77OH369Gtfd/ToUXTt2hVPnjzB7Nmz4evrizNnzqB169a4d+9evu379++P58+fw9/fH/3798fWrVsxZ86cIufs06cPFAoFfv75Z/W6nTt3wtXVFW+99Va+7e/evYugoCD06NEDy5cvx+TJk3Ht2jW0b99eXcDVq1cPc+fOBQCMHj0a27Ztw7Zt29CuXTv1fhITE9G9e3c0atQIK1euRMeOHQvMt2rVKlhbW8Pb2xu5ubkAgA0bNuDw4cP45ptv4ODgUOSflYioxFREJEvJyckqAKpevXoVafuwsDAVANXIkSM11k+aNEkFQHXs2DH1OicnJxUA1cmTJ9Xrnjx5olIqlaovvvhCvS4qKkoFQLVkyRKNfXp7e6ucnJzyZZg1a5bqn79WVqxYoQKgio+PLzT3q2Ns2bJFva5Ro0YqGxsbVWJionrdlStXVHp6eqohQ4bkO97w4cM19tm7d2+VpaVlocf8589hYmKiUqlUqg8++EDVqVMnlUqlUuXm5qrs7OxUc+bMKfAcZGZmqnJzc/P9HEqlUjV37lz1uj///DPfz/ZK+/btVQBU69evL/C59u3ba6w7dOiQCoBq/vz5qrt376oqVaqk8vLykvwZiYhKCzuNRDKVkpICADA1NS3S9vv37wcA+Pr6aqz/4osvACDf3Mf69eujbdu26sfW1tZwcXHB3bt3S5z5317Nhfzll1+Ql5dXpNfExMQgLCwMQ4cORZUqVdTr3d3d8c4776h/zn/65JNPNB63bdsWiYmJ6nNYFB9++CFOnDiB2NhYHDt2DLGxsQUOTQMv50Hq6b389Zmbm4vExET10PulS5eKfEylUolhw4YVadsuXbpgzJgxmDt3Lvr06QMjIyNs2LChyMciIvqvWDQSyZSZmRkA4Pnz50Xa/v79+9DT00Pt2rU11tvZ2cHCwgL379/XWO/o6JhvH5UrV8azZ89KmDi/AQMGoHXr1hg5ciRsbW0xcOBA7N69+7UF5KucLi4u+Z6rV68eEhISkJaWprH+3z9L5cqVAaBYP8u7774LU1NT/Pjjj9ixYweaNWuW71y+kpeXhxUrVqBOnTpQKpWwsrKCtbU1rl69iuTk5CIfs2rVqsW66GXp0qWoUqUKwsLCEBAQABsbmyK/lojov2LRSCRTZmZmcHBwwPXr14v1un9fiFIYfX39AterVKoSH+PVfLtXjI2NcfLkSRw9ehQff/wxrl69igEDBuCdd97Jt+1/8V9+lleUSiX69OmDwMBA7N27t9AuIwAsXLgQvr6+aNeuHbZv345Dhw7hyJEjaNCgQZE7qsDL81Mcly9fxpMnTwAA165dK9ZriYj+KxaNRDLWo0cPREZG4uzZs5LbOjk5IS8vD3fu3NFYHxcXh6SkJPWV0KWhcuXKGlcav/LvbiYA6OnpoVOnTli+fDlu3ryJBQsW4NixYzh+/HiB+36VMzw8PN9zt2/fhpWVFUxMTP7bD1CIDz/8EJcvX8bz588LvHjolZ9++gkdO3bEpk2bMHDgQHTp0gWdO3fOd06KWsAXRVpaGoYNG4b69etj9OjRWLx4Mf78889S2z8RkRQWjUQyNmXKFJiYmGDkyJGIi4vL93xkZCRWrVoF4OXwKoB8VzgvX74cAPDee++VWq5atWohOTkZV69eVa+LiYnB3r17NbZ7+vRpvte+usn1v28D9Iq9vT0aNWqEwMBAjSLs+vXrOHz4sPrn1IaOHTti3rx5WL16Nezs7ArdTl9fP18Xc8+ePXj06JHGulfFbUEFdnF9+eWXiI6ORmBgIJYvX44aNWrA29u70PNIRFTaeHNvIhmrVasWdu7ciQEDBqBevXoa3whz5swZ7NmzB0OHDgUAeHh4wNvbG99++y2SkpLQvn17XLhwAYGBgfDy8ir0di4lMXDgQHz55Zfo3bs3Pv/8c6Snp2PdunWoW7euxoUgc+fOxcmTJ/Hee+/ByckJT548wdq1a1GtWjW0adOm0P0vWbIE3bt3R8uWLTFixAhkZGTgm2++gbm5OWbPnl1qP8e/6enpYfr06ZLb9ejRA3PnzsWwYcPQqlUrXLt2DTt27EDNmjU1tqtVqxYsLCywfv16mJqawsTEBJ6ennB2di5WrmPHjmHt2rWYNWuW+hZAW7ZsQYcOHTBjxgwsXry4WPsjIioJdhqJZO7999/H1atX8cEHH+CXX36Bj48Ppk6dinv37mHZsmUICAhQb7tx40bMmTMHf/75JyZMmIBjx47Bz88Pu3btKtVMlpaW2Lt3LypWrIgpU6YgMDAQ/v7+6NmzZ77sjo6O2Lx5M3x8fLBmzRq0a9cOx44dg7m5eaH779y5Mw4ePAhLS0vMnDkTS5cuRYsWLXD69OliF1zaMG3aNHzxxRc4dOgQxo8fj0uXLuH3339H9erVNbYzMDBAYGAg9PX18cknn2DQoEEICQkp1rGeP3+O4cOHo3Hjxvjqq6/U69u2bYvx48dj2bJlOHfuXKn8XEREr6NQFWemOBERERHpJHYaiYiIiEgSi0YiIiIiksSikYiIiIgksWgkIiIikgl/f380a9YMpqamsLGxgZeXV7771mZmZsLHxweWlpaoVKkS+vbtW+Bt2f5JpVJh5syZsLe3h7GxMTp37pzvvr5SWDQSERERyURISAh8fHxw7tw5HDlyBDk5OejSpYvG16dOnDgRv/76K/bs2YOQkBA8fvwYffr0ee1+Fy9ejICAAKxfvx7nz5+HiYkJunbtiszMzCJn49XTRERERDIVHx8PGxsbhISEoF27dkhOToa1tTV27tyJDz74AMDLb8uqV68ezp49ixYtWuTbh0qlgoODA7744gtMmjQJAJCcnAxbW1ts3br1td+A9U/sNBIRERFpUVZWFlJSUjSWon6bU3JyMgCgSpUqAIDQ0FDk5OSgc+fO6m1cXV3h6OhY6FfORkVFITY2VuM15ubm8PT0LNLX1L5SLr8RxmfvLdERZMuvQy3REegNlJ79QnQE2XK0rCg6gmxlZOeKjiBLxob6oiPIlpHAqsS48Tit7fvLXlaYM2eOxrpZs2ZJfsNVXl4eJkyYgNatW8PNzQ0AEBsbC0NDQ1hYWGhsa2tri9jY2AL382q9ra1tkV9TkHJZNBIRERHJhZ+fH3x9fTXWKZVKydf5+Pjg+vXrOHXqlLaiFQuLRiIiIiKF9mbsKZXKIhWJ/zRu3Dj89ttvOHnyJKpVq6Zeb2dnh+zsbCQlJWl0G+Pi4mBnZ1fgvl6tj4uLg729vcZrGjVqVORMnNNIREREpFBobykGlUqFcePGYe/evTh27BicnZ01nm/SpAkMDAwQHBysXhceHo7o6Gi0bNmywH06OzvDzs5O4zUpKSk4f/58oa8pCItGIiIiIpnw8fHB9u3bsXPnTpiamiI2NhaxsbHIyMgA8PIClhEjRsDX1xfHjx9HaGgohg0bhpYtW2pcOe3q6oq9e/cCABQKBSZMmID58+dj3759uHbtGoYMGQIHBwd4eXkVORuHp4mIiIi0ODxdHOvWrQMAdOjQQWP9li1bMHToUADAihUroKenh759+yIrKwtdu3bF2rVrNbYPDw9XX3kNAFOmTEFaWhpGjx6NpKQktGnTBgcPHoSRkVGRs5XL+zTy6unC8eppKglePV04Xj1dOF49XTBePV04oVdPN52otX1nXFyhtX2XJXYaiYiIiIo591AXyaMXS0RERESyxk4jERERkUzmNMoZzxARERERSWKnkYiIiIhzGiWxaCQiIiLi8LQkniEiIiIiksROIxERERGHpyWx00hEREREkthpJCIiIuKcRkk8Q0REREQkiZ1GIiIiIs5plMROIxERERFJYqeRiIiIiHMaJbFoJCIiIuLwtCSW1UREREQkiZ1GIiIiIg5PS+IZIiIiIiJJ7DQSERERsdMoiWeIiIiIiCSx01gKalsao3MdS1S3MIKFsQE2nHuAqzGpGtu8V88KrWtUhrGBHu4mZmBXWAzi03IEJRZnZ+BGnDpxFNH3o6BUGqF+Qw+M9pmI6k7OoqMJx3NTuP1Bu3Eg6CfExT4GADg618RA79Fo2qKN4GTysWvnDgRu2YSEhHjUdXHF1Gkz0NDdXXQsoS6HXsT27zcj/OYNJCTE4+vlAWjfsbPoWLLB98y/6PHqaSnsNJYCwwp6eJichd1X4gp8/p06luhQswp2hcVgyYl7yM7Nw7jWjqigg2/Qq5cv4v2+A7F64w4sDvgWuS9eYMr4McjISBcdTTiem8JZWdvCe8xnWPndDqz4bgfc32qOBdMm4n5UpOhosnDwwH4sXeyPMZ/6YNeevXBxccXYMSOQmJgoOppQGRnpqFPXBZP8ZoiOIjt8z1BJsGgsBTfj0vDbrXhciXle4PMda1fBwfAEXI1JxeOULARefAxzowrwsDct46TiLVq5Ht16eKFGzdqoVccFU2bMx5PYGNy5fVN0NOF4bgrXvHV7NG3ZFg7VnVC1uhOGjBoHI+OKCL9xVXQ0WdgWuAV9PugPr959Uat2bUyfNQdGRkYI+vl/oqMJ1apNO3ziMx4d3mZ38d/4nimAQk97SzlRfn4SmbKsaABzowoIj09Tr8t8kYd7zzLgXMVYYDJ5SEt9OYxvamYuOIn88NwULDc3FyeDDyIzMwOubjo8lPb/crKzcevmDbRo2Uq9Tk9PDy1atMLVK5cFJiO54numEAqF9pZyQuicxoSEBGzevBlnz55FbGwsAMDOzg6tWrXC0KFDYW1tLTJeqTAzenmKUzJzNdY/z8xVP6er8vLysGbl13BzbwznWnVEx5EVnpv87kXeweRPvZGdnQ1jY2N8NX8ZHGvUEh1LuGdJz5CbmwtLS0uN9ZaWloiKuisoFckZ3zNUUsKqlj///BNdu3ZFxYoV0blzZ9StWxcAEBcXh4CAACxatAiHDh1C06ZNX7ufrKwsZGVlaazLzcmGvoGh1rJT6QhYsgD3IiOw6ttA0VFkh+cmv6qONbBq0y6kp6Xi9ImjWLFwJvy/2cjCkYhKRzkaRtYWYUXjZ599hn79+mH9+vVQ/Kt1q1Kp8Mknn+Czzz7D2bNnX7sff39/zJkzR2Nd0/6fovnAcaWeuSRSMl8AAMyM9JGS9UK93tRIHw+Tsgp7WbkXsHQBzp0OwYr1W2FtYyc6jqzw3BTMwMAADtUcAQC1Xerjzu0b2LfnB4ybPF1wMrEqW1SGvr5+vgsYEhMTYWVlJSgVyRnfM1RSwsrqK1euYOLEifkKRgBQKBSYOHEiwsLCJPfj5+eH5ORkjaVJ39FaSFwyiek5SM58ARdrE/U6owp6qFHZGFFPMwQmE0OlUiFg6QKcCjmGpas3wd6hmuhIssFzUzyqPBVycrJFxxDOwNAQ9eo3wPlzf/8Pdl5eHs6fPwt3j8YCk5Fc8T1TCM5plCSs02hnZ4cLFy7A1dW1wOcvXLgAW1tbyf0olUoolUqNdWU9NK3UV8C60t/HtKxoiGrmSqRl5+JZxgscj3iKbi5WeJKajcT0HPSoZ43kzBeFXm1dngUsWYDgw/sxb/EqVDQxwdPEBACAiUklKI2MBKcTi+emcIEbAtDEszWsbe2RkZ6GkKMHcC3sIuYsXSs6mix87D0MM6Z9iQYN3ODW0B3btwUiIyMDXr37iI4mVHp6Gh4+iFY/fvzoEf4KvwUzM3PY2TsITCYe3zNUEsKKxkmTJmH06NEIDQ1Fp06d1AViXFwcgoOD8d1332Hp0qWi4hWLY2VjTGjrpH78gfvLn+Xc/SRsuxSDI3cSYVhBgQ8b28PYQA+RiRlYc+YBXuSpREUWZt/PPwIAfD8drrF+8vR56NbDS0Ai+eC5KVzys6dYsXAGniYmwMSkEmrUqoM5S9eicbMWoqPJQrfu7+LZ06dYuzoACQnxcHGth7UbNsJSx4cab928AZ9RQ9WPVy37GgDwbk8vzJy7UFAqeeB7pgCc0yhJoVKphFUuP/74I1asWIHQ0FDk5r68ulhfXx9NmjSBr68v+vfvX6L9+uy9VZoxyxW/DrxogIovPfuF9EY6ytGyougIspWRnSu9kQ4yNtQXHUG2RN5UxLjLEq3tO+PwZK3tuywJvefLgAEDMGDAAOTk5CAh4eVQnJWVFQwMDETGIiIiIl1TjuYeaossbhRoYGAAe3t70TGIiIhIV3F4WhLPEBERERFJkkWnkYiIiEgoDk9LYqeRiIiIiCSx00hERETEOY2SeIaIiIiISBI7jURERESc0yiJnUYiIiIiksROIxERERHnNEpi0UhERETEolESzxARERERSWKnkYiIiIgXwkhip5GIiIiIJLHTSERERMQ5jZJ4hoiIiIhIEotGIiIiIoVCe0sxnTx5Ej179oSDgwMUCgWCgoL+FVVR4LJkyZJC9zl79ux827u6uhYrF4tGIiIiIhlJS0uDh4cH1qxZU+DzMTExGsvmzZuhUCjQt2/f1+63QYMGGq87depUsXJxTiMRERGRFuc0ZmVlISsrS2OdUqmEUqkscPvu3buje/fuhe7Pzs5O4/Evv/yCjh07ombNmq/NUaFChXyvLQ52GomIiIi0ODzt7+8Pc3NzjcXf379UYsfFxeH333/HiBEjJLe9c+cOHBwcULNmTQwePBjR0dHFOhY7jURERERa5OfnB19fX411hXUZiyswMBCmpqbo06fPa7fz9PTE1q1b4eLigpiYGMyZMwdt27bF9evXYWpqWqRjsWgkIiIinafQ4s29XzcU/V9t3rwZgwcPhpGR0Wu3++dwt7u7Ozw9PeHk5ITdu3cXqUsJsGgkIiIieiP98ccfCA8Px48//ljs11pYWKBu3bqIiIgo8ms4p5GIiIh0XmG3sSmNRVs2bdqEJk2awMPDo9ivTU1NRWRkJOzt7Yv8GhaNRERERDKSmpqKsLAwhIWFAQCioqIQFhamceFKSkoK9uzZg5EjRxa4j06dOmH16tXqx5MmTUJISAju3buHM2fOoHfv3tDX18egQYOKnIvD00RERETaawgW28WLF9GxY0f141cX0Xh7e2Pr1q0AgF27dkGlUhVa9EVGRiIhIUH9+OHDhxg0aBASExNhbW2NNm3a4Ny5c7C2ti5yLoVKpVKV4OeRNZ+9t0RHkC2/DrVER6A3UHr2C9ERZMvRsqLoCLKVkZ0rOoIsGRvqi44gW0YCW1km/bZobd9pe4Zpbd9liZ1GIiIi0nnanHtYXpTLonF8KyfREWRr45/3RUeQrZHN+L4pjLWpdm4VUR5cvpckOoJsVWcXtkDxz7OkN9JRdW3FvWdYNErjhTBEREREJKlcdhqJiIiIioOdRmnsNBIRERGRJHYaiYiISOex0yiNnUYiIiIiksROIxEREREbjZLYaSQiIiIiSew0EhERkc7jnEZp7DQSERERkSR2GomIiEjnsdMojUUjERER6TwWjdI4PE1EREREkthpJCIiIp3HTqM0dhqJiIiISBI7jURERERsNEpip5GIiIiIJLHTSERERDqPcxqlsdNIRERERJLYaSQiIiKdx06jNBaNREREpPNYNErj8DQRERERSWKnkYiIiIiNRknsNBIRERGRJHYaiYiISOdxTqM0dhqJiIiISBI7jURERKTz2GmUxqJRC/YH7caBoJ8QF/sYAODoXBMDvUejaYs2gpPJQ05mOq7+vh0Pr5xFVmoyKleribf6joalU13R0YTaGbgRp04cRfT9KCiVRqjf0AOjfSaiupOz6GjCXQ69iO3fb0b4zRtISIjH18sD0L5jZ9GxZGHvju/wy86NGuvsqjlh0YbdghLJBz9ThePfKSoJFo1aYGVtC+8xn8GhmiNUAIIP/ooF0yZi5aZdcHKuJTqecBd2foOkmPtoOeQLGJtXwb0/j+P46ul496u1qGhhJTqeMFcvX8T7fQfCtb4bcnNzsWndKkwZPwabfwiCsXFF0fGEyshIR526LujZqw+mfvG56DiyU9WpJibPX61+rK+vLzCNfPAzVTj+ncqPnUZpLBq1oHnr9hqPh4wahwNBexB+46rOfhhfeZGdhQdXTqPtqBmwqe0GAGj47mA8un4BEacOwL3Hx4ITirNo5XqNx1NmzEff7u1x5/ZNuDduKiiVPLRq0w6t2rQTHUO29PT0YVHFUnQM2eFnqnD8O5Ufi0ZpLBq1LDc3F6dPHEFmZgZc3dxFxxFOlZcLVV4e9A0MNNbrGygRH3lDUCp5SktNBQCYmpkLTkJyF/f4ASZ8/B4MDAxRq15D9PP+FJY2dqJjyQ4/UwXj3ykqKhaNWnIv8g4mf+qN7OxsGBsb46v5y+BYQzf/7+2fDIwqwsrZFTcO7oKZXXUYmVrgfuhJJEbdRiVre9HxZCMvLw9rVn4NN/fGcK5VR3QckrFaLg0wcuJM2FdzRNLTRPyycyMWThmD+Wt3wriiieh4ssHPVH78O/UvbDRKkvUtdx48eIDhw4e/dpusrCykpKRoLNlZWWWUsHBVHWtg1aZdWLb+e3Tv1Q8rFs5E9L1I0bFkocXHX0AF4Jfp3tg9sTf+OrEPjk3acWjgHwKWLMC9yAhMn79YdBSSOfemrdC8bSdUd66Dhk1aYOKcFUhPe44LfwSLjiYr/Ezlx79TVFyyLhqfPn2KwMDA127j7+8Pc3NzjWVDwNIySlg4AwMDOFRzRG2X+vAe8zmca9fFvj0/iI4lC6bW9ug8fhH6Lf0JveZuRdfJK6DKzUUlSw6nAUDA0gU4dzoEy9ZugjWHGKmYTCqZwq6qI57EPBAdRTb4mSoY/05pUigUWlvKC6HD0/v27Xvt83fv3pXch5+fH3x9fTXWRSfl/qdc2qDKUyEnJ1t0DFmpoDRCBaURstNTEXP7Ehr1GiY6klAqlQrfLFuIUyHHsHzNZtg7VBMdid5AmRnpeBLzCK3e7i46inD8TBUP/06RFKFFo5eXFxQKBVQqVaHbSFXoSqUSSqVSY51hRnqp5CupwA0BaOLZGta29shIT0PI0QO4FnYRc5auFZpLLmJuhUKlAsxsquJ5QgzCgjbDzLYaarbQ7fvuBSxZgODD+zFv8SpUNDHB08QEAICJSSUojYwEpxMrPT0NDx9Eqx8/fvQIf4XfgpmZOezsHQQmE2/XxlVo5NkWljZ2SEpMQNCO76CnpwfP9l1ERxOOn6nC8e9UfuWpI6gtQotGe3t7rF27Fr169Srw+bCwMDRp0qSMU/13yc+eYsXCGXiamAATk0qoUasO5ixdi8bNWoiOJgs5Gem48msg0pMSYFjRFNU9WsG95xDo6ev2dVn7fv4RAOD7qeY83snT56FbDy8BieTj1s0b8Bk1VP141bKvAQDv9vTCzLkLBaWSh6eJT7B+8QykpiTD1NwCdRp4YMbyTTAzryw6mnD8TBWOf6eoJBSq17X5tOz9999Ho0aNMHfu3AKfv3LlCho3boy8vLxi7fevOLGdRjnbeeWR6AiyNbKZk+gIsmWi5M2iC3P78XPREWSruqVu30C7MOnZL0RHkK26tuLeM9V9ftHavh+sKbg59qYR2tqZPHky0tLSCn2+du3aOH78eBkmIiIiIp3E0WlJQovGtm3bvvZ5ExMTtG/f/rXbEBEREZH26fYkMiIiIiLwQpiikPV9GomIiIhIHthpJCIiIp3HTqM0dhqJiIiISBI7jURERKTz2GmUxk4jERERkYycPHkSPXv2hIODAxQKBYKCgjSeHzp0aL7vt+7WrZvkftesWYMaNWrAyMgInp6euHDhQrFysWgkIiIinffvIqw0l+JKS0uDh4cH1qxZU+g23bp1Q0xMjHr54YcfXrvPH3/8Eb6+vpg1axYuXboEDw8PdO3aFU+ePClyLg5PExEREclodLp79+7o3r37a7dRKpWws7Mr8j6XL1+OUaNGYdiwYQCA9evX4/fff8fmzZsxderUIu2DnUYiIiIiLcrKykJKSorGkpWV9Z/2eeLECdjY2MDFxQVjx45FYmJiodtmZ2cjNDQUnTt3Vq/T09ND586dcfbs2SIfk0UjERER6TxtDk/7+/vD3NxcY/H39y9x1m7duuH7779HcHAwvv76a4SEhKB79+7Izc0tcPuEhATk5ubC1tZWY72trS1iY2OLfFwOTxMRERFpkZ+fH3x9fTXWKZXKEu9v4MCB6n9v2LAh3N3dUatWLZw4cQKdOnUq8X6lsGgkIiIinafNW+4olcr/VCRKqVmzJqysrBAREVFg0WhlZQV9fX3ExcVprI+LiyvWvEgOTxMRERG9wR4+fIjExETY29sX+LyhoSGaNGmC4OBg9bq8vDwEBwejZcuWRT4Oi0YiIiLSeQqF9pbiSk1NRVhYGMLCwgAAUVFRCAsLQ3R0NFJTUzF58mScO3cO9+7dQ3BwMHr16oXatWuja9eu6n106tQJq1evVj/29fXFd999h8DAQNy6dQtjx45FWlqa+mrqouDwNBEREZGMXLx4ER07dlQ/fjUf0tvbG+vWrcPVq1cRGBiIpKQkODg4oEuXLpg3b57GEHhkZCQSEhLUjwcMGID4+HjMnDkTsbGxaNSoEQ4ePJjv4pjXUahUKlUp/Hyy8ldcuugIsrXzyiPREWRrZDMn0RFky0SpLzqCbN1+/Fx0BNmqbllRdARZSs9+ITqCbNW1FfeeqTP5oNb2fWeJ9Le1vAnYaSQiIiKdx6+elsY5jUREREQkiZ1GIiIi0nnavOVOecFOIxERERFJYqeRiIiIdB4bjdLYaSQiIiIiSew0EhERkc7T02OrUQo7jUREREQkiZ1GIiIi0nmc0yiNRSMRERHpPN5yR1q5LBqtTZXSG+koflVe4QZuOi86gmz9+mkr0RFky9LUUHQEesPcTUgTHUG2RH6NIEkrl0UjERERUXGw0SiNF8IQERERkSR2GomIiEjncU6jNHYaiYiIiEgSO41ERESk89hplMZOIxERERFJYqeRiIiIdB4bjdJYNBIREZHO4/C0NA5PExEREZEkdhqJiIhI57HRKI2dRiIiIiKSxE4jERER6TzOaZTGTiMRERERSWKnkYiIiHQeG43S2GkkIiIiIknsNBIREZHO45xGaew0EhEREZEkdhqJiIhI57HRKI1FIxEREek8Dk9L4/A0EREREUlip5GIiIh0HhuN0thpJCIiIiJJ7DQSERGRzuOcRmnsNBIRERGRJHYaiYiISOex0SiNnUYiIiIiksROo5ZcDr2I7d9vRvjNG0hIiMfXywPQvmNn0bGE2xm4EadOHEX0/SgolUao39ADo30morqTs+hoZc6jmhk+bFYNLraVYFVJCb+gm/gjIlH9/PBWjujkYg0bMyVe5OYhPC4V3/5xHzdjnwtMLQY/T4XbH7QbB4J+QlzsYwCAo3NNDPQejaYt2ghOJh5/3xQuKTEe+7atw61L55CTnQkru2r4cNw0ONZ2FR1NGM5plMZOo5ZkZKSjTl0XTPKbITqKrFy9fBHv9x2I1Rt3YHHAt8h98QJTxo9BRka66GhlzthAHxFP0rD8aGSBzz94moEVwZHw3noJn/5wFTHJWVjezw0WxgZlnFQ8fp4KZ2VtC+8xn2Hldzuw4rsdcH+rORZMm4j7UQW/r3QJf98ULD01BaumjYW+fgV8MmMp/FZth9fQcahYyVR0NKEUCu0t5QU7jVrSqk07tGrTTnQM2Vm0cr3G4ykz5qNv9/a4c/sm3Bs3FZRKjHNRz3Au6lmhzx+5Ha/x+JsTd9HT3Q61rE0QGp2k5XTyws9T4Zq3bq/xeMiocTgQtAfhN67CybmWoFTywN83BTu6dwcsrGww+LNp6nWWtg4CE9GbgkUjCZWWmgoAMDUzF5xE3iroKdDL3Q7PM18gIj5VdBySqdzcXJw+cQSZmRlwdXMXHUd2+Pvmpet/noZro+bYsmQ6Im6EwdzSGm269Uard94XHU0oDk9LY9FIwuTl5WHNyq/h5t4YzrXqiI4jS61qVsHsHq4wMtBDYmo2Jv50DckZL0THIpm5F3kHkz/1RnZ2NoyNjfHV/GVwrKHbXcZ/4++bvyXGPcbpQ0Ho0HMA3uk7BNERt/DzppWoUMEAzTt2Fx2PZEx40ZiRkYHQ0FBUqVIF9evX13guMzMTu3fvxpAhQwp9fVZWFrKysjTX5VaAUqnUSl4qPQFLFuBeZARWfRsoOopsXXqQhGHfX4KFsQF6utthbs96GL0jDEnpOaKjkYxUdayBVZt2IT0tFadPHMWKhTPh/81GFo7/wN83f1Op8lC9lit6fjQGAFCtZl3EREfh9KEgnS4a2WmUJvRCmL/++gv16tVDu3bt0LBhQ7Rv3x4xMTHq55OTkzFs2LDX7sPf3x/m5uYay4qli7Qdnf6jgKULcO50CJat3QRrGzvRcWQrMycPj5IycSPmORYduoPcPBV6uNmKjkUyY2BgAIdqjqjtUh/eYz6Hc+262LfnB9GxZIO/bzSZWVjCrloNjXW21ZzwLCFOTCB6YwgtGr/88ku4ubnhyZMnCA8Ph6mpKVq3bo3o6Ogi78PPzw/Jyckay8RJU7WYmv4LlUqFgKULcCrkGJau3gR7h2qiI71R9BSAYQXe9IBeT5WnQk5OtugYwvH3TcGc6zXEk8eaf2efPH6Ayta6XVDz6mlpQoenz5w5g6NHj8LKygpWVlb49ddf8emnn6Jt27Y4fvw4TExMJPehVCrzDUXnpudqK3KRpaen4eGDvz+Ujx89wl/ht2BmZg47e929Si1gyQIEH96PeYtXoaKJCZ4mJgAATEwqQWlkJDhd2TI20ENVC2P1Y3tzJWpbm+B55gskZ+ZgiGd1nI58ioS0bFgYG6BPI3tYVVLieHiCwNRi8PNUuMANAWji2RrWtvbISE9DyNEDuBZ2EXOWrhUdTTj+vilYhx4DsHLaJzj80/do3Ppt3L9zE2eP7MOAT6aIjkYyp1CpVCpRBzczM8P58+dRr149jfXjxo3DL7/8gp07d6JDhw7IzS1eEfhMBkVj6MUL8Bk1NN/6d3t6YebchWUf6P+lZYk9N51aNCxw/eTp89Cth1fZhvmXgZvOl+nxGlc3xzcD8l/huv96HJYeuYNZ77mivr0pzI0NkJKZg1uxqQg8F43bsWV/9fSvn7Yq82P+k1w/TwAQ/zxLeiMtClg0G1cuXcDTxASYmFRCjVp10PfDYWjcrIXQXABQ0VDstHm5/r65/jhZ2LHVGS6exm/bNyA+5iEsbezR4f0Bsrh6ulsDa2HH7rDyjNb2fWKC2N+hpUVo0di8eXN89tln+Pjjj/M9N27cOOzYsQMpKSlvZNEoV6KLRjkr66LxTSK6aJQz0UWjnIkuGuVKDkWjXIksGjuu0l7ReHx88X6Hnjx5EkuWLEFoaChiYmKwd+9eeHl5AQBycnIwffp07N+/H3fv3oW5uTk6d+6MRYsWwcGh8JGX2bNnY86cORrrXFxccPv27SLnEjo5qnfv3vjhh4Ina69evRqDBg2CwJqWiIiIqMylpaXBw8MDa9asyfdceno6Ll26hBkzZuDSpUv4+eefER4ejvffl+4UN2jQADExMerl1KlTxcol9H8D/fz84OfnV+jza9euxdq1nJdDRERE2iWnW+50794d3bsXfPsjc3NzHDlyRGPd6tWr0bx5c0RHR8PR0bHQ/VaoUAF2diW/4ImXYRIRERFpUVZWFlJSUjSWf99j+r9ITk6GQqGAhYXFa7e7c+cOHBwcULNmTQwePLhYd6sBWDQSERERafWWOwXdU9rf379UcmdmZuLLL7/EoEGDYGZmVuh2np6e2Lp1Kw4ePIh169YhKioKbdu2xfPnz4t8LM5SJiIiItIiPz8/+Pr6aqwrjW+uy8nJQf/+/aFSqbBu3brXbvvP4W53d3d4enrCyckJu3fvxogRI4p0PBaNREREpPP0tDinsaB7Sv9XrwrG+/fv49ixY6/tMhbEwsICdevWRURERJFfw+FpIiIiojfIq4Lxzp07OHr0KCwtLYu9j9TUVERGRsLe3r7Ir2HRSERERDpPTl8jmJqairCwMISFhQEAoqKiEBYWhujoaOTk5OCDDz7AxYsXsWPHDuTm5iI2NhaxsbHIzv7760M7deqE1atXqx9PmjQJISEhuHfvHs6cOYPevXtDX18fgwYNKnIuDk8TERGRzpPTLXcuXryIjh07qh+/mg/p7e2N2bNnY9++fQCARo0aabzu+PHj6NChAwAgMjISCQl/f+3sw4cPMWjQICQmJsLa2hpt2rTBuXPnYG1d9Buqs2gkIiIikpEOHTq89stNivLFJ/fu3dN4vGvXrv8ai0UjERERkZ58Go2yxTmNRERERCSJnUYiIiLSeXKa0yhX7DQSERERkSR2GomIiEjnsdEojZ1GIiIiIpLETiMRERHpPAXYapTCopGIiIh0Hm+5I43D00REREQkiZ1GIiIi0nm85Y40dhqJiIiISBI7jURERKTz2GiUxk4jEREREUlip5GIiIh0nh5bjZLYaSQiIiIiSew0EhERkc5jo1Eai0YiIiLSebzljjQOTxMRERGRpHLZaYx/niU6gmxZmypFR5CtoxPaio4gW5V7BYiOIFt3tn8iOgIRlQI2GqWx00hEREREksplp5GIiIioOHjLHWnsNBIRERGRJHYaiYiISOexzyiNnUYiIiIiksROIxEREek83qdRGotGIiIi0nl6rBklcXiaiIiIiCSx00hEREQ6j8PT0thpJCIiIiJJ7DQSERGRzmOjURo7jUREREQkiZ1GIiIi0nmc0yiNnUYiIiIiksROIxEREek83qdRGotGIiIi0nkcnpbG4WkiIiIiksROIxEREek89hmlsdNIRERERJJKVDT+8ccf+Oijj9CyZUs8evQIALBt2zacOnWqVMMRERERlQU9hUJrS3lR7KLxf//7H7p27QpjY2NcvnwZWVlZAIDk5GQsXLiw1AMSERERkXjFLhrnz5+P9evX47vvvoOBgYF6fevWrXHp0qVSDUdERERUFhQK7S3lRbGLxvDwcLRr1y7fenNzcyQlJZVGJiIiIiKSmWIXjXZ2doiIiMi3/tSpU6hZs2aphCIiIiIqSwqFQmtLeVHsonHUqFEYP348zp8/D4VCgcePH2PHjh2YNGkSxo4dq42MRERERCRYse/TOHXqVOTl5aFTp05IT09Hu3btoFQqMWnSJHz22WfayEhERESkVeWoIag1xS4aFQoFvvrqK0yePBkRERFITU1F/fr1UalSJW3keyPtD9qNA0E/IS72MQDA0bkmBnqPRtMWbQQnk4fLoRex/fvNCL95AwkJ8fh6eQDad+wsOpZs7Nq5A4FbNiEhIR51XVwxddoMNHR3Fx2rTLVu4ICJfZvgrdrWsLeshP7zfsOv5+6qnzcxMsD8oa3Qs2UtVDE1wr24FKzdF4aNB64LTC3GzsCNOHXiKKLvR0GpNEL9hh4Y7TMR1Z2cRUcTjuemcEmJ8di3bR1uXTqHnOxMWNlVw4fjpsGxtqvoaMKUp1vjaEuJvxHG0NAQ9evXL80s5YaVtS28x3wGh2qOUAEIPvgrFkybiJWbdsHJuZboeMJlZKSjTl0X9OzVB1O/+Fx0HFk5eGA/li72x/RZc9CwoQd2bAvE2DEj8MtvB2FpaSk6XpkxMTLAtah4fH/kBn6c3iPf81+PaosO7tUwbOkh3I9LQee3HLHq046IeZqG389HCUgsztXLF/F+34Fwre+G3NxcbFq3ClPGj8HmH4JgbFxRdDyheG4Klp6aglXTxqK221v4ZMZSVDKzQHzMQ1SsZCo6GslcsYvGjh07vnZS57Fjx/5ToPKgeev2Go+HjBqHA0F7EH7jKotGAK3atEOrNvmvwCdgW+AW9PmgP7x69wUATJ81BydPnkDQz//DiFGjBacrO4dD7+Nw6P1Cn2/hao/twbfwx7WXXy6w+eANjOjeEE3r2upc0bho5XqNx1NmzEff7u1x5/ZNuDduKiiVPPDcFOzo3h2wsLLB4M+mqddZ2joITCQPcmo0njx5EkuWLEFoaChiYmKwd+9eeHl5qZ9XqVSYNWsWvvvuOyQlJaF169ZYt24d6tSp89r9rlmzBkuWLEFsbCw8PDzwzTffoHnz5kXOVewLYRo1agQPDw/1Ur9+fWRnZ+PSpUto2LBhcXdX7uXm5uJk8EFkZmbA1U23hhipeHKys3Hr5g20aNlKvU5PTw8tWrTC1SuXBSaTn3O3Y9DDsyYcLE0AAO3cq6GOgwWOXooWnEy8tNRUAICpmbngJPLDc/PS9T9Po3otV2xZMh1fDe2BxV8Mw5kj+0THon9IS0uDh4cH1qxZU+DzixcvRkBAANavX4/z58/DxMQEXbt2RWZmZqH7/PHHH+Hr64tZs2bh0qVL8PDwQNeuXfHkyZMi5yp2p3HFihUFrp89ezZS//8DScC9yDuY/Kk3srOzYWxsjK/mL4NjDXYZqXDPkp4hNzc33zC0paUloqLuFvIq3eS7LgRrPnsbkd+PQM6LXOSpgE8DgnH6xmPR0YTKy8vDmpVfw829MZxrvb7joGt4bv6WGPcYpw8FoUPPAXin7xBER9zCz5tWokIFAzTv2F10PGHkdGuc7t27o3v3gv9bqFQqrFy5EtOnT0evXr0AAN9//z1sbW0RFBSEgQMHFvi65cuXY9SoURg2bBgAYP369fj999+xefNmTJ06tUi5Sjyn8d8++ugjNG/eHEuXLi3W627duoVz586hZcuWcHV1xe3bt7Fq1SpkZWXho48+wttvv/3a12dlZam/yvCV7KxcGCqVxf4ZSlNVxxpYtWkX0tNScfrEUaxYOBP+32xk4UhUCj593x3NXe3Qd86viH6SgjZuVbFybAfEPE3D8bAHouMJE7BkAe5FRmDVt4Gio8gOz83fVKo8VK/lip4fjQEAVKtZFzHRUTh9KEini0ZtKqhWUSqVUJagVomKikJsbCw6d/77AlJzc3N4enri7NmzBRaN2dnZCA0NhZ+fn3qdnp4eOnfujLNnzxb52MUeni7M2bNnYWRkVKzXHDx4EI0aNcKkSZPQuHFjHDx4EO3atUNERATu37+PLl26SM6R9Pf3h7m5ucayIaB4has2GBgYwKGaI2q71If3mM/hXLsu9u35QXQskrHKFpWhr6+PxMREjfWJiYmwsrISlEp+jAz1MWdIK3y58Q/svxCF6/cSsf63q/jpjzuY0Oct0fGECVi6AOdOh2DZ2k2wtrETHUdWeG40mVlYwq5aDY11ttWc8CwhTkwgmdDT4lJQreLv71+inLGxsQAAW1tbjfW2trbq5/4tISEBubm5xXpNQYrdaezTp4/GY5VKhZiYGFy8eBEzZswo1r7mzp2LyZMnY/78+di1axc+/PBDjB07FgsWLAAA+Pn5YdGiRa/tNvr5+cHX11djXXRSbrFylAVVngo5OdmiY5CMGRgaol79Bjh/7ize7vTy/yDz8vJw/vxZDBz0keB08mGgrw9DA33k5ak01ufm5enkLTNUKhW+WbYQp0KOYfmazbB3qCY6kmzw3BTMuV5DPHmsOf/3yeMHqGzNglpbCqpVStJlFK3YRaO5ueYEYj09Pbi4uGDu3Lno0qVLsfZ148YNfP/99wCA/v374+OPP8YHH3ygfn7w4MHYsmXLa/dRUHvXMCO9WDlKW+CGADTxbA1rW3tkpKch5OgBXAu7iDlL1wrNJRfp6Wl4+ODvX1iPHz3CX+G3YGZmDjt73b6C72PvYZgx7Us0aOAGt4bu2L4tEBkZGfDq3Uf6xeWIiZEBajn8/bumhp0Z3Gta4dnzTDyIT8XJqw+xcHgbZGS/QPST52jbsCoGv10PX278Q2BqMQKWLEDw4f2Yt3gVKpqY4GliAgDAxKQSlMUc/SlveG4K1qHHAKyc9gkO//Q9Grd+G/fv3MTZI/sw4JMpoqMJpc05jSUdii6Ind3L4j4uLg729vbq9XFxcWjUqFGBr7GysoK+vj7i4jS7yXFxcer9FUWxisbc3FwMGzYMDRs2ROXKlYvz0kK9+o+kp6cHIyMjjaLU1NQUycnJpXKcspT87ClWLJyBp4kJMDGphBq16mDO0rVo3KyF6GiycOvmDfiMGqp+vGrZ1wCAd3t6YebchYJSyUO37u/i2dOnWLs6AAkJ8XBxrYe1GzbCUseGp9+qY4PDi/qqHy8e9fIWTduO3sToFUcxZPFBzPVuha2TuqKyqRGin6Rg9vdn8d3+a6IiC7Pv5x8BAL6fDtdYP3n6PHTr4SUgkXzw3BTMqU49jPhyIX7bvgGH9myFpY09eg//HE3bF6/xU97ovSEDFc7OzrCzs0NwcLC6SExJScH58+cL/TpnQ0NDNGnSBMHBwepb9+Tl5SE4OBjjxo0r8rGLVTTq6+ujS5cuuHXrVqkUjTVq1MCdO3dQq9bLi0POnj0LR0dH9fPR0dEaVfSb4vOps0VHkLUmTZvj3OWbomPI1qDBH2HQYN0ejv7j2iMYvxdQ6PNxz9IxZuXRMkwkX8HndK9QLiqem8K5NW0Nt6atRcegQqSmpiIiIkL9OCoqCmFhYahSpQocHR0xYcIEzJ8/H3Xq1IGzszNmzJgBBwcHjXs5durUCb1791YXhb6+vvD29kbTpk3RvHlzrFy5EmlpaeqrqYui2MPTbm5uuHv3Lpyd//vXMI0dOxa5uX/PP3Rzc9N4/sCBA5JXTxMRERH9V3LqNF68eBEdO3ZUP341H9Lb2xtbt27FlClTkJaWhtGjRyMpKQlt2rTBwYMHNS5IjoyMREJCgvrxgAEDEB8fj5kzZyI2NhaNGjXCwYMH810c8zoKlUqlkt7sbwcPHoSfnx/mzZuHJk2awMTERON5MzOz4uxOK/6KEzunUc6sTd+8ibdlxdhQX3QE2arcq/Cun667s/0T0RHoDXP98Zs37aqsdGtgLezYvvtua23fy98vH9/pXeRO49y5c/HFF1/g3XffBQC8//77GpNGVSoVFAqFRueQiIiI6E0gp5t7y1WRi8Y5c+bgk08+wfHjx7WZh4iIiIhkqMhF46tR7Pbt22stDBEREZEIcprTKFfF+kYYtm6JiIiIdFOxrp6uW7euZOH49OnT/xSIiIiIqKyxLyatWEXjnDlz8n0jDBEREdGbThe/hrS4ilU0Dhw4EDY2NtrKQkREREQyVeSikfMZiYiIqLwq1kUeOqrI56iY9wAnIiIionKkyJ3GvLw8beYgIiIiEoYDqtLYjSUiIiIiScW6EIaIiIioPOLV09LYaSQiIiIiSew0EhERkc5jo1Eai0YiIiLSefzuaWkcniYiIiIiSew0EhERkc7jhTDS2GkkIiIiIknsNBIREZHOY6NRGjuNRERERCSJnUYiIiLSebx6Who7jUREREQkiZ1GIiIi0nkKsNUohUUjERER6TwOT0vj8DQRERERSWKnkYiIiHQeO43SymXR6GhZUXQEegNlZOeKjiBbz375XHQE2arcbJzoCLL1+PQq0RFkqYOLtegIRCVSLotGIiIiouJQ8O7ekjinkYiIiIgksdNIREREOo9zGqWx00hEREREkthpJCIiIp3HKY3SWDQSERGRztNj1SiJw9NEREREJImdRiIiItJ5vBBGGjuNRERERCSJnUYiIiLSeZzSKI2dRiIiIiKSxE4jERER6Tw9sNUohZ1GIiIiIpLETiMRERHpPM5plMaikYiIiHQeb7kjjcPTRERERCSJnUYiIiLSefwaQWnsNBIRERGRJHYaiYiISOex0SiNnUYiIiIiksSikYiIiHSenkKhtaU4atSoAYVCkW/x8fEpcPutW7fm29bIyKg0Tkk+HJ4mIiIikok///wTubm56sfXr1/HO++8g379+hX6GjMzM4SHh6sfK7Q01s6ikYiIiHSeNuc0ZmVlISsrS2OdUqmEUqnMt621tbXG40WLFqFWrVpo3759oftXKBSws7MrnbCvweFpIiIi0nl6Wlz8/f1hbm6usfj7+0tmys7Oxvbt2zF8+PDXdg9TU1Ph5OSE6tWro1evXrhx40aJzoEUdhqJiIiItMjPzw++vr4a6wrqMv5bUFAQkpKSMHTo0EK3cXFxwebNm+Hu7o7k5GQsXboUrVq1wo0bN1CtWrX/Gl0Di0YiIiLSedqaBwgUPhQtZdOmTejevTscHBwK3aZly5Zo2bKl+nGrVq1Qr149bNiwAfPmzStR3sJweFqLdu3cge7vvI1mjRti8MB+uHb1quhIssFzU7DLoRfxxfhP0eOd9mjRuD5Cjh8VHUlWdP19M2l4F5zaPhlPTi3F/WB/7F4+CnWcbDS2URpWwIqp/fHw+NeIP70MPywdCZsqpoISi8XP0+vp+udJ7u7fv4+jR49i5MiRxXqdgYEBGjdujIiIiFLPxKJRSw4e2I+li/0x5lMf7NqzFy4urhg7ZgQSExNFRxOO56ZwGRnpqFPXBZP8ZoiOIjt83wBt36qN9T+eRPshS9Fj7GpUqKCP39aNQ0UjQ/U2iyf1xXvt3DB4yiZ0GbkS9tbm2LWseH90ygt+ngrHz1N+Ci0uJbFlyxbY2NjgvffeK9brcnNzce3aNdjb25fwyIVj0agl2wK3oM8H/eHVuy9q1a6N6bPmwMjICEE//090NOF4bgrXqk07fOIzHh3e7iw6iuzwfQP0GrcW2389j1t3Y3Htr0cYPWs7HO2roHH96gAAs0pGGOrVEl8u/xkhf/6Fy7ceYPSs7WjZqBaaN6whNrwA/DwVjp8necvLy8OWLVvg7e2NChU0ZxIOGTIEfn5+6sdz587F4cOHcffuXVy6dAkfffQR7t+/X+wOZVHIrmhUqVSiI/xnOdnZuHXzBlq0bKVep6enhxYtWuHqlcsCk4nHc0MlwfdNwcwqvbyB77PkdABA43qOMDSogGPn/r5f21/34hAd8xSe7s5CMpL88PNUMLnc3BsAjh49iujoaAwfPjzfc9HR0YiJiVE/fvbsGUaNGoV69erh3XffRUpKCs6cOYP69ev/p/NRENldCKNUKnHlyhXUq1dPdJQSe5b0DLm5ubC0tNRYb2lpiaiou4JSyQPPDZUE3zf5KRQKLJn0Ac5cjsTNyJd/QOwszZCVnYPk1AyNbZ8kpsDW0kxETJIhfp7kr0uXLoU20U6cOKHxeMWKFVixYkUZpBJYNP770vNXcnNzsWjRIvWbefny5a/dT0E3zFTpl+wqJSKiN8VKv/5oUNsenYaVzR8LovJOi/f2LjeEFY0rV66Eh4cHLCwsNNarVCrcunULJiYmRbr83d/fH3PmzNFY99WMWZg+c3Yppi2eyhaVoa+vn29CcWJiIqysrASlkgeeGyoJvm80rfiyH95t64bOI1bi0ZMk9frYxBQoDQ1gXslYo9toY2mGuMQUAUlJjvh5Kpg2vxGmvBA2p3HhwoVITk7GjBkzcPz4cfWir6+PrVu34vjx4zh27Jjkfvz8/JCcnKyxTP7ST/J12mRgaIh69Rvg/Lmz6nV5eXk4f/4s3D0aC0wmHs8NlQTfN39b8WU/vP+2B7qNCcD9x5p/9C/fikZ2zgt09HRRr6vjZANH+yo4fzWqrKOSTPHzRCUlrNM4depUdOrUCR999BF69uwJf39/GBgYFHs/Bd0wM/NFaaUsuY+9h2HGtC/RoIEb3Bq6Y/u2QGRkZMCrdx/R0YTjuSlcenoaHj6IVj9+/OgR/gq/BTMzc9jZF35zV13A983LIekB3Zui38RvkZqWCVvLl/dfTE7NRGZWDlJSM7E16Cy+/qIPnian4XlaJpZ/2Q/nrtzFhWv3xIYXgJ+nwvHzlJ82b+5dXgi9EKZZs2YIDQ2Fj48PmjZtih07dpSb/2jdur+LZ0+fYu3qACQkxMPFtR7WbtgISx1u/b/Cc1O4WzdvwGfUUPXjVcu+BgC829MLM+cuFJRKHvi+Acb0bwcAOLJxgsb6UTO3Yfuv5wEAU5b+D3l5KvywdCSUhhVw9MwtjPf/sayjygI/T4Xj54lKQqGSyT1udu3ahQkTJiA+Ph7Xrl37T5eKy6HTSG+ejOxc0RFky9hQX3QE2arcbJzoCLL1+PQq0RFkiZ+nwhkJbGX9ePmR1vY9oHFVre27LMnmljsDBw5EmzZtEBoaCicnJ9FxiIiIiOgfZFM0AkC1atVQrVo10TGIiIhIx5SX6XHaJLtvhCEiIiIi+ZFVp5GIiIhIBPYZpbHTSERERESS2GkkIiIincc5jdJYNBIREZHO49CrNJ4jIiIiIpLETiMRERHpPA5PS2OnkYiIiIgksdNIREREOo99RmnsNBIRERGRJHYaiYiISOdxSqM0dhqJiIiISBI7jURERKTz9DirURKLRiIiItJ5HJ6WxuFpIiIiIpLETiMRERHpPAWHpyWx00hEREREkthpJCIiIp3HOY3S2GkkIiIiIknsNBIREZHO4y13pLHTSERERESS2GkkIiIincc5jdJYNBIREZHOY9EojcPTRERERCSJnUYiIiLSeby5tzR2GomIiIhIUrnsNCY8zxYdgd5A6dkvREeQLUfLiqIjyNadY8tFR5CtnmvPiI4gS4NaVhcdQbZ8WtcQdmw9NholsdNIRERERJLKZaeRiIiIqDg4p1EaO41EREREJImdRiIiItJ5vE+jNBaNREREpPM4PC2Nw9NEREREJImdRiIiItJ5vOWONHYaiYiIiEgSO41ERESk8zinURo7jUREREQkiZ1GIiIi0nm85Y40dhqJiIiIZGL27NlQKBQai6ur62tfs2fPHri6usLIyAgNGzbE/v37tZKNRSMRERHpPIUWl+Jq0KABYmJi1MupU6cK3fbMmTMYNGgQRowYgcuXL8PLywteXl64fv16CY78ehyeJiIiIp2nJ6Px6QoVKsDOzq5I265atQrdunXD5MmTAQDz5s3DkSNHsHr1aqxfv75Uc7HTSERERKRFWVlZSElJ0ViysrIK3f7OnTtwcHBAzZo1MXjwYERHRxe67dmzZ9G5c2eNdV27dsXZs2dLLf8rLBqJiIhI52lzeNrf3x/m5uYai7+/f4E5PD09sXXrVhw8eBDr1q1DVFQU2rZti+fPnxe4fWxsLGxtbTXW2draIjY2tuQnoxAcniYiIiLSIj8/P/j6+mqsUyqVBW7bvXt39b+7u7vD09MTTk5O2L17N0aMGKHVnFJYNBIRERFpcUqjUqkstEiUYmFhgbp16yIiIqLA5+3s7BAXF6exLi4urshzIouDw9NEREREMpWamorIyEjY29sX+HzLli0RHBysse7IkSNo2bJlqWdh0UhEREQ6T6HFf4pj0qRJCAkJwb1793DmzBn07t0b+vr6GDRoEABgyJAh8PPzU28/fvx4HDx4EMuWLcPt27cxe/ZsXLx4EePGjSvV8wNweJqIiIhINh4+fIhBgwYhMTER1tbWaNOmDc6dOwdra2sAQHR0NPT0/u75tWrVCjt37sT06dMxbdo01KlTB0FBQXBzcyv1bCwaiYiISOfJ5TaNu3bteu3zJ06cyLeuX79+6Nevn5YS/Y1FIxEREek8mdSMssY5jUREREQkiZ1GIiIiIrYaJbHTSERERESS2GnUgp2BG3HqxFFE34+CUmmE+g09MNpnIqo7OYuOJhzPTeH2B+3GgaCfEBf7GADg6FwTA71Ho2mLNoKTyceunTsQuGUTEhLiUdfFFVOnzUBDd3fRsYTiZ+pvHtXM8GGzanCxrQSrSkr4Bd3EHxGJ6ueHt3JEJxdr2Jgp8SI3D+Fxqfj2j/u4GVvw17OVV3l5uTgftB3h54KRlvwMJhaWqN/6HTTr+SEUcrkaRIDi3hpHF7HTqAVXL1/E+30HYvXGHVgc8C1yX7zAlPFjkJGRLjqacDw3hbOytoX3mM+w8rsdWPHdDri/1RwLpk3E/ahI0dFk4eCB/Vi62B9jPvXBrj174eLiirFjRiAxMVH6xeUYP1N/MzbQR8STNCw/WvBn5sHTDKwIjoT31kv49IeriEnOwvJ+brAwNijjpGKF7t+Nayd+Q/vBPvh4wXdo3W8EQg/swZWjv4iORjKnUKlUKtEhStvDZ9miI2hIevYUfbu3x4p1W+DeuKnoOLIip3OTnv1C6PELMui99hg2dgK69OgtNIejZUWhxweAwQP7oYFbQ0ybPhMAkJeXhy6d2mPQhx9jxKjRwnIlPOfvm8IM3HRe2LFPTWqbr9P4bxUN9XH481YYv/saQqOTyizboJbVy+xYBdm3cgYqmlVG5+F/fxfy72vmooKBEl1HfykwGeDTuoawY4feS9HavpvUMNPavssSO41lIC01FQBgamYuOIn88NwULDc3FyeDDyIzMwOubro9/AoAOdnZuHXzBlq0bKVep6enhxYtWuHqlcsCk8kPP1NFU0FPgV7udnie+QIR8ami45Qp+9r18eBWGJ7FPgQAxEdH4vGdG3Bq2ExwMpI7zmnUsry8PKxZ+TXc3BvDuVYd0XFkhecmv3uRdzD5U29kZ2fD2NgYX81fBscatUTHEu5Z0jPk5ubC0tJSY72lpSWiou4KSiU//ExJa1WzCmb3cIWRgR4SU7Mx8adrSM6Q3yiDNjV9dwCyM9Kx7auR0NPTQ15eHlr2GQrXlm+LjiYUZzRKk1XRmJaWht27dyMiIgL29vYYNGhQvj8S/5aVlYWsrKx/rVNAqVRqM2qRBSxZgHuREVj1baDoKLLDc5NfVccaWLVpF9LTUnH6xFGsWDgT/t9sZOFIRcLPlLRLD5Iw7PtLsDA2QE93O8ztWQ+jd4QhKT1HdLQyc+fPkwg/dwzdRk9FlapOiI+OxB8/rEclC0vUa/2O6HjisGqUJHR4un79+nj69CkA4MGDB3Bzc8PEiRNx5MgRzJo1C/Xr10dUVNRr9+Hv7w9zc3ONZc2KxWURX1LA0gU4dzoEy9ZugrWNneg4ssJzUzADAwM4VHNEbZf68B7zOZxr18W+PT+IjiVcZYvK0NfXz3fRS2JiIqysrASlkhd+poomMycPj5IycSPmORYduoPcPBV6uNmKjlWmTu3+Dk3eHYC6nh1gVc0Z9Vp1RqMufXDx99d/fR2R0KLx9u3bePHi5bCAn58fHBwccP/+fVy4cAH379+Hu7s7vvrqq9fuw8/PD8nJyRqLz8QpZRG/UCqVCgFLF+BUyDEsXb0J9g7VhOaRE56b4lHlqZCTI68LLUQwMDREvfoNcP7cWfW6vLw8nD9/Fu4ejQUmE4+fqf9GTwEYVtCt6f0vsrOg0NNsqyn09FAOr4stFoUW/ykvZDM8ffbsWaxfvx7m5i8nb1eqVAlz5szBwIEDX/s6pVKZbyg6JVfsH9mAJQsQfHg/5i1ehYomJniamAAAMDGpBKWRkdBsovHcFC5wQwCaeLaGta09MtLTEHL0AK6FXcScpWtFR5OFj72HYca0L9GggRvcGrpj+7ZAZGRkwKt3H9HRhOJn6m/GBnqoamGsfmxvrkRtaxM8z3yB5MwcDPGsjtORT5GQlg0LYwP0aWQPq0pKHA9PEJi67Dk3aoE/f9sF0yo2sKzqhPj7kbh86Gc0aNtFdDSSOaG33NHT00NcXBysra1RtWpVHDp0CG5uburn79+/D1dXV2RkZBRrv6JvudOpRcMC10+ePg/deniVbRiZkfO5EX3LnYBFs3Hl0gU8TUyAiUkl1KhVB30/HIbGzVoIzQXI45Y7APDDju3qm3u7uNbDl9Omw93dQ2gm0bfckfNnqqxvudO4ujm+GZD/bgP7r8dh6ZE7mPWeK+rbm8Lc2AApmTm4FZuKwHPRuB1btldPi77lTnZGOs7tDUTk5TNIT0mCiYUlXDw7oPn7g6FfQew9K0XecicsWns3eW/kaKq1fZcl4UWjm5sbKlSogDt37mDr1q3o27ev+vmTJ0/iww8/xMOHD4u1X9FFI72ZRBeNciaXolGORBeNcibyPo1yJrpolDMWjfImdHh61qxZGo8rVaqk8fjXX39F27ZtyzISERER6aDyM/NQe2RVNP7bkiVLyigJEREREb2ObC6EISIiIhKGrUZJLBqJiIhI55WnW+Noi27dnIqIiIiISoSdRiIiItJ5CjYaJbHTSERERESS2GkkIiIincdGozR2GomIiIhIEjuNRERERGw1SmKnkYiIiIgksdNIREREOo/3aZTGTiMRERERSWKnkYiIiHQe79MojUUjERER6TzWjNI4PE1EREREkthpJCIiImKrURI7jUREREQkiZ1GIiIi0nm85Y40dhqJiIiISBI7jURERKTzeMsdaew0EhEREZEkdhqJiIhI57HRKI1FIxERERGrRkkcniYiIiIiSew0EhERkc7jLXeksdNIRERERJLYaSQiIiKdx1vuSFOoVCqV6BCl7eGzbNERZMtEqS86gmzFP88SHUG2rE2VoiPQG+j24+eiI8jS28OWi44gWxl/zBV27IgnGVrbd20bY63tuyyx00hEREQ6j41GaZzTSERERESS2GkkIiIiYqtREjuNREREpPMUWvynOPz9/dGsWTOYmprCxsYGXl5eCA8Pf+1rtm7dCoVCobEYGRn9l9NRIBaNRERERDIREhICHx8fnDt3DkeOHEFOTg66dOmCtLS0177OzMwMMTEx6uX+/fulno3D00RERKTz5HLLnYMHD2o83rp1K2xsbBAaGop27doV+jqFQgE7OzutZmOnkYiIiEiLsrKykJKSorFkZRXtNm/JyckAgCpVqrx2u9TUVDg5OaF69ero1asXbty48Z9z/xuLRiIiItJ5Ci0u/v7+MDc311j8/f0lM+Xl5WHChAlo3bo13NzcCt3OxcUFmzdvxi+//ILt27cjLy8PrVq1wsOHD0t0LgrDm3vrGN7cu3C8uXfheHNvKgne3LtgvLl34UTe3PteQqbW9m1vqsjXWVQqlVAqX/+7dezYsThw4ABOnTqFatWqFfl4OTk5qFevHgYNGoR58+aVKHNBOKeRiIiISItzGotSIP7buHHj8Ntvv+HkyZPFKhgBwMDAAI0bN0ZERESxXieFw9NEREREMqFSqTBu3Djs3bsXx44dg7Ozc7H3kZubi2vXrsHe3r5Us7HTSERERDqvuPdT1BYfHx/s3LkTv/zyC0xNTREbGwsAMDc3h7Hxy++wHjJkCKpWraqeFzl37ly0aNECtWvXRlJSEpYsWYL79+9j5MiRpZqNRSMRERHpPLnccmfdunUAgA4dOmis37JlC4YOHQoAiI6Ohp7e34PFz549w6hRoxAbG4vKlSujSZMmOHPmDOrXr1+q2XghjI7hhTCF44UwheOFMFQSvBCmYLwQpnAiL4SJfqq9vwGOVcrH71B2GomIiEjnyaTRKGu8EIaIiIiIJLHTSERERDpPLnMa5YydRiIiIiKSxE4jEREREWc1SmKnkYiIiIgksdNIREREOo9zGqWxaCQiIiKdx5pRGoeniYiIiEgSO41ERESk8zg8LY2dRiIiIiKSxE4jERER6TwFZzVKYtGoBTsDN+LUiaOIvh8FpdII9Rt6YLTPRFR3chYdTRYuh17E9u83I/zmDSQkxOPr5QFo37Gz6FjC7Q/ajQNBPyEu9jEAwNG5JgZ6j0bTFm0EJxOP75nC8dwUbu+O7/DLzo0a6+yqOWHRht2CEonT2sMJEwe1wVsu9rC3MkP/aTvx6x+31c/bVDbB/LFd0LlZLZhXMsKpK/fhu/J3RD58KjA1yQ2Hp7Xg6uWLeL/vQKzeuAOLA75F7osXmDJ+DDIy0kVHk4WMjHTUqeuCSX4zREeRFStrW3iP+Qwrv9uBFd/tgPtbzbFg2kTcj4oUHU04vmcKx3PzelWdamLltv3q5avF34qOJISJkSGuRcRiwvLfC3x+98IP4WxfGf38dqLF8HWIjk3C/hVDUdHIoIyTCqTQ4lJOsNOoBYtWrtd4PGXGfPTt3h53bt+Ee+OmglLJR6s27dCqTTvRMWSneev2Go+HjBqHA0F7EH7jKpycawlKJQ98zxSO5+b19PT0YVHFUnQM4Q6fv4PD5+8U+Fzt6pbwdKuOtz7+BrfuxQMAPl/2G+79Mhn9OzfE1t8ulWVUkjEWjWUgLTUVAGBqZi44Cb0pcnNzcfrEEWRmZsDVzV10HKI3VtzjB5jw8XswMDBErXoN0c/7U1ja2ImOJStKA30AQGb2C/U6lUqF7OxctHJ30pmisRw1BLWGRaOW5eXlYc3Kr+Hm3hjOteqIjkMydy/yDiZ/6o3s7GwYGxvjq/nL4FhDt7uMRCVVy6UBRk6cCftqjkh6mohfdm7EwiljMH/tThhXNBEdTzbC7ycgOjYJ88a8g3FL9iEtMwef92+JarbmsLM0FR2vzPCWO9KEzmm8dOkSoqKi1I+3bduG1q1bo3r16mjTpg127doluY+srCykpKRoLFlZWdqMXSwBSxbgXmQEps9fLDoKvQGqOtbAqk27sGz99+jeqx9WLJyJ6Huc00hUEu5NW6F5206o7lwHDZu0wMQ5K5Ce9hwX/ggWHU1WXuTmYeBXP6B2dUvEHJiGp0emo91bzjh49i/k5alExyMZEVo0Dhs2DJGRL/8gbty4EWPGjEHTpk3x1VdfoVmzZhg1ahQ2b9782n34+/vD3NxcY1mzQh4FWsDSBTh3OgTL1m6CNYdDqAgMDAzgUM0RtV3qw3vM53CuXRf79vwgOhZRuWBSyRR2VR3xJOaB6Ciyc/mvGLQYvg623RbAufcS9Jq0DZbmFRH1WHeunlZo8Z/yQujw9J07d1Cnzssh27Vr12LVqlUYNWqU+vlmzZphwYIFGD58eKH78PPzg6+vr8a6+HSx/4FUKhW+WbYQp0KOYfmazbB3qCY0D725VHkq5ORki45BVC5kZqTjScwjtHq7u+gospWS9nKkrla1KnjLxQFzNrIrS38TWjRWrFgRCQkJcHJywqNHj9C8eXON5z09PTWGrwuiVCqhVCo11qXkiv0jG7BkAYIP78e8xatQ0cQETxMTAAAmJpWgNDISmk0O0tPT8PBBtPrx40eP8Ff4LZiZmcPO3kFgMrECNwSgiWdrWNvaIyM9DSFHD+Ba2EXMWbpWdDTh+J4pHM9N4XZtXIVGnm1haWOHpMQEBO34Dnp6evBs30V0tDJnYmyIWlWrqB/XsK8M99p2eJaSgQdPktGnQwPEJ6XhQVwy3GrZYunn3fHrH7cQ/KcOTY8pPw1BrVGoVCphExY+/vhjKJVKbNy4Ef3794eLiwvmzZunft7f3x8//PADrl69Wqz9Pnwmtmjs1KJhgesnT5+Hbj28yjbMv5go9YUeHwBCL16Az6ih+da/29MLM+cuLPtA/y/+udi5sAGLZuPKpQt4mpgAE5NKqFGrDvp+OAyNm7UQmgsArE2V0htpkVzfM3Ig53Nz+/Fzocdf+/VX+Ot6GFJTkmFqboE6DTzwwZCxsLEXO/rz9rDlZX7Mto1q4PA3+Uftth24jNEL9+LTvp6YOKgNbKqYIDYxFTsOhsE/MAQ5L3LLNGfGH3PL9Hj/FJ/6QnqjErKuVD6uOxZaND5+/BitW7eGo6MjmjZtinXr1qFJkyaoV68ewsPDce7cOezduxfvvvtusfYrumiUMzkUjXIlumiUM9FFI72ZRBeNciWiaHxTiCwaE7RYNFqVk6JR6IUwDg4OuHz5Mlq2bImDBw9CpVLhwoULOHz4MKpVq4bTp08Xu2AkIiIiotInvPS1sLDAokWLsGjRItFRiIiISEfxPo3ShBeNRERERKKVp1vjaIvQ4WkiIiIiejOw00hEREQ6j8PT0thpJCIiIiJJLBqJiIiISBKLRiIiIiKSxDmNREREpPM4p1EaO41EREREJImdRiIiItJ5vE+jNBaNREREpPM4PC2Nw9NEREREJImdRiIiItJ5bDRKY6eRiIiIiCSx00hERETEVqMkdhqJiIiISBI7jURERKTzeMsdaew0EhEREZEkdhqJiIhI5/E+jdLYaSQiIiIiSew0EhERkc5jo1Eai0YiIiIiVo2SODxNRERERJJYNBIREZHOU2jxn5JYs2YNatSoASMjI3h6euLChQuv3X7Pnj1wdXWFkZERGjZsiP3795fouK/DopGIiIhIRn788Uf4+vpi1qxZuHTpEjw8PNC1a1c8efKkwO3PnDmDQYMGYcSIEbh8+TK8vLzg5eWF69evl2ouhUqlUpXqHmXg4bNs0RFky0SpLzqCbMU/zxIdQbasTZWiI9Ab6Pbj56IjyNLbw5aLjiBbGX/MFXbszBfa27dRMa8g8fT0RLNmzbB69WoAQF5eHqpXr47PPvsMU6dOzbf9gAEDkJaWht9++029rkWLFmjUqBHWr1//n7L/EzuNRERERFqUlZWFlJQUjSUrq+BGRXZ2NkJDQ9G5c2f1Oj09PXTu3Blnz54t8DVnz57V2B4AunbtWuj2JaYircrMzFTNmjVLlZmZKTqK7PDcFIznpXA8N4XjuSkcz03heG7KxqxZs1QANJZZs2YVuO2jR49UAFRnzpzRWD958mRV8+bNC3yNgYGBaufOnRrr1qxZo7KxsSmV/K+Uy+FpOUlJSYG5uTmSk5NhZmYmOo6s8NwUjOelcDw3heO5KRzPTeF4bspGVlZWvs6iUqmEUpl/6s/jx49RtWpVnDlzBi1btlSvnzJlCkJCQnD+/Pl8rzE0NERgYCAGDRqkXrd27VrMmTMHcXFxpfZz8D6NRERERFpUWIFYECsrK+jr6+cr9uLi4mBnZ1fga+zs7Iq1fUlxTiMRERGRTBgaGqJJkyYIDg5Wr8vLy0NwcLBG5/GfWrZsqbE9ABw5cqTQ7UuKnUYiIiIiGfH19YW3tzeaNm2K5s2bY+XKlUhLS8OwYcMAAEOGDEHVqlXh7+8PABg/fjzat2+PZcuW4b333sOuXbtw8eJFfPvtt6Wai0WjlimVSsyaNavIbWldwnNTMJ6XwvHcFI7npnA8N4XjuZGnAQMGID4+HjNnzkRsbCwaNWqEgwcPwtbWFgAQHR0NPb2/B4tbtWqFnTt3Yvr06Zg2bRrq1KmDoKAguLm5lWouXghDRERERJI4p5GIiIiIJLFoJCIiIiJJLBqJiIiISBKLRiIiIiKSxKJRi9asWYMaNWrAyMgInp6euHDhguhIsnDy5En07NkTDg4OUCgUCAoKEh1JFvz9/dGsWTOYmprCxsYGXl5eCA8PFx1LFtatWwd3d3eYmZnBzMwMLVu2xIEDB0THkp1FixZBoVBgwoQJoqPIwuzZs6FQKDQWV1dX0bFk4dGjR/joo49gaWkJY2NjNGzYEBcvXhQdi2SORaOW/Pjjj/D19cWsWbNw6dIleHh4oGvXrnjy5InoaMKlpaXBw8MDa9asER1FVkJCQuDj44Nz587hyJEjyMnJQZcuXZCWliY6mnDVqlXDokWLEBoaiosXL+Ltt99Gr169cOPGDdHRZOPPP//Ehg0b4O7uLjqKrDRo0AAxMTHq5dSpU6IjCffs2TO0bt0aBgYGOHDgAG7evIlly5ahcuXKoqORzPGWO1ri6emJZs2aYfXq1QBe3s29evXq+OyzzzB16lTB6eRDoVBg79698PLyEh1FduLj42FjY4OQkBC0a9dOdBzZqVKlCpYsWYIRI0aIjiJcamoq3nrrLaxduxbz589Ho0aNsHLlStGxhJs9ezaCgoIQFhYmOoqsTJ06FadPn8Yff/whOgq9Ydhp1ILs7GyEhoaic+fO6nV6enro3Lkzzp49KzAZvUmSk5MBvCyO6G+5ubnYtWsX0tLSSv0rst5UPj4+eO+99zR+59BLd+7cgYODA2rWrInBgwcjOjpadCTh9u3bh6ZNm6Jfv36wsbFB48aN8d1334mORW8AFo1akJCQgNzcXPWd21+xtbVFbGysoFT0JsnLy8OECRPQunXrUr+j/5vq2rVrqFSpEpRKJT755BPs3bsX9evXFx1LuF27duHSpUvqrxOjv3l6emLr1q04ePAg1q1bh6ioKLRt2xbPnz8XHU2ou3fvYt26dahTpw4OHTqEsWPH4vPPP0dgYKDoaCRz/BpBIhny8fHB9evXOf/qH1xcXBAWFobk5GT89NNP8Pb2RkhIiE4Xjg8ePMD48eNx5MgRGBkZiY4jO927d1f/u7u7Ozw9PeHk5ITdu3fr9LSGvLw8NG3aFAsXLgQANG7cGNevX8f69evh7e0tOB3JGTuNWmBlZQV9fX3ExcVprI+Li4OdnZ2gVPSmGDduHH777TccP34c1apVEx1HNgwNDVG7dm00adIE/v7+8PDwwKpVq0THEio0NBRPnjzBW2+9hQoVKqBChQoICQlBQEAAKlSogNzcXNERZcXCwgJ169ZFRESE6ChC2dvb5/ufrXr16nHoniSxaNQCQ0NDNGnSBMHBwep1eXl5CA4O5hwsKpRKpcK4ceOwd+9eHDt2DM7OzqIjyVpeXh6ysrJExxCqU6dOuHbtGsLCwtRL06ZNMXjwYISFhUFfX190RFlJTU1FZGQk7O3tRUcRqnXr1vlu5/XXX3/ByclJUCJ6U3B4Wkt8fX3h7e2Npk2bonnz5li5ciXS0tIwbNgw0dGES01N1fg//aioKISFhaFKlSpwdHQUmEwsHx8f7Ny5E7/88gtMTU3V81/Nzc1hbGwsOJ1Yfn5+6N69OxwdHfH8+XPs3LkTJ06cwKFDh0RHE8rU1DTfnFcTExNYWlpyLiyASZMmoWfPnnBycsLjx48xa9Ys6OvrY9CgQaKjCTVx4kS0atUKCxcuRP/+/XHhwgV8++23+Pbbb0VHI7lTkdZ88803KkdHR5WhoaGqefPmqnPnzomOJAvHjx9XAci3eHt7i44mVEHnBIBqy5YtoqMJN3z4cJWTk5PK0NBQZW1trerUqZPq8OHDomPJUvv27VXjx48XHUMWBgwYoLK3t1cZGhqqqlatqhowYIAqIiJCdCxZ+PXXX1Vubm4qpVKpcnV1VX377beiI9EbgPdpJCIiIiJJnNNIRERERJJYNBIRERGRJBaNRERERCSJRSMRERERSWLRSERERESSWDQSERERkSQWjUREREQkiUUjEREREUli0UhEsjV06FB4eXmpH3fo0AETJkwo8xwnTpyAQqFAUlJSmR+biEguWDQSUbENHToUCoUCCoUChoaGqF27NubOnYsXL15o9bg///wz5s2bV6RtWegREZWuCqIDENGbqVu3btiyZQuysrKwf/9++Pj4wMDAAH5+fhrbZWdnw9DQsFSOWaVKlVLZDxERFR87jURUIkqlEnZ2dnBycsLYsWPRuXNn7Nu3Tz2kvGDBAjg4OMDFxQUA8ODBA/Tv3x8WFhaoUqUKevXqhXv37qn3l5ubC19fX1hYWMDS0hJTpkyBSqXSOOa/h6ezsrLw5Zdfonr16lAqlahduzY2bdqEe/fuoWPHjgCAypUrQ6FQYOjQoQCAvLw8+Pv7w9nZGcbGxvDw8MBPP/2kcZz9+/ejbt26MDY2RseOHTVyEhHpKhaNRFQqjI2NkZ2dDQAIDg5GeHg4jhw5gt9++w05OTno2rUrTE1N8ccff+D06dOoVKkSunXrpn7NsmXLsHXrVmzevBmnTp3C06dPsXfv3tcec8iQIfjhhx8QEBCAW7duYcOGDahUqRKqV6+O//3vfwCA8PBwxMTEYNWqVQAAf39/fP/991i/fj1u3LiBiRMn4qOPPkJISAiAl8Vtnz590LNnT4SFhWHkyJGYOnWqtk4bEdEbg8PTRPSfqFQqBAcH49ChQ/jss88QHx8PExMTbNy4UT0svX37duTl5WHjxo1QKBQAgC1btsDCwgInTpxAly5dsHLlSvj5+aFPnz4AgPXr1+PQoUOFHvevv/7C7t27ceTIEXTu3BkAULNmTfXzr4aybWxsYGFhAeBlZ3LhwoU4evQoWrZsqX7NqVOnsGHDBrRv3x7r1q1DrVq1sGzZMgCAi4sLrl27hq+//roUzxoR0ZuHRSMRlchvv/2GSpUqIScnB3l5efjwww8xe/Zs+Pj4oGHDhhrzGK9cuYKIiAiYmppq7CMzMxORkZFITk5GTEwMPD091c9VqFABTZs2zTdE/UpYWBj09fXRvn37ImeOiIhAeno63nnnHY312dnZaNy4MQDg1q1bGjkAqAtMIiJdxqKRiEqkY8eOWLduHQwNDeHg4IAKFf7+dWJiYqKxbWpqKpo0aYIdO3bk24+1tXWJjm9sbFzs16SmpgIAfv/9d1StWlXjOaVSWaIcRES6gkUjEZWIiYkJateuXaRt33rrLfz444+wsbGBmZlZgdvY29vj/PnzaNeuHQDgxYsXCA0NxVtvvVXg9g0bNkReXh5CQkLUw9P/9KrTmZubq15Xv359KJVKREdHF9qhrFevHvbt26ex7ty5c9I/JBFROccLYYhI6wYPHgwrKyv06tULf/zxB6KionDixAl8/vnnePjwIQBg/PjxWLRoEYKCgnD79m18+umnr73HYo0aNeDt7Y3hw4cjKChIvc/du3cDAJycnKBQKPDbb78hPj4eqampMDU1xaRJkzBx4kQEBgYiMjISly5dwjfffIPAwEAAwCeffII7d+5g8uTJCA8Px86dO7F161ZtnyIiItlj0UhEWlexYkWcPHkSjo6O6NOnD+rVq4cRI0YgMzNT3Xn84osv8PHHH8Pb2xstW7aEqakpevfu/dr9rlu3Dh988AE+/fRTuLq6YtSoUUhLSwMAVK1aFXPmzMHUqVNha2uLcePGAQDmzZuHGTNmwN/fH/Xq1UO3bt3w+++/w9nZGQDg6OiI//3vfwgKCoKHhwfWr1+PhQsXavHsEBG9GRSqwmaZExERERH9P3YaiYiIiEgSi0YiIiIiksSikYiIiIgksWgkIiIiIkksGomIiIhIEotGIiIiIpLEopGIiIiIJLFoJCIiIiJJLBqJiIiISBKLRiIiIiKSxKKRiIiIiCT9H485P6swobnbAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.56      0.51        18\n",
            "           1       0.53      0.36      0.43        25\n",
            "           2       0.54      0.46      0.50        28\n",
            "           3       0.75      0.56      0.64        32\n",
            "           4       0.61      0.91      0.73        22\n",
            "           5       0.50      0.43      0.46        30\n",
            "           6       0.45      0.59      0.51        32\n",
            "\n",
            "    accuracy                           0.55       187\n",
            "   macro avg       0.55      0.55      0.54       187\n",
            "weighted avg       0.55      0.55      0.54       187\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(labels, preds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3DnLGSr659u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67cc373f-c194-49cf-fba6-01f13eeedc2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MotionLSTM(\n",
              "  (chan_att): ChannelAttention(\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=531, out_features=66, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=66, out_features=531, bias=True)\n",
              "      (3): Sigmoid()\n",
              "    )\n",
              "  )\n",
              "  (lstm): LSTM(531, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (temp_att): TemporalAttention(\n",
              "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.3, inplace=False)\n",
              "    (3): Linear(in_features=256, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_lstm.pth\", map_location=device))\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAbChLUjUJwR"
      },
      "source": [
        "Evaluation on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp1biUNa7Rt4"
      },
      "outputs": [],
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_dl:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(yb.cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0KBEjalUNo9"
      },
      "source": [
        "Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw2zYLZd7T2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa8dc335-a0c7-4bb2-dda8-2da0253da574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5385    0.3889    0.4516        18\n",
            "           1     0.5667    0.6800    0.6182        25\n",
            "           2     0.7273    0.2857    0.4103        28\n",
            "           3     0.6897    0.6250    0.6557        32\n",
            "           4     0.7037    0.8636    0.7755        22\n",
            "           5     0.6000    0.7000    0.6462        30\n",
            "           6     0.4524    0.5938    0.5135        32\n",
            "\n",
            "    accuracy                         0.5936       187\n",
            "   macro avg     0.6112    0.5910    0.5816       187\n",
            "weighted avg     0.6110    0.5936    0.5825       187\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(all_labels, all_preds, digits=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oA-C9ZhUQni"
      },
      "source": [
        "Overall Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sxSvUsT7WY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086c2258-76bb-4f63-aa42-f7125e0c1e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Validation Accuracy: 0.5935828877005348\n"
          ]
        }
      ],
      "source": [
        "acc = (np.array(all_labels) == np.array(all_preds)).mean()\n",
        "print(\"Final Validation Accuracy:\", acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmaClPpBUS8T"
      },
      "source": [
        "Per-Class Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VXVjuor7bBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c7eb50-3417-4645-ccf1-89ef11ff04bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: Accuracy = 0.389\n",
            "Class 1: Accuracy = 0.680\n",
            "Class 2: Accuracy = 0.286\n",
            "Class 3: Accuracy = 0.625\n",
            "Class 4: Accuracy = 0.864\n",
            "Class 5: Accuracy = 0.700\n",
            "Class 6: Accuracy = 0.594\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "labels = np.array(all_labels)\n",
        "preds = np.array(all_preds)\n",
        "\n",
        "unique_classes = np.unique(labels)\n",
        "\n",
        "for cl in unique_classes:\n",
        "    idx = labels == cl\n",
        "    class_acc = (labels[idx] == preds[idx]).mean()\n",
        "    print(f\"Class {cl}: Accuracy = {class_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Hv41PfUVQ5"
      },
      "source": [
        "Probability Inspection for Debugging\n",
        "\n",
        "\n",
        "This helps to check if the model is:\n",
        "\n",
        "Overconfident\n",
        "\n",
        "Always predicting one label\n",
        "\n",
        "Producing uniform probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIpNTDTX7dJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9172e6-8e64-4616-fe79-5c4d5c955a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities for first batch sample:\n",
            "[0.01628284 0.04607429 0.0465103  0.09521506 0.01394125 0.3978706\n",
            " 0.38410574]\n"
          ]
        }
      ],
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    xb, yb = next(iter(val_dl))\n",
        "    xb = xb.to(device)\n",
        "    probs = softmax(model(xb)).cpu().numpy()\n",
        "\n",
        "print(\"Probabilities for first batch sample:\")\n",
        "print(probs[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc_yOE4E7gCT"
      },
      "outputs": [],
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_dl:\n",
        "        xb = xb.to(device)\n",
        "        logits = model(xb)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(yb.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhJvC8N0UhcV"
      },
      "source": [
        "Final Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSG18U6n7tt7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b269f2-50f6-4aca-8b68-a17ecd7a7592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Validation Accuracy: 0.5935828877005348\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "final_acc = (np.array(all_preds) == np.array(all_labels)).mean()\n",
        "print(\"Final Validation Accuracy:\", final_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezAlxZDw7xz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c25176f-32c8-4eaf-cfd2-a6d94d9308ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label: 5\n",
            "Predicted Label: 5\n"
          ]
        }
      ],
      "source": [
        "idx = 0  # choose any index from validation set\n",
        "x = X_val[idx]  # numpy array\n",
        "y_true = y_val[idx]\n",
        "\n",
        "x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(device)  # (1,T,F)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(x_tensor)\n",
        "    pred = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "print(\"True Label:\", y_true)\n",
        "print(\"Predicted Label:\", pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 13: Baseline Model Testing"
      ],
      "metadata": {
        "id": "viFf1kt6TrNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross validation"
      ],
      "metadata": {
        "id": "1ZMB-wJ_mBZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 10. K-FOLD CROSS VALIDATION (REPLACES TRAIN/VAL SPLIT)\n",
        "# ===============================================================\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "K = 5  # number of folds\n",
        "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
        "\n",
        "fold_accuracies = []\n",
        "fold_reports = []\n",
        "fold_confusions = []\n",
        "\n",
        "def train_one_epoch(model, train_dl, optimizer, scheduler):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "\n",
        "    for xb, yb in train_dl:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        xb_mix, y_a, y_b, lam = mixup_data(xb, yb)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb_mix)\n",
        "        loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    return running_loss / len(train_dl.dataset)\n",
        "\n",
        "def eval_model(model, val_dl):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_dl:\n",
        "            xb = xb.to(device)\n",
        "            logits = model(xb)\n",
        "            pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            preds.extend(pred)\n",
        "            labels.extend(yb.numpy())\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return acc, preds, labels\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# K-FOLD LOOP\n",
        "# ------------------------------\n",
        "fold = 1\n",
        "for train_idx, val_idx in skf.split(X_lstm, labels_arr):\n",
        "    print(f\"\\n============================\")\n",
        "    print(f\"â–¶ FOLD {fold}/{K}\")\n",
        "    print(f\"============================\\n\")\n",
        "\n",
        "    # Build dataset for this fold\n",
        "    X_train, X_val = X_lstm[train_idx], X_lstm[val_idx]\n",
        "    y_train, y_val = labels_arr[train_idx], labels_arr[val_idx]\n",
        "\n",
        "    train_ds = LSTMDataset(X_train, y_train, V, training=True)\n",
        "    val_ds   = LSTMDataset(X_val, y_val, V, training=False)\n",
        "\n",
        "    train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "    val_dl   = DataLoader(val_ds, batch_size=32)\n",
        "\n",
        "    # Reinitialize a fresh model for each fold\n",
        "    model = MotionLSTM(\n",
        "        input_dim=9*V,\n",
        "        hidden_dim=256,\n",
        "        num_layers=2,\n",
        "        num_classes=len(np.unique(labels_arr)),\n",
        "        dropout=0.5\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
        "    )\n",
        "\n",
        "    best_acc = 0\n",
        "    EPOCHS = 40  # use fewer epochs because we train K times\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        loss = train_one_epoch(model, train_dl, optimizer, scheduler)\n",
        "        acc, preds, labels = eval_model(model, val_dl)\n",
        "        print(f\"Fold {fold} | Epoch {epoch+1}/{EPOCHS} | Loss {loss:.4f} | Val Acc {acc:.4f}\")\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_preds = preds\n",
        "            best_labels = labels\n",
        "\n",
        "    print(f\"\\nâœ” Best Accuracy for Fold {fold}: {best_acc:.4f}\")\n",
        "\n",
        "    # Save results\n",
        "    fold_accuracies.append(best_acc)\n",
        "    fold_reports.append(classification_report(best_labels, best_preds, output_dict=True))\n",
        "    fold_confusions.append(confusion_matrix(best_labels, best_preds))\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# 11. SUMMARY OF RESULTS\n",
        "# ===============================================================\n",
        "\n",
        "print(\"\\n==========================================\")\n",
        "print(\"K-FOLD CROSS VALIDATION SUMMARY\")\n",
        "print(\"==========================================\\n\")\n",
        "\n",
        "print(\"Accuracies per fold:\", fold_accuracies)\n",
        "print(\"Mean Accuracy:\", np.mean(fold_accuracies))\n",
        "print(\"Std Dev:\", np.std(fold_accuracies))\n",
        "\n",
        "print(\"\\nFinal Classification Report (averaged):\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Average F1-scores across folds\n",
        "all_reports = fold_reports\n",
        "classes = list(all_reports[0].keys())[:-3]  # skip accuracy, macro avg, weighted avg\n",
        "\n",
        "avg_report = {}\n",
        "\n",
        "for cls in classes:\n",
        "    p = np.mean([r[cls][\"precision\"] for r in all_reports])\n",
        "    r = np.mean([r[cls][\"recall\"] for r in all_reports])\n",
        "    f1 = np.mean([r[cls][\"f1-score\"] for r in all_reports])\n",
        "    avg_report[cls] = {\"precision\": p, \"recall\": r, \"f1-score\": f1}\n",
        "\n",
        "print(json.dumps(avg_report, indent=4))\n"
      ],
      "metadata": {
        "id": "qDOYRqWo_Pvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b07c0ccc-2d61-42ae-933d-48f5f3bb4eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================\n",
            "â–¶ FOLD 1/5\n",
            "============================\n",
            "\n",
            "Fold 1 | Epoch 1/40 | Loss 1.9439 | Val Acc 0.1872\n",
            "Fold 1 | Epoch 2/40 | Loss 1.9328 | Val Acc 0.2299\n",
            "Fold 1 | Epoch 3/40 | Loss 1.9025 | Val Acc 0.2513\n",
            "Fold 1 | Epoch 4/40 | Loss 1.8830 | Val Acc 0.2567\n",
            "Fold 1 | Epoch 5/40 | Loss 1.7946 | Val Acc 0.2620\n",
            "Fold 1 | Epoch 6/40 | Loss 1.7486 | Val Acc 0.2513\n",
            "Fold 1 | Epoch 7/40 | Loss 1.8028 | Val Acc 0.2674\n",
            "Fold 1 | Epoch 8/40 | Loss 1.7417 | Val Acc 0.3316\n",
            "Fold 1 | Epoch 9/40 | Loss 1.5647 | Val Acc 0.3369\n",
            "Fold 1 | Epoch 10/40 | Loss 1.5267 | Val Acc 0.3797\n",
            "Fold 1 | Epoch 11/40 | Loss 1.4968 | Val Acc 0.3904\n",
            "Fold 1 | Epoch 12/40 | Loss 1.4511 | Val Acc 0.4225\n",
            "Fold 1 | Epoch 13/40 | Loss 1.4492 | Val Acc 0.3743\n",
            "Fold 1 | Epoch 14/40 | Loss 1.5190 | Val Acc 0.3904\n",
            "Fold 1 | Epoch 15/40 | Loss 1.5011 | Val Acc 0.4759\n",
            "Fold 1 | Epoch 16/40 | Loss 1.4892 | Val Acc 0.4439\n",
            "Fold 1 | Epoch 17/40 | Loss 1.4562 | Val Acc 0.4225\n",
            "Fold 1 | Epoch 18/40 | Loss 1.3609 | Val Acc 0.4813\n",
            "Fold 1 | Epoch 19/40 | Loss 1.2785 | Val Acc 0.5027\n",
            "Fold 1 | Epoch 20/40 | Loss 1.1782 | Val Acc 0.5348\n",
            "Fold 1 | Epoch 21/40 | Loss 1.0503 | Val Acc 0.5348\n",
            "Fold 1 | Epoch 22/40 | Loss 1.0427 | Val Acc 0.5561\n",
            "Fold 1 | Epoch 23/40 | Loss 0.9894 | Val Acc 0.5668\n",
            "Fold 1 | Epoch 24/40 | Loss 1.1394 | Val Acc 0.5455\n",
            "Fold 1 | Epoch 25/40 | Loss 0.9492 | Val Acc 0.5668\n",
            "Fold 1 | Epoch 26/40 | Loss 0.9140 | Val Acc 0.5561\n",
            "Fold 1 | Epoch 27/40 | Loss 0.9714 | Val Acc 0.5027\n",
            "Fold 1 | Epoch 28/40 | Loss 1.1423 | Val Acc 0.4920\n",
            "Fold 1 | Epoch 29/40 | Loss 1.0482 | Val Acc 0.5455\n",
            "Fold 1 | Epoch 30/40 | Loss 0.9308 | Val Acc 0.5508\n",
            "Fold 1 | Epoch 31/40 | Loss 0.9470 | Val Acc 0.5615\n",
            "Fold 1 | Epoch 32/40 | Loss 0.9114 | Val Acc 0.5455\n",
            "Fold 1 | Epoch 33/40 | Loss 0.9665 | Val Acc 0.5241\n",
            "Fold 1 | Epoch 34/40 | Loss 0.7444 | Val Acc 0.5561\n",
            "Fold 1 | Epoch 35/40 | Loss 0.5757 | Val Acc 0.5401\n",
            "Fold 1 | Epoch 36/40 | Loss 0.7373 | Val Acc 0.5455\n",
            "Fold 1 | Epoch 37/40 | Loss 0.6585 | Val Acc 0.5615\n",
            "Fold 1 | Epoch 38/40 | Loss 0.7957 | Val Acc 0.5615\n",
            "Fold 1 | Epoch 39/40 | Loss 0.5450 | Val Acc 0.6096\n",
            "Fold 1 | Epoch 40/40 | Loss 0.5040 | Val Acc 0.5882\n",
            "\n",
            "âœ” Best Accuracy for Fold 1: 0.6096\n",
            "\n",
            "============================\n",
            "â–¶ FOLD 2/5\n",
            "============================\n",
            "\n",
            "Fold 2 | Epoch 1/40 | Loss 1.9408 | Val Acc 0.1551\n",
            "Fold 2 | Epoch 2/40 | Loss 1.9147 | Val Acc 0.1872\n",
            "Fold 2 | Epoch 3/40 | Loss 1.8694 | Val Acc 0.2139\n",
            "Fold 2 | Epoch 4/40 | Loss 1.8851 | Val Acc 0.2246\n",
            "Fold 2 | Epoch 5/40 | Loss 1.8078 | Val Acc 0.2674\n",
            "Fold 2 | Epoch 6/40 | Loss 1.7842 | Val Acc 0.2781\n",
            "Fold 2 | Epoch 7/40 | Loss 1.7956 | Val Acc 0.2567\n",
            "Fold 2 | Epoch 8/40 | Loss 1.7764 | Val Acc 0.2888\n",
            "Fold 2 | Epoch 9/40 | Loss 1.6861 | Val Acc 0.3743\n",
            "Fold 2 | Epoch 10/40 | Loss 1.5839 | Val Acc 0.3743\n",
            "Fold 2 | Epoch 11/40 | Loss 1.5445 | Val Acc 0.3743\n",
            "Fold 2 | Epoch 12/40 | Loss 1.4874 | Val Acc 0.3850\n",
            "Fold 2 | Epoch 13/40 | Loss 1.4888 | Val Acc 0.3529\n",
            "Fold 2 | Epoch 14/40 | Loss 1.5717 | Val Acc 0.4225\n",
            "Fold 2 | Epoch 15/40 | Loss 1.4819 | Val Acc 0.4385\n",
            "Fold 2 | Epoch 16/40 | Loss 1.4550 | Val Acc 0.4332\n",
            "Fold 2 | Epoch 17/40 | Loss 1.3719 | Val Acc 0.5027\n",
            "Fold 2 | Epoch 18/40 | Loss 1.3515 | Val Acc 0.4118\n",
            "Fold 2 | Epoch 19/40 | Loss 1.2818 | Val Acc 0.4706\n",
            "Fold 2 | Epoch 20/40 | Loss 1.1705 | Val Acc 0.4706\n",
            "Fold 2 | Epoch 21/40 | Loss 1.1790 | Val Acc 0.5187\n",
            "Fold 2 | Epoch 22/40 | Loss 1.0294 | Val Acc 0.5455\n",
            "Fold 2 | Epoch 23/40 | Loss 1.0531 | Val Acc 0.5401\n",
            "Fold 2 | Epoch 24/40 | Loss 0.8273 | Val Acc 0.5615\n",
            "Fold 2 | Epoch 25/40 | Loss 0.8810 | Val Acc 0.5455\n",
            "Fold 2 | Epoch 26/40 | Loss 0.8325 | Val Acc 0.5401\n",
            "Fold 2 | Epoch 27/40 | Loss 0.9910 | Val Acc 0.5187\n",
            "Fold 2 | Epoch 28/40 | Loss 1.1451 | Val Acc 0.5187\n",
            "Fold 2 | Epoch 29/40 | Loss 0.9431 | Val Acc 0.4973\n",
            "Fold 2 | Epoch 30/40 | Loss 0.9006 | Val Acc 0.5775\n",
            "Fold 2 | Epoch 31/40 | Loss 0.8351 | Val Acc 0.5455\n",
            "Fold 2 | Epoch 32/40 | Loss 0.8261 | Val Acc 0.5348\n",
            "Fold 2 | Epoch 33/40 | Loss 0.8066 | Val Acc 0.5134\n",
            "Fold 2 | Epoch 34/40 | Loss 0.6661 | Val Acc 0.5027\n",
            "Fold 2 | Epoch 35/40 | Loss 0.6393 | Val Acc 0.5561\n",
            "Fold 2 | Epoch 36/40 | Loss 0.8541 | Val Acc 0.5241\n",
            "Fold 2 | Epoch 37/40 | Loss 0.5838 | Val Acc 0.5401\n",
            "Fold 2 | Epoch 38/40 | Loss 0.6382 | Val Acc 0.5187\n",
            "Fold 2 | Epoch 39/40 | Loss 0.8048 | Val Acc 0.5508\n",
            "Fold 2 | Epoch 40/40 | Loss 0.6135 | Val Acc 0.5134\n",
            "\n",
            "âœ” Best Accuracy for Fold 2: 0.5775\n",
            "\n",
            "============================\n",
            "â–¶ FOLD 3/5\n",
            "============================\n",
            "\n",
            "Fold 3 | Epoch 1/40 | Loss 1.9415 | Val Acc 0.1613\n",
            "Fold 3 | Epoch 2/40 | Loss 1.9274 | Val Acc 0.1935\n",
            "Fold 3 | Epoch 3/40 | Loss 1.9099 | Val Acc 0.1989\n",
            "Fold 3 | Epoch 4/40 | Loss 1.9030 | Val Acc 0.2204\n",
            "Fold 3 | Epoch 5/40 | Loss 1.8941 | Val Acc 0.2473\n",
            "Fold 3 | Epoch 6/40 | Loss 1.8161 | Val Acc 0.2849\n",
            "Fold 3 | Epoch 7/40 | Loss 1.8094 | Val Acc 0.2903\n",
            "Fold 3 | Epoch 8/40 | Loss 1.7706 | Val Acc 0.3065\n",
            "Fold 3 | Epoch 9/40 | Loss 1.7151 | Val Acc 0.3118\n",
            "Fold 3 | Epoch 10/40 | Loss 1.6225 | Val Acc 0.3441\n",
            "Fold 3 | Epoch 11/40 | Loss 1.5517 | Val Acc 0.3602\n",
            "Fold 3 | Epoch 12/40 | Loss 1.5950 | Val Acc 0.3763\n",
            "Fold 3 | Epoch 13/40 | Loss 1.4928 | Val Acc 0.3763\n",
            "Fold 3 | Epoch 14/40 | Loss 1.5430 | Val Acc 0.3441\n",
            "Fold 3 | Epoch 15/40 | Loss 1.5599 | Val Acc 0.3978\n",
            "Fold 3 | Epoch 16/40 | Loss 1.4571 | Val Acc 0.3656\n",
            "Fold 3 | Epoch 17/40 | Loss 1.4624 | Val Acc 0.4409\n",
            "Fold 3 | Epoch 18/40 | Loss 1.2867 | Val Acc 0.4194\n",
            "Fold 3 | Epoch 19/40 | Loss 1.1815 | Val Acc 0.4785\n",
            "Fold 3 | Epoch 20/40 | Loss 1.1297 | Val Acc 0.5054\n",
            "Fold 3 | Epoch 21/40 | Loss 1.0709 | Val Acc 0.5000\n",
            "Fold 3 | Epoch 22/40 | Loss 0.9375 | Val Acc 0.4892\n",
            "Fold 3 | Epoch 23/40 | Loss 1.0402 | Val Acc 0.5108\n",
            "Fold 3 | Epoch 24/40 | Loss 0.8417 | Val Acc 0.5215\n",
            "Fold 3 | Epoch 25/40 | Loss 0.8522 | Val Acc 0.5215\n",
            "Fold 3 | Epoch 26/40 | Loss 0.8594 | Val Acc 0.5323\n",
            "Fold 3 | Epoch 27/40 | Loss 1.1060 | Val Acc 0.4301\n",
            "Fold 3 | Epoch 28/40 | Loss 1.0865 | Val Acc 0.4839\n",
            "Fold 3 | Epoch 29/40 | Loss 1.0410 | Val Acc 0.4946\n",
            "Fold 3 | Epoch 30/40 | Loss 1.0222 | Val Acc 0.5161\n",
            "Fold 3 | Epoch 31/40 | Loss 0.9873 | Val Acc 0.4785\n",
            "Fold 3 | Epoch 32/40 | Loss 0.9515 | Val Acc 0.5000\n",
            "Fold 3 | Epoch 33/40 | Loss 0.8549 | Val Acc 0.5000\n",
            "Fold 3 | Epoch 34/40 | Loss 0.8673 | Val Acc 0.4892\n",
            "Fold 3 | Epoch 35/40 | Loss 0.8406 | Val Acc 0.4409\n",
            "Fold 3 | Epoch 36/40 | Loss 0.7099 | Val Acc 0.5161\n",
            "Fold 3 | Epoch 37/40 | Loss 0.6743 | Val Acc 0.4892\n",
            "Fold 3 | Epoch 38/40 | Loss 0.6524 | Val Acc 0.5323\n",
            "Fold 3 | Epoch 39/40 | Loss 0.6756 | Val Acc 0.5484\n",
            "Fold 3 | Epoch 40/40 | Loss 0.6352 | Val Acc 0.5269\n",
            "\n",
            "âœ” Best Accuracy for Fold 3: 0.5484\n",
            "\n",
            "============================\n",
            "â–¶ FOLD 4/5\n",
            "============================\n",
            "\n",
            "Fold 4 | Epoch 1/40 | Loss 1.9403 | Val Acc 0.2258\n",
            "Fold 4 | Epoch 2/40 | Loss 1.9291 | Val Acc 0.2204\n",
            "Fold 4 | Epoch 3/40 | Loss 1.9061 | Val Acc 0.1774\n",
            "Fold 4 | Epoch 4/40 | Loss 1.9050 | Val Acc 0.1720\n",
            "Fold 4 | Epoch 5/40 | Loss 1.8862 | Val Acc 0.2473\n",
            "Fold 4 | Epoch 6/40 | Loss 1.8257 | Val Acc 0.2634\n",
            "Fold 4 | Epoch 7/40 | Loss 1.8337 | Val Acc 0.2527\n",
            "Fold 4 | Epoch 8/40 | Loss 1.8224 | Val Acc 0.3172\n",
            "Fold 4 | Epoch 9/40 | Loss 1.7385 | Val Acc 0.3441\n",
            "Fold 4 | Epoch 10/40 | Loss 1.6483 | Val Acc 0.3656\n",
            "Fold 4 | Epoch 11/40 | Loss 1.5424 | Val Acc 0.4086\n",
            "Fold 4 | Epoch 12/40 | Loss 1.4840 | Val Acc 0.4032\n",
            "Fold 4 | Epoch 13/40 | Loss 1.4354 | Val Acc 0.3871\n",
            "Fold 4 | Epoch 14/40 | Loss 1.5202 | Val Acc 0.3656\n",
            "Fold 4 | Epoch 15/40 | Loss 1.4893 | Val Acc 0.3763\n",
            "Fold 4 | Epoch 16/40 | Loss 1.4238 | Val Acc 0.3817\n",
            "Fold 4 | Epoch 17/40 | Loss 1.4341 | Val Acc 0.3602\n",
            "Fold 4 | Epoch 18/40 | Loss 1.2286 | Val Acc 0.4086\n",
            "Fold 4 | Epoch 19/40 | Loss 1.2511 | Val Acc 0.4355\n",
            "Fold 4 | Epoch 20/40 | Loss 1.2408 | Val Acc 0.4677\n",
            "Fold 4 | Epoch 21/40 | Loss 0.9921 | Val Acc 0.4462\n",
            "Fold 4 | Epoch 22/40 | Loss 0.9727 | Val Acc 0.5108\n",
            "Fold 4 | Epoch 23/40 | Loss 0.9596 | Val Acc 0.4785\n",
            "Fold 4 | Epoch 24/40 | Loss 0.8366 | Val Acc 0.5054\n",
            "Fold 4 | Epoch 25/40 | Loss 1.1498 | Val Acc 0.5161\n",
            "Fold 4 | Epoch 26/40 | Loss 0.8497 | Val Acc 0.5054\n",
            "Fold 4 | Epoch 27/40 | Loss 1.1276 | Val Acc 0.5054\n",
            "Fold 4 | Epoch 28/40 | Loss 1.0502 | Val Acc 0.4624\n",
            "Fold 4 | Epoch 29/40 | Loss 1.0914 | Val Acc 0.5000\n",
            "Fold 4 | Epoch 30/40 | Loss 1.0489 | Val Acc 0.4731\n",
            "Fold 4 | Epoch 31/40 | Loss 0.9775 | Val Acc 0.4946\n",
            "Fold 4 | Epoch 32/40 | Loss 0.9142 | Val Acc 0.5538\n",
            "Fold 4 | Epoch 33/40 | Loss 0.8265 | Val Acc 0.5215\n",
            "Fold 4 | Epoch 34/40 | Loss 0.7270 | Val Acc 0.5376\n",
            "Fold 4 | Epoch 35/40 | Loss 0.7786 | Val Acc 0.4946\n",
            "Fold 4 | Epoch 36/40 | Loss 0.7468 | Val Acc 0.5269\n",
            "Fold 4 | Epoch 37/40 | Loss 0.5340 | Val Acc 0.5430\n",
            "Fold 4 | Epoch 38/40 | Loss 0.6483 | Val Acc 0.5591\n",
            "Fold 4 | Epoch 39/40 | Loss 0.6366 | Val Acc 0.5269\n",
            "Fold 4 | Epoch 40/40 | Loss 0.6194 | Val Acc 0.5269\n",
            "\n",
            "âœ” Best Accuracy for Fold 4: 0.5591\n",
            "\n",
            "============================\n",
            "â–¶ FOLD 5/5\n",
            "============================\n",
            "\n",
            "Fold 5 | Epoch 1/40 | Loss 1.9398 | Val Acc 0.2258\n",
            "Fold 5 | Epoch 2/40 | Loss 1.9168 | Val Acc 0.2473\n",
            "Fold 5 | Epoch 3/40 | Loss 1.8699 | Val Acc 0.1882\n",
            "Fold 5 | Epoch 4/40 | Loss 1.9094 | Val Acc 0.3011\n",
            "Fold 5 | Epoch 5/40 | Loss 1.8375 | Val Acc 0.3495\n",
            "Fold 5 | Epoch 6/40 | Loss 1.7951 | Val Acc 0.3280\n",
            "Fold 5 | Epoch 7/40 | Loss 1.8098 | Val Acc 0.3011\n",
            "Fold 5 | Epoch 8/40 | Loss 1.7506 | Val Acc 0.3495\n",
            "Fold 5 | Epoch 9/40 | Loss 1.6966 | Val Acc 0.3817\n",
            "Fold 5 | Epoch 10/40 | Loss 1.5693 | Val Acc 0.3925\n",
            "Fold 5 | Epoch 11/40 | Loss 1.5427 | Val Acc 0.4194\n",
            "Fold 5 | Epoch 12/40 | Loss 1.4830 | Val Acc 0.4409\n",
            "Fold 5 | Epoch 13/40 | Loss 1.4467 | Val Acc 0.4140\n",
            "Fold 5 | Epoch 14/40 | Loss 1.5969 | Val Acc 0.3925\n",
            "Fold 5 | Epoch 15/40 | Loss 1.4816 | Val Acc 0.3978\n",
            "Fold 5 | Epoch 16/40 | Loss 1.4848 | Val Acc 0.5108\n",
            "Fold 5 | Epoch 17/40 | Loss 1.3646 | Val Acc 0.5215\n",
            "Fold 5 | Epoch 18/40 | Loss 1.2749 | Val Acc 0.5430\n",
            "Fold 5 | Epoch 19/40 | Loss 1.1685 | Val Acc 0.5269\n",
            "Fold 5 | Epoch 20/40 | Loss 1.0578 | Val Acc 0.5430\n",
            "Fold 5 | Epoch 21/40 | Loss 1.1902 | Val Acc 0.5376\n",
            "Fold 5 | Epoch 22/40 | Loss 1.0850 | Val Acc 0.5591\n",
            "Fold 5 | Epoch 23/40 | Loss 0.8352 | Val Acc 0.5806\n",
            "Fold 5 | Epoch 24/40 | Loss 0.9948 | Val Acc 0.5860\n",
            "Fold 5 | Epoch 25/40 | Loss 0.9294 | Val Acc 0.5860\n",
            "Fold 5 | Epoch 26/40 | Loss 0.7342 | Val Acc 0.5806\n",
            "Fold 5 | Epoch 27/40 | Loss 1.0903 | Val Acc 0.5430\n",
            "Fold 5 | Epoch 28/40 | Loss 0.9639 | Val Acc 0.5054\n",
            "Fold 5 | Epoch 29/40 | Loss 1.0915 | Val Acc 0.5591\n",
            "Fold 5 | Epoch 30/40 | Loss 1.1062 | Val Acc 0.5699\n",
            "Fold 5 | Epoch 31/40 | Loss 0.8519 | Val Acc 0.5215\n",
            "Fold 5 | Epoch 32/40 | Loss 1.0214 | Val Acc 0.5968\n",
            "Fold 5 | Epoch 33/40 | Loss 0.9622 | Val Acc 0.5968\n",
            "Fold 5 | Epoch 34/40 | Loss 0.7620 | Val Acc 0.5753\n",
            "Fold 5 | Epoch 35/40 | Loss 0.6467 | Val Acc 0.6022\n",
            "Fold 5 | Epoch 36/40 | Loss 0.8802 | Val Acc 0.5484\n",
            "Fold 5 | Epoch 37/40 | Loss 0.5987 | Val Acc 0.5699\n",
            "Fold 5 | Epoch 38/40 | Loss 0.6719 | Val Acc 0.5591\n",
            "Fold 5 | Epoch 39/40 | Loss 0.6415 | Val Acc 0.5538\n",
            "Fold 5 | Epoch 40/40 | Loss 0.4777 | Val Acc 0.6129\n",
            "\n",
            "âœ” Best Accuracy for Fold 5: 0.6129\n",
            "\n",
            "==========================================\n",
            "K-FOLD CROSS VALIDATION SUMMARY\n",
            "==========================================\n",
            "\n",
            "Accuracies per fold: [0.6096256684491979, 0.5775401069518716, 0.5483870967741935, 0.5591397849462365, 0.6129032258064516]\n",
            "Mean Accuracy: 0.5815191765855902\n",
            "Std Dev: 0.02603589179691301\n",
            "\n",
            "Final Classification Report (averaged):\n",
            "{\n",
            "    \"0\": {\n",
            "        \"precision\": 0.5678137651821863,\n",
            "        \"recall\": 0.5209150326797386,\n",
            "        \"f1-score\": 0.5402195589631922\n",
            "    },\n",
            "    \"1\": {\n",
            "        \"precision\": 0.6700525997300191,\n",
            "        \"recall\": 0.46299999999999997,\n",
            "        \"f1-score\": 0.531345029239766\n",
            "    },\n",
            "    \"2\": {\n",
            "        \"precision\": 0.5664210789210788,\n",
            "        \"recall\": 0.5527093596059113,\n",
            "        \"f1-score\": 0.5568343079922028\n",
            "    },\n",
            "    \"3\": {\n",
            "        \"precision\": 0.6397225632539767,\n",
            "        \"recall\": 0.6604838709677419,\n",
            "        \"f1-score\": 0.6484126277025422\n",
            "    },\n",
            "    \"4\": {\n",
            "        \"precision\": 0.7105962527421152,\n",
            "        \"recall\": 0.9019762845849802,\n",
            "        \"f1-score\": 0.7899121446103294\n",
            "    },\n",
            "    \"5\": {\n",
            "        \"precision\": 0.49931077694235587,\n",
            "        \"recall\": 0.5819354838709676,\n",
            "        \"f1-score\": 0.5313008598982165\n",
            "    },\n",
            "    \"6\": {\n",
            "        \"precision\": 0.5126427626427625,\n",
            "        \"recall\": 0.4235887096774194,\n",
            "        \"f1-score\": 0.45745111753954204\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline model testing"
      ],
      "metadata": {
        "id": "mJ5oG-8c2QnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_baseline = X_lstm.reshape(N, T * 9 * V)\n"
      ],
      "metadata": {
        "id": "7cXJJW5Il6gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding baseline models : Majority class , SVM and Rndom Forest\n"
      ],
      "metadata": {
        "id": "6jQfwfwE2Wsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "#  BASELINE INPUT: Flatten sequence for classical ML models\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "N, T, F = X_lstm.shape  # F = 9*V\n",
        "X_baseline = X_lstm.reshape(N, T * F)\n",
        "\n",
        "print(\"Flattened baseline shape:\", X_baseline.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f4_JMqD2UWa",
        "outputId": "2453714d-0600-4433-dfef-7ef9f5b35999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened baseline shape: (932, 53100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Majority class Baseline"
      ],
      "metadata": {
        "id": "UyOMtSsR2qEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "majority_class = Counter(labels_arr).most_common(1)[0][0]\n",
        "\n",
        "majority_acc = np.mean(labels_arr == majority_class)\n",
        "\n",
        "print(\"Majority Class:\", majority_class)\n",
        "print(\"Majority Class Accuracy:\", majority_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZH4t7gb2rx7",
        "outputId": "f977abfd-290c-42e7-a955-f1dd2ed44873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Majority Class: 3\n",
            "Majority Class Accuracy: 0.17060085836909872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Test for classical models"
      ],
      "metadata": {
        "id": "-GHDkfT72xB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
        "    X_baseline, labels_arr, test_size=0.2, stratify=labels_arr, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "NAGk5FYq2sSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train And Evaluate SVM"
      ],
      "metadata": {
        "id": "2nUw_FPl22KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== SVM BASELINE =====\")\n",
        "\n",
        "svm_clf = SVC(kernel=\"rbf\", class_weight=\"balanced\")\n",
        "svm_clf.fit(X_train_b, y_train_b)\n",
        "\n",
        "svm_preds = svm_clf.predict(X_test_b)\n",
        "svm_acc = accuracy_score(y_test_b, svm_preds)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_acc)\n",
        "print(classification_report(y_test_b, svm_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOVCV05C20_N",
        "outputId": "87b60623-b8fe-495d-bfd6-a2c6710e4717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== SVM BASELINE =====\n",
            "SVM Accuracy: 0.3315508021390374\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.56      0.43        18\n",
            "           1       0.37      0.28      0.32        25\n",
            "           2       0.50      0.14      0.22        28\n",
            "           3       0.46      0.38      0.41        32\n",
            "           4       0.31      0.50      0.38        22\n",
            "           5       0.30      0.20      0.24        30\n",
            "           6       0.24      0.38      0.30        32\n",
            "\n",
            "    accuracy                           0.33       187\n",
            "   macro avg       0.36      0.35      0.33       187\n",
            "weighted avg       0.36      0.33      0.32       187\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Evaluate Random Forest"
      ],
      "metadata": {
        "id": "5cu4g3Yo28CS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== RANDOM FOREST BASELINE =====\")\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=30,\n",
        "    class_weight=\"balanced_subsample\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf.fit(X_train_b, y_train_b)\n",
        "\n",
        "rf_preds = rf.predict(X_test_b)\n",
        "rf_acc = accuracy_score(y_test_b, rf_preds)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", rf_acc)\n",
        "print(classification_report(y_test_b, rf_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8ItkVpf26b7",
        "outputId": "c000ab2b-3d9d-41c9-9700-19cae1d8694c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== RANDOM FOREST BASELINE =====\n",
            "Random Forest Accuracy: 0.44385026737967914\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        18\n",
            "           1       0.50      0.20      0.29        25\n",
            "           2       0.52      0.43      0.47        28\n",
            "           3       0.48      0.62      0.54        32\n",
            "           4       0.82      0.64      0.72        22\n",
            "           5       0.36      0.50      0.42        30\n",
            "           6       0.35      0.53      0.42        32\n",
            "\n",
            "    accuracy                           0.44       187\n",
            "   macro avg       0.43      0.42      0.41       187\n",
            "weighted avg       0.44      0.44      0.42       187\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m2hFQiI93CyV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}