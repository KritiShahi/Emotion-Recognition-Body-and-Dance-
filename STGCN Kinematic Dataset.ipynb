{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "I26sFjKBZ56N"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "I26sFjKBZ56N"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfyGH6bfZ56O",
        "outputId": "53f8a9c0-e8bd-4747-82de-1d48349fdd6c"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,precision_recall_fscore_support\n",
        "\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "id": "RfyGH6bfZ56O"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PJ09F1xMZ56O"
      },
      "source": [
        "class BVHParser:\n",
        "\n",
        "    def __init__(self, filepath: str):\n",
        "        self.filepath = filepath\n",
        "        self.joints = []\n",
        "        self.hierarchy = {}\n",
        "        self.joint_parents = {}\n",
        "        self.channels_list = []\n",
        "        self.motion_data = None\n",
        "        self.frame_time = 0.0\n",
        "        self.num_frames = 0\n",
        "        self._joint_channel_counts = {}\n",
        "        self.ordered_joints = []\n",
        "\n",
        "    def parse(self):\n",
        "        with open(self.filepath, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # Find MOTION index\n",
        "        motion_idx = None\n",
        "        for i, line in enumerate(lines):\n",
        "            if 'MOTION' in line.upper():\n",
        "                motion_idx = i\n",
        "                break\n",
        "\n",
        "        self._parse_hierarchy(lines[:motion_idx])\n",
        "        self._parse_motion(lines[motion_idx:])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _parse_hierarchy(self, lines):\n",
        "      \"\"\"Extract joint hierarchy\"\"\"\n",
        "      joint_stack = []\n",
        "      current_joint = None\n",
        "      self.joints = []\n",
        "      self.hierarchy = {}\n",
        "      self.joint_parents = {}\n",
        "      self.channels_list = []\n",
        "      self.ordered_joints = []\n",
        "\n",
        "      for line in lines:\n",
        "          stripped = line.strip()\n",
        "          if stripped.startswith(\"ROOT\") or stripped.startswith(\"JOINT\"):\n",
        "              parts = stripped.split()\n",
        "              if len(parts) >= 2:\n",
        "                  current_joint = parts[1]\n",
        "                  self.joints.append(current_joint)\n",
        "                  self.ordered_joints.append(current_joint)\n",
        "                  self.hierarchy[current_joint] = {\n",
        "                      'channels': [],\n",
        "                      'offset': np.array([0.0, 0.0, 0.0], dtype=np.float32),\n",
        "                      'children': []\n",
        "                  }\n",
        "                  if joint_stack:\n",
        "                      parent = joint_stack[-1]\n",
        "                      self.joint_parents[current_joint] = parent\n",
        "                      self.hierarchy[parent]['children'].append(current_joint)\n",
        "                  else:\n",
        "                      self.joint_parents[current_joint] = None\n",
        "                  joint_stack.append(current_joint)\n",
        "\n",
        "          elif stripped.startswith(\"End Site\"):\n",
        "              # End sites don't have channels, skip them\n",
        "              pass\n",
        "\n",
        "          elif stripped.startswith(\"OFFSET\") and current_joint:\n",
        "              parts = stripped.split()\n",
        "              try:\n",
        "                  ox, oy, oz = float(parts[1]), float(parts[2]), float(parts[3])\n",
        "                  self.hierarchy[current_joint]['offset'] = np.array([ox, oy, oz], dtype=np.float32)\n",
        "              except:\n",
        "                  pass\n",
        "\n",
        "          elif stripped.startswith(\"CHANNELS\") and current_joint:\n",
        "              parts = stripped.split()\n",
        "              try:\n",
        "                  num_ch = int(parts[1])\n",
        "                  chs = parts[2:2+num_ch]\n",
        "                  self.hierarchy[current_joint]['channels'] = chs\n",
        "                  self._joint_channel_counts[current_joint] = len(chs)\n",
        "                  for ch in chs:\n",
        "                      self.channels_list.append((current_joint, ch))\n",
        "              except:\n",
        "                  pass\n",
        "\n",
        "          elif '}' in stripped:\n",
        "              if joint_stack:\n",
        "                  joint_stack.pop()\n",
        "                  current_joint = joint_stack[-1] if joint_stack else None\n",
        "\n",
        "    def _parse_motion(self, lines):\n",
        "        \"\"\"Extract motion data\"\"\"\n",
        "        for line in lines[:20]:\n",
        "            if \"Frames:\" in line:\n",
        "                self.num_frames = int(line.split(\":\")[1].strip())\n",
        "            if \"Frame Time:\" in line:\n",
        "                self.frame_time = float(line.split(\":\")[1].strip())\n",
        "\n",
        "\n",
        "        data_start = None\n",
        "        for i, line in enumerate(lines):\n",
        "            s = line.strip()\n",
        "            if not s:\n",
        "                continue\n",
        "            parts = s.split()\n",
        "            try:\n",
        "                _ = float(parts[0])\n",
        "                data_start = i\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        data = []\n",
        "        for line in lines[data_start:]:\n",
        "            s = line.strip()\n",
        "            if not s:\n",
        "                continue\n",
        "            parts = s.split()\n",
        "            try:\n",
        "                nums = [float(p) for p in parts]\n",
        "                data.append(nums)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        self.motion_data = np.array(data, dtype=np.float32)\n",
        "        if self.num_frames == 0:\n",
        "            self.num_frames = len(data)\n",
        "\n",
        "\n",
        "    def compute_joint_positions(self):\n",
        "\n",
        "        T = self.motion_data.shape[0]\n",
        "        V = len(self.ordered_joints)\n",
        "        positions = np.zeros((T, V, 3), dtype=np.float32)\n",
        "\n",
        "        joint_col_idx = {}\n",
        "        col = 0\n",
        "        for j in self.ordered_joints:\n",
        "            chs = self.hierarchy[j]['channels']\n",
        "            cnt = len(chs)\n",
        "            joint_col_idx[j] = (col, col + cnt)\n",
        "            col += cnt\n",
        "\n",
        "        for t in range(T):\n",
        "            global_rot = {}\n",
        "            global_pos = {}\n",
        "\n",
        "            for v_idx, joint in enumerate(self.ordered_joints):\n",
        "                parent = self.joint_parents.get(joint, None)\n",
        "                offset = self.hierarchy[joint]['offset']\n",
        "\n",
        "                local_rot = np.eye(3, dtype=np.float32)\n",
        "                local_pos = np.zeros(3, dtype=np.float32)\n",
        "\n",
        "                start, end = joint_col_idx[joint]\n",
        "                if end > start:\n",
        "                    ch_names = self.hierarchy[joint]['channels']\n",
        "                    values = self.motion_data[t, start:end]\n",
        "                    pos_vals = []\n",
        "                    rot_vals = []\n",
        "                    pos_order = []\n",
        "                    rot_order = []\n",
        "                    for i, ch in enumerate(ch_names):\n",
        "                        lower = ch.lower()\n",
        "                        if 'position' in lower:\n",
        "                            pos_vals.append(values[i])\n",
        "                            pos_order.append(lower[0])\n",
        "                        elif 'rotation' in lower:\n",
        "                            rot_vals.append(values[i])\n",
        "                            rot_order.append(ch)\n",
        "\n",
        "                    if len(pos_vals) > 0:\n",
        "                        lp = np.zeros(3, dtype=np.float32)\n",
        "                        for i, ch in enumerate(ch_names):\n",
        "                            if 'position' in ch.lower():\n",
        "                                axis = ch.lower()[0]  # x/y/z\n",
        "                                if axis == 'x':\n",
        "                                    lp[0] = values[i]\n",
        "                                elif axis == 'y':\n",
        "                                    lp[1] = values[i]\n",
        "                                elif axis == 'z':\n",
        "                                    lp[2] = values[i]\n",
        "                        local_pos = lp\n",
        "                    if len(rot_vals) > 0:\n",
        "                        rot_mat = np.eye(3, dtype=np.float32)\n",
        "                        for i, ch in enumerate(ch_names):\n",
        "                            if 'rotation' in ch.lower():\n",
        "                                angle_deg = values[i]\n",
        "                                angle = math.radians(angle_deg)\n",
        "                                axis = ch.lower()[0]  # x/y/z\n",
        "                                if axis == 'x':\n",
        "                                    R = np.array([[1,0,0],\n",
        "                                                  [0, math.cos(angle), -math.sin(angle)],\n",
        "                                                  [0, math.sin(angle),  math.cos(angle)]], dtype=np.float32)\n",
        "                                elif axis == 'y':\n",
        "                                    R = np.array([[ math.cos(angle), 0, math.sin(angle)],\n",
        "                                                  [0,1,0],\n",
        "                                                  [-math.sin(angle),0, math.cos(angle)]], dtype=np.float32)\n",
        "                                else:\n",
        "                                    R = np.array([[math.cos(angle), -math.sin(angle), 0],\n",
        "                                                  [math.sin(angle),  math.cos(angle), 0],\n",
        "                                                  [0,0,1]], dtype=np.float32)\n",
        "                                rot_mat = rot_mat @ R\n",
        "                        local_rot = rot_mat\n",
        "\n",
        "                if parent is None:\n",
        "                    if np.any(local_pos != 0):\n",
        "                        root_pos = local_pos\n",
        "                    else:\n",
        "                        root_pos = offset\n",
        "                    global_pos[joint] = root_pos\n",
        "                    global_rot[joint] = local_rot\n",
        "                else:\n",
        "                    p_rot = global_rot[parent]\n",
        "                    p_pos = global_pos[parent]\n",
        "                    joint_pos = p_pos + p_rot.dot(offset) + p_rot.dot(local_pos)\n",
        "                    global_pos[joint] = joint_pos\n",
        "                    global_rot[joint] = p_rot.dot(local_rot)\n",
        "\n",
        "                positions[t, v_idx, :] = global_pos[joint]\n",
        "\n",
        "        return positions\n",
        "\n",
        "\n",
        "def compute_motion_features(positions):\n",
        "\n",
        "  velocity = np.zeros_like(positions)\n",
        "  velocity[1:] = positions[1:] - positions[:-1]\n",
        "\n",
        "  acceleration = np.zeros_like(positions)\n",
        "  acceleration[1:] = velocity[1:] - velocity[:-1]\n",
        "\n",
        "  motion_features = np.concatenate([positions, velocity, acceleration], axis=2)\n",
        "\n",
        "  return motion_features\n",
        "\n",
        "\n",
        "def resample_time_sequence(seq, target_frames):\n",
        "    T, V, C = seq.shape\n",
        "    if T == target_frames:\n",
        "        return seq\n",
        "    if T < 2:\n",
        "        out = np.tile(seq, (target_frames, 1, 1))\n",
        "        return out[:target_frames]\n",
        "    old_idx = np.linspace(0, T-1, T)\n",
        "    new_idx = np.linspace(0, T-1, target_frames)\n",
        "    out = np.zeros((target_frames, V, C), dtype=seq.dtype)\n",
        "    for v in range(V):\n",
        "        for c in range(C):\n",
        "            out[:, v, c] = np.interp(new_idx, old_idx, seq[:, v, c])\n",
        "    return out\n",
        "\n",
        "def center_on_root(seq, root_index = 0, keep_z = True):\n",
        "    T, V, C = seq.shape\n",
        "    root_pos = seq[:, root_index:root_index+1, :]\n",
        "    centered = seq - root_pos\n",
        "    if not keep_z:\n",
        "        centered[..., 2] = 0.0\n",
        "    return centered\n",
        "\n",
        "def normalize_sequence(seq, scale = None):\n",
        "    if scale is not None:\n",
        "        return seq / scale, scale\n",
        "    T, V, C = seq.shape\n",
        "    dists = np.linalg.norm(seq, axis=2)\n",
        "    mean_dist = float(np.mean(dists))\n",
        "    if mean_dist == 0:\n",
        "        mean_dist = 1.0\n",
        "    return seq / mean_dist, mean_dist\n",
        "\n",
        "\n",
        "def random_rotation_xyz(sample, angle_range=np.pi/12):\n",
        "    C, T, V = sample.shape\n",
        "    if C % 3 != 0:\n",
        "        return sample\n",
        "    theta = np.random.uniform(-angle_range, angle_range)\n",
        "    c, s = np.cos(theta), np.sin(theta)\n",
        "    R = np.array([[c, 0, -s],\n",
        "                  [0, 1,  0],\n",
        "                  [s, 0,  c]], dtype=np.float32)\n",
        "    out = sample.copy()\n",
        "    for v in range(V):\n",
        "        xyz = sample[:, :, v].reshape(3, -1)\n",
        "        xyz_rot = R @ xyz\n",
        "        out[0:3, :, v] = xyz_rot\n",
        "    return out\n",
        "\n",
        "def temporal_jitter(sample, max_shift=8):\n",
        "\n",
        "    C, T, V = sample.shape\n",
        "    shift = np.random.randint(-max_shift, max_shift + 1)\n",
        "    if shift == 0: return sample\n",
        "    if shift > 0:\n",
        "\n",
        "        idx = np.linspace(0, T-1, T-shift).astype(int)\n",
        "        new = sample[:, idx, :]\n",
        "        pad = np.repeat(new[:, -1:, :], shift, axis=1)\n",
        "        out = np.concatenate([new, pad], axis=1)\n",
        "    else:\n",
        "\n",
        "        idx = np.linspace(0, T-1, min(T, T+(-shift))).astype(int)\n",
        "        new = sample[:, idx, :]\n",
        "        if new.shape[1] >= T:\n",
        "            out = new[:, :T, :]\n",
        "        else:\n",
        "            pad = np.repeat(new[:, -1:, :], T - new.shape[1], axis=1)\n",
        "            out = np.concatenate([new, pad], axis=1)\n",
        "    return out\n",
        "\n",
        "def add_gaussian_noise(sample, sigma=0.005):\n",
        "    return sample + np.random.normal(scale=sigma, size=sample.shape).astype(np.float32)\n",
        "\n",
        "\n",
        "def center_and_scale(sample, root_idx=0, scale_pair=(11,14)):\n",
        "\n",
        "    C, T, V = sample.shape\n",
        "    out = sample.copy().astype(np.float32)\n",
        "    if C < 3:\n",
        "        return out\n",
        "\n",
        "    root_xyz = out[0:3, :, root_idx].mean(axis=1)  # (3,)\n",
        "    out[0:3, :, :] = out[0:3, :, :] - root_xyz.reshape(3,1,1)\n",
        "\n",
        "    p1 = out[0:3, :, scale_pair[0]].mean(axis=1)\n",
        "    p2 = out[0:3, :, scale_pair[1]].mean(axis=1)\n",
        "    scale = np.linalg.norm(p1 - p2) + 1e-6\n",
        "    out[0:3, :, :] = out[0:3, :, :] / scale\n",
        "    return out\n",
        "\n",
        "def build_edge_list(ordered_joints, joint_parents):\n",
        "\n",
        "    name2idx = {name: i for i, name in enumerate(ordered_joints)}\n",
        "    edges = []\n",
        "    for j, parent in joint_parents.items():\n",
        "        if parent is None:\n",
        "            continue\n",
        "        u = name2idx[parent]\n",
        "        v = name2idx[j]\n",
        "        edges.append((u, v))\n",
        "        edges.append((v, u))\n",
        "    return edges"
      ],
      "execution_count": 2,
      "outputs": [],
      "id": "PJ09F1xMZ56O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDmXjAvpZ56P"
      },
      "source": [
        "### STGCN Dataset Builder"
      ],
      "id": "tDmXjAvpZ56P"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HnwJkMRSZ56P",
        "outputId": "9fb65bfe-9c89-40b1-b39a-28419b291583"
      },
      "source": [
        "class STGCNDatasetBuilder:\n",
        "\n",
        "    def __init__(self, data_dir, fileinfo_csv, output_dir, target_frames = 100, center_root = True,normalize = True, root_name = None):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.fileinfo = pd.read_csv(fileinfo_csv)\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.target_frames = target_frames\n",
        "        self.center_root = center_root\n",
        "        self.normalize = normalize\n",
        "        self.root_name = root_name\n",
        "\n",
        "        self.sample_paths = []\n",
        "        self.labels = []\n",
        "        self.failed = []\n",
        "        self.label2idx = {}\n",
        "\n",
        "    def _find_bvh(self, filename: str):\n",
        "        # Try direct and recursive search\n",
        "        candidates = [\n",
        "            self.data_dir / f\"{filename}.bvh\",\n",
        "            self.data_dir / \"bvh\" / f\"{filename}.bvh\",\n",
        "            self.data_dir / \"data\" / f\"{filename}.bvh\",\n",
        "            self.data_dir / filename / f\"{filename}.bvh\",\n",
        "        ]\n",
        "        for p in candidates:\n",
        "            if p.exists():\n",
        "                return p\n",
        "        # recursive search\n",
        "        found = list(self.data_dir.rglob(f\"{filename}.bvh\"))\n",
        "        if found:\n",
        "            return found[0]\n",
        "        return None\n",
        "\n",
        "    def build(self, save_as_single_array: bool = True):\n",
        "        print(\"Processing dataset...\")\n",
        "        data_list = []\n",
        "        label_list = []\n",
        "        global_joint_order = None\n",
        "        global_edge_list = None\n",
        "\n",
        "        for idx, row in self.fileinfo.iterrows():\n",
        "            filename = row['filename']\n",
        "            emotion = row.get('emotion', None)\n",
        "            bvh_path = self._find_bvh(filename)\n",
        "            if bvh_path is None:\n",
        "                self.failed.append((filename, \"not found\"))\n",
        "                continue\n",
        "\n",
        "            parser = BVHParser(str(bvh_path)).parse()\n",
        "            positions = parser.compute_joint_positions()  # (T, V, 3)\n",
        "\n",
        "            if global_joint_order is None:\n",
        "                global_joint_order = parser.ordered_joints\n",
        "                global_edge_list = build_edge_list(parser.ordered_joints, parser.joint_parents)\n",
        "\n",
        "                if self.root_name and self.root_name in global_joint_order:\n",
        "                    root_idx = global_joint_order.index(self.root_name)\n",
        "                else:\n",
        "                    root_idx = 0\n",
        "\n",
        "\n",
        "            positions = resample_time_sequence(positions, self.target_frames)  # (T, V, 3)\n",
        "            positions_with_motion = compute_motion_features(positions)\n",
        "\n",
        "\n",
        "            if self.center_root:\n",
        "                positions_with_motion = center_on_root(positions_with_motion, root_index=root_idx)\n",
        "\n",
        "\n",
        "            if self.normalize:\n",
        "                positions_with_motion, used_scale = normalize_sequence(positions_with_motion, scale=None)\n",
        "\n",
        "\n",
        "            if parser.ordered_joints != global_joint_order:\n",
        "\n",
        "                name2idx_local = {name: i for i, name in enumerate(parser.ordered_joints)}\n",
        "                reordered = np.zeros((self.target_frames, len(global_joint_order), 3), dtype=positions.dtype)\n",
        "                for i, name in enumerate(global_joint_order):\n",
        "                    if name in name2idx_local:\n",
        "                        reordered[:, i, :] = positions[:, name2idx_local[name], :]\n",
        "                    else:\n",
        "\n",
        "                        reordered[:, i, :] = 0.0\n",
        "                positions = reordered\n",
        "\n",
        "            seq = np.transpose(positions_with_motion, (2, 0, 1))\n",
        "            data_list.append(seq.astype(np.float32))\n",
        "\n",
        "\n",
        "            if emotion not in self.label2idx:\n",
        "                self.label2idx[emotion] = len(self.label2idx)\n",
        "            label_list.append(self.label2idx[emotion])\n",
        "\n",
        "            sample_out = self.output_dir / f\"{filename}.npy\"\n",
        "            np.save(sample_out, seq.astype(np.float32))\n",
        "            self.sample_paths.append(str(sample_out))\n",
        "\n",
        "            if len(data_list) % 50 == 0:\n",
        "                print(f\"Processed {len(data_list)} samples...\")\n",
        "\n",
        "\n",
        "        data_arr = np.stack(data_list, axis=0)\n",
        "        labels_arr = np.array(label_list, dtype=np.int64)\n",
        "\n",
        "        if save_as_single_array:\n",
        "            np.save(self.output_dir / \"data.npy\", data_arr)\n",
        "            np.save(self.output_dir / \"labels.npy\", labels_arr)\n",
        "            meta = {\n",
        "                'joint_names': global_joint_order,\n",
        "                'edge_list': global_edge_list,\n",
        "                'label2idx': self.label2idx,\n",
        "                'target_frames': self.target_frames,\n",
        "                'center_root': self.center_root,\n",
        "                'normalize': self.normalize\n",
        "            }\n",
        "            with open(self.output_dir / \"meta.json\", \"w\") as f:\n",
        "                json.dump(meta, f, indent=2)\n",
        "            print(f\"Saved data.npy ({data_arr.shape}), labels.npy ({labels_arr.shape}), meta.json\")\n",
        "\n",
        "        return data_arr, labels_arr, global_joint_order, global_edge_list\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = \"/content/drive/MyDrive/kinematic_dataset_final/BVH/\"\n",
        "    fileinfo_csv = \"/content/drive/MyDrive/kinematic_dataset_final/file-info.csv\"\n",
        "    output_dir = \"/content/drive/MyDrive/kinematic_dataset_final/stgcn_input_final/\"\n",
        "    target_frames = 100\n",
        "    center_root = True\n",
        "    normalize = True\n",
        "    sample_save_single_array = True\n",
        "\n",
        "    builder = STGCNDatasetBuilder(data_dir, fileinfo_csv, output_dir,\n",
        "                                  target_frames=target_frames,\n",
        "                                  center_root=center_root,\n",
        "                                  normalize=normalize)\n",
        "    data_arr, labels_arr, joints, edges = builder.build(save_as_single_array=sample_save_single_array)\n",
        "\n",
        "    print(\"Data shape:\", data_arr.shape)\n",
        "    print(\"Label distribution:\", np.bincount(labels_arr))\n",
        "    print(\"Joints:\", joints)\n",
        "    print(\"Edges:\", edges)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing dataset...\n",
            "Processed 50 samples...\n",
            "Processed 100 samples...\n",
            "Processed 150 samples...\n",
            "Processed 200 samples...\n",
            "Processed 250 samples...\n",
            "Processed 300 samples...\n",
            "Processed 350 samples...\n",
            "Processed 400 samples...\n",
            "Processed 450 samples...\n",
            "Processed 500 samples...\n",
            "Processed 550 samples...\n",
            "Processed 600 samples...\n",
            "Processed 650 samples...\n",
            "Processed 700 samples...\n",
            "Processed 750 samples...\n",
            "Processed 800 samples...\n",
            "Processed 850 samples...\n",
            "Processed 900 samples...\n",
            "Processed 950 samples...\n",
            "Processed 1000 samples...\n",
            "Processed 1050 samples...\n",
            "Processed 1100 samples...\n",
            "Processed 1150 samples...\n",
            "Processed 1200 samples...\n",
            "Processed 1250 samples...\n",
            "Processed 1300 samples...\n",
            "Processed 1350 samples...\n",
            "Processed 1400 samples...\n",
            "Saved data.npy ((1401, 9, 100, 59)), labels.npy ((1401,)), meta.json\n",
            "Data shape: (1401, 9, 100, 59)\n",
            "Label distribution: [200 210 216 216 145 202 212]\n",
            "Joints: ['Hips', 'RightUpLeg', 'RightLeg', 'RightFoot', 'LeftUpLeg', 'LeftLeg', 'LeftFoot', 'Spine', 'Spine1', 'Spine2', 'Spine3', 'Neck', 'Head', 'RightShoulder', 'RightArm', 'RightForeArm', 'RightHand', 'RightHandThumb1', 'RightHandThumb2', 'RightHandThumb3', 'RightInHandIndex', 'RightHandIndex1', 'RightHandIndex2', 'RightHandIndex3', 'RightInHandMiddle', 'RightHandMiddle1', 'RightHandMiddle2', 'RightHandMiddle3', 'RightInHandRing', 'RightHandRing1', 'RightHandRing2', 'RightHandRing3', 'RightInHandPinky', 'RightHandPinky1', 'RightHandPinky2', 'RightHandPinky3', 'LeftShoulder', 'LeftArm', 'LeftForeArm', 'LeftHand', 'LeftHandThumb1', 'LeftHandThumb2', 'LeftHandThumb3', 'LeftInHandIndex', 'LeftHandIndex1', 'LeftHandIndex2', 'LeftHandIndex3', 'LeftInHandMiddle', 'LeftHandMiddle1', 'LeftHandMiddle2', 'LeftHandMiddle3', 'LeftInHandRing', 'LeftHandRing1', 'LeftHandRing2', 'LeftHandRing3', 'LeftInHandPinky', 'LeftHandPinky1', 'LeftHandPinky2', 'LeftHandPinky3']\n",
            "Edges: [(0, 1), (1, 0), (1, 2), (2, 1), (2, 3), (3, 2), (4, 5), (5, 4), (5, 6), (6, 5), (7, 8), (8, 7), (8, 9), (9, 8), (9, 10), (10, 9), (10, 11), (11, 10), (11, 12), (12, 11), (9, 13), (13, 9), (13, 14), (14, 13), (14, 15), (15, 14), (15, 16), (16, 15), (16, 17), (17, 16), (17, 18), (18, 17), (18, 19), (19, 18), (15, 20), (20, 15), (20, 21), (21, 20), (21, 22), (22, 21), (22, 23), (23, 22), (14, 24), (24, 14), (24, 25), (25, 24), (25, 26), (26, 25), (26, 27), (27, 26), (13, 28), (28, 13), (28, 29), (29, 28), (29, 30), (30, 29), (30, 31), (31, 30), (9, 32), (32, 9), (32, 33), (33, 32), (33, 34), (34, 33), (34, 35), (35, 34), (36, 37), (37, 36), (37, 38), (38, 37), (38, 39), (39, 38), (39, 40), (40, 39), (40, 41), (41, 40), (41, 42), (42, 41), (38, 43), (43, 38), (43, 44), (44, 43), (44, 45), (45, 44), (45, 46), (46, 45), (37, 47), (47, 37), (47, 48), (48, 47), (48, 49), (49, 48), (49, 50), (50, 49), (36, 51), (51, 36), (51, 52), (52, 51), (52, 53), (53, 52), (53, 54), (54, 53), (55, 56), (56, 55), (56, 57), (57, 56), (57, 58), (58, 57)]\n"
          ]
        }
      ],
      "id": "HnwJkMRSZ56P"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POZq_WibZ56P",
        "outputId": "310e6987-a654-46f7-83fd-3351cf5fada1"
      },
      "source": [
        "### Uncomment it when using colab\n",
        "X_path = \"/content/drive/MyDrive/kinematic_dataset_final/stgcn_input_final/data.npy\"\n",
        "y_path = \"/content/drive/MyDrive/kinematic_dataset_final/stgcn_input_final/labels.npy\"\n",
        "\n",
        "# X_path = \"data.npy\"\n",
        "# y_path = \"labels.npy\"\n",
        "\n",
        "\n",
        "X = np.load(X_path)\n",
        "y = np.load(y_path)\n",
        "\n",
        "print(\"Loaded X\", X.shape, \"y\", y.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded X (1401, 9, 100, 59) y (1401,)\n"
          ]
        }
      ],
      "id": "POZq_WibZ56P"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_O4yRBwZ56Q",
        "outputId": "44ae1863-a64f-4856-b80b-44ab515ae4ec"
      },
      "source": [
        "if X.ndim == 5 and X.shape[-1] == 1:\n",
        "    X = X[..., 0]\n",
        "print(\"Using X shape:\", X.shape)\n",
        "\n",
        "N, C, T, V = X.shape\n",
        "print(\"N,C,T,V =\", N, C, T, V)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using X shape: (1401, 9, 100, 59)\n",
            "N,C,T,V = 1401 9 100 59\n"
          ]
        }
      ],
      "id": "N_O4yRBwZ56Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umpXpRGUZ56Q",
        "outputId": "1b92e7fd-4bb3-4491-fcc8-7f7022ed964b"
      },
      "source": [
        "class STGCNDataset(Dataset):\n",
        "    def __init__(self, X, y, augment=False,train =True, fixed_T=100):\n",
        "        self.X = X.astype(np.float32)\n",
        "        self.y = y.astype(np.int64)\n",
        "        self.train = train\n",
        "        self.augment = augment\n",
        "        self.fixed_T = fixed_T\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]  # (C, T, V)\n",
        "        if self.augment:\n",
        "            x = x + 0.001 * np.random.randn(*x.shape).astype(np.float32)\n",
        "        return x, self.y[idx]\n",
        "\n",
        "\n",
        "train_idx, val_idx = train_test_split(np.arange(N), test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "X_train, y_train = X[train_idx], y[train_idx]\n",
        "X_val, y_val = X[val_idx], y[val_idx]\n",
        "print(\"Train/Val sizes:\", X_train.shape[0], X_val.shape[0])\n",
        "\n",
        "fixed_T = 100\n",
        "train_ds = STGCNDataset(X_train, y_train, train=True, augment=True, fixed_T=fixed_T)\n",
        "val_ds = STGCNDataset(X_val, y_val, train=False, augment=False, fixed_T=fixed_T)\n",
        "\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Val sizes: 1120 281\n"
          ]
        }
      ],
      "id": "umpXpRGUZ56Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6hcvFOVZ56Q",
        "outputId": "a04e6ea8-f523-49a3-f2aa-0c7420c07ab5"
      },
      "source": [
        "edge_list = [(0, 1), (1, 0), (1, 2), (2, 1), (2, 3), (3, 2), (4, 5), (5, 4), (5, 6), (6, 5), (7, 8), (8, 7), (8, 9), (9, 8), (9, 10), (10, 9), (10, 11), (11, 10), (11, 12), (12, 11), (9, 13), (13, 9), (13, 14), (14, 13), (14, 15), (15, 14), (15, 16), (16, 15), (16, 17), (17, 16), (17, 18), (18, 17), (18, 19), (19, 18), (15, 20), (20, 15), (20, 21), (21, 20), (21, 22), (22, 21), (22, 23), (23, 22), (14, 24), (24, 14), (24, 25), (25, 24), (25, 26), (26, 25), (26, 27), (27, 26), (13, 28), (28, 13), (28, 29), (29, 28), (29, 30), (30, 29), (30, 31), (31, 30), (9, 32), (32, 9), (32, 33), (33, 32), (33, 34), (34, 33), (34, 35), (35, 34), (36, 37), (37, 36), (37, 38), (38, 37), (38, 39), (39, 38), (39, 40), (40, 39), (40, 41), (41, 40), (41, 42), (42, 41), (38, 43), (43, 38), (43, 44), (44, 43), (44, 45), (45, 44), (45, 46), (46, 45), (37, 47), (47, 37), (47, 48), (48, 47), (48, 49), (49, 48), (49, 50), (50, 49), (36, 51), (51, 36), (51, 52), (52, 51), (52, 53), (53, 52), (53, 54), (54, 53), (55, 56), (56, 55), (56, 57), (57, 56), (57, 58), (58, 57)]\n",
        "\n",
        "def build_adj(V, edge_list, self_link=True):\n",
        "    A = np.zeros((V, V), dtype=np.float32)\n",
        "    for (u,v) in edge_list:\n",
        "        A[u, v] = 1\n",
        "        A[v, u] = 1\n",
        "    if self_link:\n",
        "        for i in range(V):\n",
        "            A[i,i] = 1\n",
        "    return A\n",
        "\n",
        "def normalize_adj(A):\n",
        "    # symmetric normalization D^-1/2 A D^-1/2\n",
        "    D = np.sum(A, axis=1)\n",
        "    D_inv_sqrt = np.power(D, -0.5)\n",
        "    D_inv_sqrt[np.isinf(D_inv_sqrt)] = 0.0\n",
        "    Dm = np.diag(D_inv_sqrt)\n",
        "    return Dm @ A @ Dm\n",
        "\n",
        "A = build_adj(V, edge_list, self_link=True)\n",
        "A_norm = normalize_adj(A)\n",
        "A_torch = torch.tensor(A_norm, dtype=torch.float32, device=device)  # (V,V)\n",
        "print(\"A_norm shape:\", A_torch.shape)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A_norm shape: torch.Size([59, 59])\n"
          ]
        }
      ],
      "id": "E6hcvFOVZ56Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "czmHoHaGZ56Q"
      },
      "source": [
        "\n",
        "class SpatialGraphConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bias=True):\n",
        "        super().__init__()\n",
        "        self.conv1x1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias)\n",
        "\n",
        "    def forward(self, x, A):\n",
        "        x = self.conv1x1(x)\n",
        "        N, outC, T, V = x.shape\n",
        "        x = x.permute(0,2,1,3).contiguous().view(N*T, outC, V)\n",
        "        x = torch.matmul(x, A.t())\n",
        "        x = x.view(N, T, outC, V).permute(0,2,1,3).contiguous()\n",
        "        return x\n",
        "\n",
        "\n",
        "class TemporalAttention(nn.Module):\n",
        "    \"\"\"Attention across time dimension\"\"\"\n",
        "    def __init__(self, channels, reduction=8):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((None, 1))\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d((None, 1))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(channels*2, channels // reduction, kernel_size=1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels // reduction, channels, kernel_size=1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.avg_pool(x)\n",
        "        max_out = self.max_pool(x)\n",
        "        concat = torch.cat([avg_out, max_out], dim=1)\n",
        "        attention = self.fc(concat)\n",
        "        return x * attention.expand_as(x)\n",
        "\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    \"\"\"Attention across joints (spatial dimension)\"\"\"\n",
        "    def __init__(self, channels, reduction=8):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, None))  # Pool over T dimension\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d((1, None))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(channels*2, channels // reduction, kernel_size=1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels // reduction, channels, kernel_size=1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.avg_pool(x)\n",
        "        max_out = self.max_pool(x)\n",
        "        concat = torch.cat([avg_out, max_out], dim=1)\n",
        "        attention = self.fc(concat)\n",
        "        return x * attention.expand_as(x)\n",
        "\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    \"\"\"Attention across feature channels\"\"\"\n",
        "    def __init__(self, channels, reduction=8):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels // reduction, kernel_size=1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels // reduction, channels, kernel_size=1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        attention = avg_out + max_out\n",
        "        return x * attention\n",
        "\n",
        "\n",
        "class STGCNBlockWithAttention(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, A, kernel_size=9, stride=1, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.A = A\n",
        "        padding = (kernel_size - 1) // 2\n",
        "\n",
        "        self.gconv = SpatialGraphConv(in_channels, out_channels)\n",
        "\n",
        "        self.tconv = nn.Conv2d(out_channels, out_channels,\n",
        "                               kernel_size=(kernel_size, 1),\n",
        "                               padding=(padding, 0),\n",
        "                               stride=(stride, 1))\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.use_attention = use_attention\n",
        "        if use_attention:\n",
        "            self.temporal_attn = TemporalAttention(out_channels)\n",
        "            self.spatial_attn = SpatialAttention(out_channels)\n",
        "            self.channel_attn = ChannelAttention(out_channels)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        if (in_channels == out_channels) and (stride == 1):\n",
        "            self.residual = lambda x: x\n",
        "        else:\n",
        "            self.residual = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(stride, 1)),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        res = self.residual(x)\n",
        "        x = self.gconv(x, self.A)\n",
        "        x = self.tconv(x)\n",
        "        x = self.bn(x)\n",
        "        if self.use_attention:\n",
        "            x = self.temporal_attn(x)\n",
        "            x = self.spatial_attn(x)\n",
        "            x = self.channel_attn(x)\n",
        "\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + res\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 10,
      "outputs": [],
      "id": "czmHoHaGZ56Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8v4s0ZJZ56Q",
        "outputId": "66dfad5b-1f54-4c98-cf4a-6773dac67579"
      },
      "source": [
        "class STGCN(nn.Module):\n",
        "    def __init__(self, in_channels, num_class, A, base_channels=64, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.register_buffer('A', A)\n",
        "\n",
        "        # in_channels are 9 (3 positions + 3 velocity + 3 acceleration)\n",
        "        self.data_bn = nn.BatchNorm1d(in_channels * V)\n",
        "\n",
        "        # Multiple blocks with attention\n",
        "        self.layer1 = nn.Sequential(\n",
        "            STGCNBlockWithAttention(in_channels, base_channels, A, kernel_size=9, stride=1, use_attention=True),\n",
        "            STGCNBlockWithAttention(base_channels, base_channels, A, kernel_size=7, stride=1, use_attention=True),\n",
        "        )\n",
        "\n",
        "        # Downsample and extract higher-level features\n",
        "        self.layer2 = nn.Sequential(\n",
        "            STGCNBlockWithAttention(base_channels, base_channels*2, A, kernel_size=7, stride=2, use_attention=True),\n",
        "            STGCNBlockWithAttention(base_channels*2, base_channels*2, A, kernel_size=5, stride=1, use_attention=True),\n",
        "        )\n",
        "\n",
        "        # Downsampling with attention\n",
        "        self.layer3 = nn.Sequential(\n",
        "            STGCNBlockWithAttention(base_channels*2, base_channels*4, A, kernel_size=5, stride=2, use_attention=True),\n",
        "            STGCNBlockWithAttention(base_channels*4, base_channels*4, A, kernel_size=3, stride=1, use_attention=True),\n",
        "        )\n",
        "\n",
        "        # Global attention before pooling\n",
        "        self.global_temporal_attn = TemporalAttention(base_channels*4)\n",
        "        self.global_spatial_attn = SpatialAttention(base_channels*4)\n",
        "\n",
        "        # Pooling\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Classifier\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(base_channels*4, base_channels*2),\n",
        "            nn.BatchNorm1d(base_channels*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(base_channels*2, num_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, T, V = x.shape\n",
        "\n",
        "        # Data normalization\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        x = x.view(N, T, C*V).permute(0, 2, 1).contiguous()\n",
        "        x = self.data_bn(x)\n",
        "        x = x.permute(0, 2, 1).contiguous().view(N, T, C, V).permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        # Forward through layers\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        # global attention\n",
        "        x = self.global_temporal_attn(x)\n",
        "        x = self.global_spatial_attn(x)\n",
        "\n",
        "        # Pool and classify\n",
        "        x = self.pool(x).view(N, -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "num_classes = int(np.max(y) + 1)\n",
        "model = STGCN(in_channels=C, num_class=num_classes, A=A_torch, base_channels=64, dropout=0.5).to(device)\n",
        "print(model)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STGCN(\n",
            "  (data_bn): BatchNorm1d(531, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): STGCNBlockWithAttention(\n",
            "      (gconv): SpatialGraphConv(\n",
            "        (conv1x1): Conv2d(9, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (tconv): Conv2d(64, 64, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (temporal_attn): TemporalAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(None, 1))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (spatial_attn): SpatialAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(1, None))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (channel_attn): ChannelAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (residual): Sequential(\n",
            "        (0): Conv2d(9, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): STGCNBlockWithAttention(\n",
            "      (gconv): SpatialGraphConv(\n",
            "        (conv1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (tconv): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (temporal_attn): TemporalAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(None, 1))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (spatial_attn): SpatialAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(1, None))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (channel_attn): ChannelAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): STGCNBlockWithAttention(\n",
            "      (gconv): SpatialGraphConv(\n",
            "        (conv1x1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (tconv): Conv2d(128, 128, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0))\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (temporal_attn): TemporalAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(None, 1))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (spatial_attn): SpatialAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(1, None))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (channel_attn): ChannelAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (residual): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 1))\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): STGCNBlockWithAttention(\n",
            "      (gconv): SpatialGraphConv(\n",
            "        (conv1x1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (tconv): Conv2d(128, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (temporal_attn): TemporalAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(None, 1))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (spatial_attn): SpatialAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(1, None))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (channel_attn): ChannelAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): STGCNBlockWithAttention(\n",
            "      (gconv): SpatialGraphConv(\n",
            "        (conv1x1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (tconv): Conv2d(256, 256, kernel_size=(5, 1), stride=(2, 1), padding=(2, 0))\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (temporal_attn): TemporalAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(None, 1))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (spatial_attn): SpatialAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(1, None))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (channel_attn): ChannelAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (residual): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 1))\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): STGCNBlockWithAttention(\n",
            "      (gconv): SpatialGraphConv(\n",
            "        (conv1x1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (tconv): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (temporal_attn): TemporalAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(None, 1))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (spatial_attn): SpatialAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=(1, None))\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (channel_attn): ChannelAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "        (fc): Sequential(\n",
            "          (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (global_temporal_attn): TemporalAttention(\n",
            "    (avg_pool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "    (max_pool): AdaptiveMaxPool2d(output_size=(None, 1))\n",
            "    (fc): Sequential(\n",
            "      (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (3): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (global_spatial_attn): SpatialAttention(\n",
            "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, None))\n",
            "    (max_pool): AdaptiveMaxPool2d(output_size=(1, None))\n",
            "    (fc): Sequential(\n",
            "      (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (3): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.3, inplace=False)\n",
            "    (4): Linear(in_features=128, out_features=7, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "id": "z8v4s0ZJZ56Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "iXlzd3e5Z56Q"
      },
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "        _, pred = output.topk(maxk, 1, True, True) # (N, maxk)\n",
        "        pred = pred.t()  # (maxk, N)\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append((correct_k.mul_(100.0 / batch_size)).item())\n",
        "        return res"
      ],
      "execution_count": 13,
      "outputs": [],
      "id": "iXlzd3e5Z56Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8xiBVJuZ56Q",
        "outputId": "f9ac98f8-f93b-4a99-c722-867ca50782a3"
      },
      "source": [
        "print(\"X.shape =\", X.shape)\n",
        "print(\"A_torch.shape =\", A_torch.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape = (1401, 9, 100, 59)\n",
            "A_torch.shape = torch.Size([59, 59])\n"
          ]
        }
      ],
      "id": "H8xiBVJuZ56Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "R0hJ95BpZ56S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b318aad4-1c5a-4dad-fbaa-b8d097ff04ed"
      },
      "source": [
        "### Final\n",
        "### Batch Size 16\n",
        "import os, random, numpy as np, time\n",
        "import torch\n",
        "\n",
        "random_seed = 42\n",
        "n_splits = 5\n",
        "patience = 8\n",
        "\n",
        "# seed\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
        "fold_results = []\n",
        "all_preds = []\n",
        "all_trues = []\n",
        "best_models = []\n",
        "\n",
        "for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    print(f\"\\n=== Fold {fold+1}/{n_splits} ===\")\n",
        "    X_train, y_train = X[tr_idx], y[tr_idx]\n",
        "    X_val, y_val = X[val_idx], y[val_idx]\n",
        "    print(\"Train/Val sizes:\", X_train.shape[0], X_val.shape[0])\n",
        "\n",
        "    fixed_T = 100\n",
        "    train_ds = STGCNDataset(X_train, y_train, train=True, augment=True, fixed_T=fixed_T)\n",
        "    val_ds = STGCNDataset(X_val, y_val, train=False, augment=False, fixed_T=fixed_T)\n",
        "\n",
        "    batch_size = 32\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "                              num_workers=2, pin_memory=True, drop_last=True)  # ok\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
        "                            num_workers=2, pin_memory=True, drop_last=False)  # FIXED\n",
        "\n",
        "    config = {\n",
        "        'batch_size': 16,\n",
        "        'lr': 0.001,\n",
        "        'weight_decay': 1e-5,\n",
        "        'dropout': 0.5,\n",
        "        'epochs': 150,\n",
        "        'base_channels': 64,\n",
        "        'optimizer': 'AdamW',\n",
        "        'scheduler': 'CosineAnnealingWarmRestarts',\n",
        "    }\n",
        "\n",
        "    model = STGCN(in_channels=C, num_class=num_classes, A=A_torch,\n",
        "                  base_channels=config['base_channels'],\n",
        "                  dropout=config['dropout']).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config['lr'],\n",
        "                            weight_decay=config['weight_decay'], betas=(0.9, 0.999))\n",
        "\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
        "\n",
        "    num_epochs = config['epochs']\n",
        "    best_val_acc = 0.0\n",
        "    save_path = f\"stgcn_best_fold_{fold+1}_final.pth\"\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        t0 = time.time()\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        cnt = 0\n",
        "        for batch_idx, (xb, yb) in enumerate(train_loader):\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "            acc1 = float(accuracy(logits, yb, topk=(1,))[0])\n",
        "\n",
        "            running_loss += loss.item() * xb.size(0)\n",
        "            running_acc += acc1 * xb.size(0)\n",
        "            cnt += xb.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / cnt\n",
        "        epoch_acc = running_acc / cnt\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_acc = 0.0\n",
        "        vcnt = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb = xb.to(device)\n",
        "                yb = yb.to(device)\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "                acc1 = float(accuracy(logits, yb, topk=(1,))[0])\n",
        "                val_loss += loss.item() * xb.size(0)\n",
        "                val_acc += acc1 * xb.size(0)\n",
        "                vcnt += xb.size(0)\n",
        "\n",
        "        val_loss /= max(1, vcnt)\n",
        "        val_acc /= max(1, vcnt)\n",
        "\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        t1 = time.time()\n",
        "        print(f\"Epoch {epoch:02d}/{num_epochs} | \"\n",
        "              f\"train_loss {epoch_loss:.4f} train_acc {epoch_acc:.2f}% | \"\n",
        "              f\"val_loss {val_loss:.4f} val_acc {val_acc:.2f}% | time {(t1-t0):.1f}s\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save({'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'val_acc': val_acc},\n",
        "                       save_path)\n",
        "            epochs_no_improve = 0\n",
        "            best_models.append(save_path)   # track saved model\n",
        "            print(\"Saved best model at epoch\", epoch, \"val_acc\", val_acc)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "    fold_results.append({'fold': fold+1, 'best_val_acc': best_val_acc})\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1/5 ===\n",
            "Train/Val sizes: 1120 281\n",
            "Epoch 01/150 | train_loss 1.9216 train_acc 20.09% | val_loss 1.9593 val_acc 14.59% | time 14.8s\n",
            "Saved best model at epoch 1 val_acc 14.590747330960854\n",
            "Epoch 02/150 | train_loss 1.8038 train_acc 26.96% | val_loss 1.8977 val_acc 21.35% | time 13.2s\n",
            "Saved best model at epoch 2 val_acc 21.352313167259787\n",
            "Epoch 03/150 | train_loss 1.7490 train_acc 28.84% | val_loss 1.7174 val_acc 30.60% | time 13.3s\n",
            "Saved best model at epoch 3 val_acc 30.604982206405694\n",
            "Epoch 04/150 | train_loss 1.6628 train_acc 34.91% | val_loss 1.7121 val_acc 32.03% | time 13.5s\n",
            "Saved best model at epoch 4 val_acc 32.02846975088968\n",
            "Epoch 05/150 | train_loss 1.6203 train_acc 35.27% | val_loss 1.6488 val_acc 35.59% | time 13.7s\n",
            "Saved best model at epoch 5 val_acc 35.587188612099645\n",
            "Epoch 06/150 | train_loss 1.5328 train_acc 40.62% | val_loss 1.6116 val_acc 35.94% | time 13.9s\n",
            "Saved best model at epoch 6 val_acc 35.94306049822064\n",
            "Epoch 07/150 | train_loss 1.4592 train_acc 43.84% | val_loss 1.5825 val_acc 39.15% | time 14.1s\n",
            "Saved best model at epoch 7 val_acc 39.145907473309606\n",
            "Epoch 08/150 | train_loss 1.4110 train_acc 45.54% | val_loss 1.5385 val_acc 39.15% | time 13.9s\n",
            "Epoch 09/150 | train_loss 1.3513 train_acc 50.18% | val_loss 1.5373 val_acc 40.57% | time 13.8s\n",
            "Saved best model at epoch 9 val_acc 40.569395017793596\n",
            "Epoch 10/150 | train_loss 1.3326 train_acc 49.11% | val_loss 1.5267 val_acc 38.43% | time 13.7s\n",
            "Epoch 11/150 | train_loss 1.4315 train_acc 44.20% | val_loss 1.6216 val_acc 31.67% | time 13.7s\n",
            "Epoch 12/150 | train_loss 1.3960 train_acc 46.70% | val_loss 1.5609 val_acc 40.57% | time 13.8s\n",
            "Epoch 13/150 | train_loss 1.3293 train_acc 48.57% | val_loss 1.6517 val_acc 40.57% | time 13.9s\n",
            "Epoch 14/150 | train_loss 1.2551 train_acc 51.70% | val_loss 1.5458 val_acc 45.20% | time 14.0s\n",
            "Saved best model at epoch 14 val_acc 45.195729537366546\n",
            "Epoch 15/150 | train_loss 1.2178 train_acc 53.04% | val_loss 1.5347 val_acc 40.93% | time 13.8s\n",
            "Epoch 16/150 | train_loss 1.1778 train_acc 55.80% | val_loss 1.5540 val_acc 40.93% | time 13.8s\n",
            "Epoch 17/150 | train_loss 1.1438 train_acc 57.32% | val_loss 1.6687 val_acc 40.21% | time 13.8s\n",
            "Epoch 18/150 | train_loss 1.0376 train_acc 61.79% | val_loss 1.5032 val_acc 46.26% | time 13.8s\n",
            "Saved best model at epoch 18 val_acc 46.263345195729535\n",
            "Epoch 19/150 | train_loss 0.9619 train_acc 63.66% | val_loss 1.4750 val_acc 42.35% | time 13.8s\n",
            "Epoch 20/150 | train_loss 0.9296 train_acc 65.62% | val_loss 1.5257 val_acc 45.55% | time 13.9s\n",
            "Epoch 21/150 | train_loss 0.8660 train_acc 68.04% | val_loss 1.4637 val_acc 45.55% | time 14.0s\n",
            "Epoch 22/150 | train_loss 0.7878 train_acc 70.09% | val_loss 1.4770 val_acc 48.04% | time 13.9s\n",
            "Saved best model at epoch 22 val_acc 48.04270462633452\n",
            "Epoch 23/150 | train_loss 0.7448 train_acc 73.30% | val_loss 1.3963 val_acc 49.47% | time 13.9s\n",
            "Saved best model at epoch 23 val_acc 49.4661921708185\n",
            "Epoch 24/150 | train_loss 0.6833 train_acc 75.80% | val_loss 1.4144 val_acc 48.04% | time 13.8s\n",
            "Epoch 25/150 | train_loss 0.6527 train_acc 77.32% | val_loss 1.4282 val_acc 51.60% | time 13.8s\n",
            "Saved best model at epoch 25 val_acc 51.60142348754449\n",
            "Epoch 26/150 | train_loss 0.6080 train_acc 78.57% | val_loss 1.3919 val_acc 51.60% | time 14.0s\n",
            "Epoch 27/150 | train_loss 0.5775 train_acc 81.07% | val_loss 1.4342 val_acc 49.47% | time 13.9s\n",
            "Epoch 28/150 | train_loss 0.5560 train_acc 82.77% | val_loss 1.3789 val_acc 51.96% | time 13.9s\n",
            "Saved best model at epoch 28 val_acc 51.95729537366548\n",
            "Epoch 29/150 | train_loss 0.5393 train_acc 82.95% | val_loss 1.3790 val_acc 53.02% | time 13.8s\n",
            "Saved best model at epoch 29 val_acc 53.02491103202847\n",
            "Epoch 30/150 | train_loss 0.5256 train_acc 83.12% | val_loss 1.3848 val_acc 51.25% | time 13.8s\n",
            "Epoch 31/150 | train_loss 0.7322 train_acc 74.55% | val_loss 2.0340 val_acc 43.42% | time 13.8s\n",
            "Epoch 32/150 | train_loss 0.9794 train_acc 64.73% | val_loss 1.7830 val_acc 45.91% | time 13.8s\n",
            "Epoch 33/150 | train_loss 0.8121 train_acc 69.82% | val_loss 1.5590 val_acc 49.11% | time 13.8s\n",
            "Epoch 34/150 | train_loss 0.7307 train_acc 75.09% | val_loss 1.6150 val_acc 47.33% | time 13.9s\n",
            "Epoch 35/150 | train_loss 0.7318 train_acc 73.57% | val_loss 1.6025 val_acc 49.47% | time 13.9s\n",
            "Epoch 36/150 | train_loss 0.6647 train_acc 77.05% | val_loss 1.6880 val_acc 49.11% | time 13.8s\n",
            "Epoch 37/150 | train_loss 0.5678 train_acc 79.82% | val_loss 1.6892 val_acc 46.62% | time 13.8s\n",
            "Early stopping\n",
            "\n",
            "=== Fold 2/5 ===\n",
            "Train/Val sizes: 1121 280\n",
            "Epoch 01/150 | train_loss 1.9353 train_acc 20.80% | val_loss 1.9298 val_acc 16.79% | time 13.8s\n",
            "Saved best model at epoch 1 val_acc 16.785714176722934\n",
            "Epoch 02/150 | train_loss 1.8415 train_acc 24.82% | val_loss 1.8393 val_acc 25.00% | time 13.8s\n",
            "Saved best model at epoch 2 val_acc 24.999999782017298\n",
            "Epoch 03/150 | train_loss 1.7696 train_acc 27.77% | val_loss 1.7598 val_acc 26.07% | time 13.8s\n",
            "Saved best model at epoch 3 val_acc 26.07142835344587\n",
            "Epoch 04/150 | train_loss 1.7176 train_acc 31.43% | val_loss 1.7478 val_acc 29.29% | time 13.9s\n",
            "Saved best model at epoch 4 val_acc 29.285714285714285\n",
            "Epoch 05/150 | train_loss 1.6736 train_acc 33.04% | val_loss 1.6451 val_acc 35.71% | time 13.9s\n",
            "Saved best model at epoch 5 val_acc 35.714285605294364\n",
            "Epoch 06/150 | train_loss 1.6219 train_acc 36.43% | val_loss 1.6428 val_acc 37.14% | time 13.8s\n",
            "Saved best model at epoch 6 val_acc 37.142856924874444\n",
            "Epoch 07/150 | train_loss 1.5431 train_acc 39.55% | val_loss 1.5976 val_acc 38.93% | time 13.8s\n",
            "Saved best model at epoch 7 val_acc 38.92857131958008\n",
            "Epoch 08/150 | train_loss 1.4994 train_acc 42.77% | val_loss 1.5768 val_acc 39.64% | time 13.8s\n",
            "Saved best model at epoch 8 val_acc 39.642857142857146\n",
            "Epoch 09/150 | train_loss 1.4660 train_acc 43.12% | val_loss 1.5600 val_acc 39.64% | time 13.8s\n",
            "Epoch 10/150 | train_loss 1.4518 train_acc 44.20% | val_loss 1.5673 val_acc 38.57% | time 13.8s\n",
            "Epoch 11/150 | train_loss 1.5205 train_acc 42.68% | val_loss 1.7505 val_acc 37.50% | time 14.0s\n",
            "Epoch 12/150 | train_loss 1.4772 train_acc 44.20% | val_loss 1.5177 val_acc 42.86% | time 13.9s\n",
            "Saved best model at epoch 12 val_acc 42.85714263916016\n",
            "Epoch 13/150 | train_loss 1.4308 train_acc 44.38% | val_loss 1.5289 val_acc 43.93% | time 13.8s\n",
            "Saved best model at epoch 13 val_acc 43.92857137407575\n",
            "Epoch 14/150 | train_loss 1.3478 train_acc 47.41% | val_loss 1.4718 val_acc 42.86% | time 13.8s\n",
            "Epoch 15/150 | train_loss 1.2638 train_acc 52.41% | val_loss 1.4125 val_acc 46.07% | time 13.8s\n",
            "Saved best model at epoch 15 val_acc 46.07142857142857\n",
            "Epoch 16/150 | train_loss 1.1844 train_acc 56.16% | val_loss 1.4217 val_acc 47.14% | time 13.8s\n",
            "Saved best model at epoch 16 val_acc 47.142857142857146\n",
            "Epoch 17/150 | train_loss 1.1626 train_acc 57.41% | val_loss 1.3465 val_acc 50.00% | time 13.9s\n",
            "Saved best model at epoch 17 val_acc 49.99999989100865\n",
            "Epoch 18/150 | train_loss 1.1047 train_acc 58.12% | val_loss 1.3207 val_acc 52.86% | time 13.9s\n",
            "Saved best model at epoch 18 val_acc 52.85714274815151\n",
            "Epoch 19/150 | train_loss 1.0496 train_acc 60.54% | val_loss 1.4497 val_acc 52.14% | time 13.8s\n",
            "Epoch 20/150 | train_loss 0.9594 train_acc 65.27% | val_loss 1.3250 val_acc 52.86% | time 13.8s\n",
            "Saved best model at epoch 20 val_acc 52.857142857142854\n",
            "Epoch 21/150 | train_loss 0.8880 train_acc 69.82% | val_loss 1.3290 val_acc 50.36% | time 13.8s\n",
            "Epoch 22/150 | train_loss 0.8143 train_acc 72.32% | val_loss 1.3471 val_acc 53.21% | time 13.8s\n",
            "Saved best model at epoch 22 val_acc 53.214285605294364\n",
            "Epoch 23/150 | train_loss 0.7834 train_acc 73.21% | val_loss 1.3812 val_acc 55.00% | time 13.8s\n",
            "Saved best model at epoch 23 val_acc 54.99999967302595\n",
            "Epoch 24/150 | train_loss 0.7125 train_acc 76.16% | val_loss 1.3509 val_acc 52.14% | time 13.8s\n",
            "Epoch 25/150 | train_loss 0.6929 train_acc 75.54% | val_loss 1.3140 val_acc 52.86% | time 14.0s\n",
            "Epoch 26/150 | train_loss 0.6509 train_acc 77.23% | val_loss 1.3304 val_acc 53.21% | time 13.8s\n",
            "Epoch 27/150 | train_loss 0.5930 train_acc 81.61% | val_loss 1.3414 val_acc 53.93% | time 13.8s\n",
            "Epoch 28/150 | train_loss 0.5734 train_acc 82.59% | val_loss 1.3419 val_acc 53.93% | time 13.8s\n",
            "Epoch 29/150 | train_loss 0.5522 train_acc 81.07% | val_loss 1.3522 val_acc 52.14% | time 13.8s\n",
            "Epoch 30/150 | train_loss 0.5457 train_acc 83.93% | val_loss 1.3471 val_acc 52.50% | time 13.8s\n",
            "Epoch 31/150 | train_loss 0.8038 train_acc 70.80% | val_loss 1.9574 val_acc 44.29% | time 13.9s\n",
            "Early stopping\n",
            "\n",
            "=== Fold 3/5 ===\n",
            "Train/Val sizes: 1121 280\n",
            "Epoch 01/150 | train_loss 1.9355 train_acc 19.64% | val_loss 1.9575 val_acc 16.79% | time 14.0s\n",
            "Saved best model at epoch 1 val_acc 16.78571423121861\n",
            "Epoch 02/150 | train_loss 1.8063 train_acc 25.36% | val_loss 1.8639 val_acc 23.21% | time 13.8s\n",
            "Saved best model at epoch 2 val_acc 23.21428565979004\n",
            "Epoch 03/150 | train_loss 1.7787 train_acc 26.96% | val_loss 1.7609 val_acc 30.36% | time 13.8s\n",
            "Saved best model at epoch 3 val_acc 30.357142857142858\n",
            "Epoch 04/150 | train_loss 1.7207 train_acc 28.39% | val_loss 1.7188 val_acc 34.29% | time 13.8s\n",
            "Saved best model at epoch 4 val_acc 34.285714176722934\n",
            "Epoch 05/150 | train_loss 1.6710 train_acc 33.21% | val_loss 1.6555 val_acc 38.93% | time 13.8s\n",
            "Saved best model at epoch 5 val_acc 38.92857137407575\n",
            "Epoch 06/150 | train_loss 1.6078 train_acc 36.16% | val_loss 1.6080 val_acc 37.86% | time 13.8s\n",
            "Epoch 07/150 | train_loss 1.5270 train_acc 40.18% | val_loss 1.5407 val_acc 40.71% | time 13.9s\n",
            "Saved best model at epoch 7 val_acc 40.714285714285715\n",
            "Epoch 08/150 | train_loss 1.4667 train_acc 43.04% | val_loss 1.5394 val_acc 41.43% | time 13.9s\n",
            "Saved best model at epoch 8 val_acc 41.42857121058873\n",
            "Epoch 09/150 | train_loss 1.4188 train_acc 46.61% | val_loss 1.4836 val_acc 43.57% | time 13.8s\n",
            "Saved best model at epoch 9 val_acc 43.57142846243722\n",
            "Epoch 10/150 | train_loss 1.3733 train_acc 48.48% | val_loss 1.4819 val_acc 43.57% | time 13.8s\n",
            "Saved best model at epoch 10 val_acc 43.5714285169329\n",
            "Epoch 11/150 | train_loss 1.5386 train_acc 40.18% | val_loss 1.6082 val_acc 38.57% | time 13.8s\n",
            "Epoch 12/150 | train_loss 1.4530 train_acc 44.64% | val_loss 1.4361 val_acc 45.36% | time 13.8s\n",
            "Saved best model at epoch 12 val_acc 45.357142857142854\n",
            "Epoch 13/150 | train_loss 1.3359 train_acc 48.57% | val_loss 1.3935 val_acc 45.00% | time 13.9s\n",
            "Epoch 14/150 | train_loss 1.3021 train_acc 50.45% | val_loss 1.4678 val_acc 44.64% | time 13.9s\n",
            "Epoch 15/150 | train_loss 1.2182 train_acc 53.75% | val_loss 1.3844 val_acc 48.21% | time 13.9s\n",
            "Saved best model at epoch 15 val_acc 48.214285714285715\n",
            "Epoch 16/150 | train_loss 1.1884 train_acc 55.45% | val_loss 1.5729 val_acc 50.00% | time 13.9s\n",
            "Saved best model at epoch 16 val_acc 49.9999997820173\n",
            "Epoch 17/150 | train_loss 1.1158 train_acc 57.68% | val_loss 1.3773 val_acc 53.21% | time 13.8s\n",
            "Saved best model at epoch 17 val_acc 53.214285605294364\n",
            "Epoch 18/150 | train_loss 1.0498 train_acc 59.91% | val_loss 1.3427 val_acc 51.07% | time 13.8s\n",
            "Epoch 19/150 | train_loss 1.0633 train_acc 60.54% | val_loss 1.2673 val_acc 56.07% | time 13.8s\n",
            "Saved best model at epoch 19 val_acc 56.07142846243722\n",
            "Epoch 20/150 | train_loss 0.9407 train_acc 65.00% | val_loss 1.3209 val_acc 53.57% | time 13.8s\n",
            "Epoch 21/150 | train_loss 0.9147 train_acc 65.18% | val_loss 1.3811 val_acc 55.00% | time 13.9s\n",
            "Epoch 22/150 | train_loss 0.8372 train_acc 69.73% | val_loss 1.2992 val_acc 56.43% | time 13.9s\n",
            "Saved best model at epoch 22 val_acc 56.42857121058873\n",
            "Epoch 23/150 | train_loss 0.7625 train_acc 71.88% | val_loss 1.2648 val_acc 56.79% | time 13.8s\n",
            "Saved best model at epoch 23 val_acc 56.78571406773158\n",
            "Epoch 24/150 | train_loss 0.7234 train_acc 74.29% | val_loss 1.2659 val_acc 56.07% | time 13.8s\n",
            "Epoch 25/150 | train_loss 0.6609 train_acc 76.88% | val_loss 1.1924 val_acc 61.43% | time 13.8s\n",
            "Saved best model at epoch 25 val_acc 61.42857121058873\n",
            "Epoch 26/150 | train_loss 0.6433 train_acc 77.59% | val_loss 1.2075 val_acc 61.79% | time 13.8s\n",
            "Saved best model at epoch 26 val_acc 61.785714285714285\n",
            "Epoch 27/150 | train_loss 0.6501 train_acc 76.88% | val_loss 1.1703 val_acc 62.86% | time 13.8s\n",
            "Saved best model at epoch 27 val_acc 62.85714263916016\n",
            "Epoch 28/150 | train_loss 0.5795 train_acc 80.89% | val_loss 1.1832 val_acc 61.43% | time 13.9s\n",
            "Epoch 29/150 | train_loss 0.5715 train_acc 80.09% | val_loss 1.1704 val_acc 61.79% | time 13.9s\n",
            "Epoch 30/150 | train_loss 0.5711 train_acc 80.36% | val_loss 1.1683 val_acc 62.14% | time 13.8s\n",
            "Epoch 31/150 | train_loss 0.8715 train_acc 68.30% | val_loss 2.5382 val_acc 40.36% | time 13.8s\n",
            "Epoch 32/150 | train_loss 1.0066 train_acc 62.95% | val_loss 1.3180 val_acc 53.93% | time 13.8s\n",
            "Epoch 33/150 | train_loss 0.8209 train_acc 70.36% | val_loss 1.3512 val_acc 54.29% | time 13.8s\n",
            "Epoch 34/150 | train_loss 0.7768 train_acc 70.27% | val_loss 1.4067 val_acc 52.86% | time 13.9s\n",
            "Epoch 35/150 | train_loss 0.7131 train_acc 75.00% | val_loss 1.5518 val_acc 52.86% | time 13.9s\n",
            "Early stopping\n",
            "\n",
            "=== Fold 4/5 ===\n",
            "Train/Val sizes: 1121 280\n",
            "Epoch 01/150 | train_loss 1.9511 train_acc 19.02% | val_loss 1.9268 val_acc 17.14% | time 13.9s\n",
            "Saved best model at epoch 1 val_acc 17.142857088361467\n",
            "Epoch 02/150 | train_loss 1.8394 train_acc 25.27% | val_loss 1.7937 val_acc 26.79% | time 13.8s\n",
            "Saved best model at epoch 2 val_acc 26.785714067731586\n",
            "Epoch 03/150 | train_loss 1.7645 train_acc 27.95% | val_loss 1.6791 val_acc 32.14% | time 13.8s\n",
            "Saved best model at epoch 3 val_acc 32.142856924874444\n",
            "Epoch 04/150 | train_loss 1.7063 train_acc 30.45% | val_loss 1.6883 val_acc 34.29% | time 13.8s\n",
            "Saved best model at epoch 4 val_acc 34.285714285714285\n",
            "Epoch 05/150 | train_loss 1.6688 train_acc 34.02% | val_loss 1.6186 val_acc 37.50% | time 13.8s\n",
            "Saved best model at epoch 5 val_acc 37.4999997820173\n",
            "Epoch 06/150 | train_loss 1.5879 train_acc 38.93% | val_loss 1.5654 val_acc 39.64% | time 13.8s\n",
            "Saved best model at epoch 6 val_acc 39.642857142857146\n",
            "Epoch 07/150 | train_loss 1.5284 train_acc 39.91% | val_loss 1.5551 val_acc 39.64% | time 13.9s\n",
            "Epoch 08/150 | train_loss 1.4729 train_acc 45.18% | val_loss 1.4884 val_acc 41.79% | time 13.9s\n",
            "Saved best model at epoch 8 val_acc 41.785714176722934\n",
            "Epoch 09/150 | train_loss 1.4176 train_acc 46.52% | val_loss 1.4687 val_acc 40.00% | time 13.8s\n",
            "Epoch 10/150 | train_loss 1.3922 train_acc 46.96% | val_loss 1.4619 val_acc 41.43% | time 13.8s\n",
            "Epoch 11/150 | train_loss 1.4502 train_acc 46.16% | val_loss 1.5571 val_acc 38.93% | time 13.8s\n",
            "Epoch 12/150 | train_loss 1.4553 train_acc 43.93% | val_loss 1.4797 val_acc 41.43% | time 13.8s\n",
            "Epoch 13/150 | train_loss 1.3456 train_acc 50.62% | val_loss 1.4139 val_acc 45.71% | time 13.8s\n",
            "Saved best model at epoch 13 val_acc 45.714285714285715\n",
            "Epoch 14/150 | train_loss 1.2874 train_acc 51.34% | val_loss 1.6646 val_acc 39.29% | time 13.8s\n",
            "Epoch 15/150 | train_loss 1.2782 train_acc 52.59% | val_loss 1.5429 val_acc 42.50% | time 14.0s\n",
            "Epoch 16/150 | train_loss 1.2006 train_acc 54.29% | val_loss 1.4060 val_acc 48.93% | time 13.8s\n",
            "Saved best model at epoch 16 val_acc 48.92857142857143\n",
            "Epoch 17/150 | train_loss 1.0768 train_acc 60.45% | val_loss 1.3439 val_acc 49.64% | time 13.8s\n",
            "Saved best model at epoch 17 val_acc 49.642856924874444\n",
            "Epoch 18/150 | train_loss 1.0336 train_acc 62.05% | val_loss 1.3056 val_acc 54.29% | time 13.8s\n",
            "Saved best model at epoch 18 val_acc 54.285714285714285\n",
            "Epoch 19/150 | train_loss 0.9913 train_acc 62.77% | val_loss 1.3715 val_acc 52.14% | time 13.8s\n",
            "Epoch 20/150 | train_loss 0.9592 train_acc 64.91% | val_loss 1.2352 val_acc 55.36% | time 13.8s\n",
            "Saved best model at epoch 20 val_acc 55.35714274815151\n",
            "Epoch 21/150 | train_loss 0.8626 train_acc 68.57% | val_loss 1.2624 val_acc 55.71% | time 13.8s\n",
            "Saved best model at epoch 21 val_acc 55.71428549630301\n",
            "Epoch 22/150 | train_loss 0.7908 train_acc 71.61% | val_loss 1.3189 val_acc 50.71% | time 14.0s\n",
            "Epoch 23/150 | train_loss 0.7554 train_acc 72.68% | val_loss 1.2483 val_acc 53.93% | time 13.8s\n",
            "Epoch 24/150 | train_loss 0.6921 train_acc 75.80% | val_loss 1.2995 val_acc 51.79% | time 13.8s\n",
            "Epoch 25/150 | train_loss 0.6293 train_acc 79.11% | val_loss 1.3650 val_acc 51.07% | time 13.8s\n",
            "Epoch 26/150 | train_loss 0.6234 train_acc 79.29% | val_loss 1.3381 val_acc 53.57% | time 13.8s\n",
            "Epoch 27/150 | train_loss 0.5845 train_acc 80.45% | val_loss 1.3186 val_acc 53.21% | time 13.8s\n",
            "Epoch 28/150 | train_loss 0.5529 train_acc 81.25% | val_loss 1.3386 val_acc 52.14% | time 13.8s\n",
            "Epoch 29/150 | train_loss 0.5084 train_acc 83.39% | val_loss 1.3483 val_acc 52.50% | time 13.9s\n",
            "Early stopping\n",
            "\n",
            "=== Fold 5/5 ===\n",
            "Train/Val sizes: 1121 280\n",
            "Epoch 01/150 | train_loss 1.9347 train_acc 19.55% | val_loss 1.9209 val_acc 17.14% | time 13.8s\n",
            "Saved best model at epoch 1 val_acc 17.142857142857142\n",
            "Epoch 02/150 | train_loss 1.8502 train_acc 23.30% | val_loss 1.8159 val_acc 26.43% | time 13.8s\n",
            "Saved best model at epoch 2 val_acc 26.42857121058873\n",
            "Epoch 03/150 | train_loss 1.7827 train_acc 26.43% | val_loss 1.7135 val_acc 33.21% | time 13.8s\n",
            "Saved best model at epoch 3 val_acc 33.21428549630301\n",
            "Epoch 04/150 | train_loss 1.7294 train_acc 29.55% | val_loss 1.6476 val_acc 36.43% | time 13.8s\n",
            "Saved best model at epoch 4 val_acc 36.42857121058873\n",
            "Epoch 05/150 | train_loss 1.6682 train_acc 32.86% | val_loss 1.6460 val_acc 36.79% | time 13.8s\n",
            "Saved best model at epoch 5 val_acc 36.785714285714285\n",
            "Epoch 06/150 | train_loss 1.6212 train_acc 36.43% | val_loss 1.5901 val_acc 41.79% | time 14.0s\n",
            "Saved best model at epoch 6 val_acc 41.78571395874023\n",
            "Epoch 07/150 | train_loss 1.5261 train_acc 40.27% | val_loss 1.5158 val_acc 44.29% | time 13.8s\n",
            "Saved best model at epoch 7 val_acc 44.285714285714285\n",
            "Epoch 08/150 | train_loss 1.4677 train_acc 44.46% | val_loss 1.4844 val_acc 43.21% | time 13.8s\n",
            "Epoch 09/150 | train_loss 1.4083 train_acc 47.59% | val_loss 1.4692 val_acc 44.29% | time 13.9s\n",
            "Epoch 10/150 | train_loss 1.3942 train_acc 45.54% | val_loss 1.4546 val_acc 46.07% | time 13.8s\n",
            "Saved best model at epoch 10 val_acc 46.07142835344587\n",
            "Epoch 11/150 | train_loss 1.4866 train_acc 41.61% | val_loss 1.4797 val_acc 45.71% | time 13.9s\n",
            "Epoch 12/150 | train_loss 1.4539 train_acc 42.95% | val_loss 1.4651 val_acc 45.00% | time 14.0s\n",
            "Epoch 13/150 | train_loss 1.3860 train_acc 47.41% | val_loss 1.3956 val_acc 42.50% | time 13.8s\n",
            "Epoch 14/150 | train_loss 1.2759 train_acc 50.54% | val_loss 1.3834 val_acc 44.29% | time 13.8s\n",
            "Epoch 15/150 | train_loss 1.2545 train_acc 52.32% | val_loss 1.3699 val_acc 45.71% | time 13.8s\n",
            "Epoch 16/150 | train_loss 1.1937 train_acc 55.09% | val_loss 1.3734 val_acc 47.50% | time 13.8s\n",
            "Saved best model at epoch 16 val_acc 47.49999994550433\n",
            "Epoch 17/150 | train_loss 1.0675 train_acc 60.89% | val_loss 1.2706 val_acc 44.64% | time 13.8s\n",
            "Epoch 18/150 | train_loss 1.0162 train_acc 62.77% | val_loss 1.2990 val_acc 51.07% | time 13.9s\n",
            "Saved best model at epoch 18 val_acc 51.07142835344587\n",
            "Epoch 19/150 | train_loss 0.9725 train_acc 65.00% | val_loss 1.3249 val_acc 51.79% | time 13.8s\n",
            "Saved best model at epoch 19 val_acc 51.785714176722934\n",
            "Epoch 20/150 | train_loss 0.8904 train_acc 68.66% | val_loss 1.3699 val_acc 53.93% | time 13.8s\n",
            "Saved best model at epoch 20 val_acc 53.92857121058873\n",
            "Epoch 21/150 | train_loss 0.8249 train_acc 70.18% | val_loss 1.3630 val_acc 48.93% | time 13.8s\n",
            "Epoch 22/150 | train_loss 0.8068 train_acc 71.43% | val_loss 1.2755 val_acc 53.21% | time 13.8s\n",
            "Epoch 23/150 | train_loss 0.7147 train_acc 75.80% | val_loss 1.2711 val_acc 53.21% | time 13.9s\n",
            "Epoch 24/150 | train_loss 0.6840 train_acc 75.89% | val_loss 1.2576 val_acc 52.50% | time 13.9s\n",
            "Epoch 25/150 | train_loss 0.6445 train_acc 77.23% | val_loss 1.2779 val_acc 52.14% | time 13.8s\n",
            "Epoch 26/150 | train_loss 0.5538 train_acc 82.41% | val_loss 1.2047 val_acc 54.64% | time 13.8s\n",
            "Saved best model at epoch 26 val_acc 54.64285681588309\n",
            "Epoch 27/150 | train_loss 0.5643 train_acc 80.18% | val_loss 1.2698 val_acc 51.79% | time 13.8s\n",
            "Epoch 28/150 | train_loss 0.5348 train_acc 82.86% | val_loss 1.2242 val_acc 55.71% | time 13.8s\n",
            "Saved best model at epoch 28 val_acc 55.714285605294364\n",
            "Epoch 29/150 | train_loss 0.5184 train_acc 85.45% | val_loss 1.2329 val_acc 55.36% | time 13.8s\n",
            "Epoch 30/150 | train_loss 0.5131 train_acc 84.20% | val_loss 1.2293 val_acc 55.36% | time 13.9s\n",
            "Epoch 31/150 | train_loss 0.7289 train_acc 73.66% | val_loss 1.4611 val_acc 53.21% | time 13.9s\n",
            "Epoch 32/150 | train_loss 0.9065 train_acc 67.32% | val_loss 1.7366 val_acc 44.29% | time 13.8s\n",
            "Epoch 33/150 | train_loss 0.8404 train_acc 69.38% | val_loss 1.2593 val_acc 56.79% | time 13.8s\n",
            "Saved best model at epoch 33 val_acc 56.78571406773158\n",
            "Epoch 34/150 | train_loss 0.6719 train_acc 76.16% | val_loss 1.6045 val_acc 52.50% | time 13.8s\n",
            "Epoch 35/150 | train_loss 0.6711 train_acc 76.25% | val_loss 1.3956 val_acc 52.86% | time 13.8s\n",
            "Epoch 36/150 | train_loss 0.5838 train_acc 78.57% | val_loss 1.5181 val_acc 51.79% | time 13.9s\n",
            "Epoch 37/150 | train_loss 0.5476 train_acc 82.50% | val_loss 1.4425 val_acc 55.36% | time 13.9s\n",
            "Epoch 38/150 | train_loss 0.5230 train_acc 81.43% | val_loss 1.7328 val_acc 47.14% | time 13.8s\n",
            "Epoch 39/150 | train_loss 0.4787 train_acc 83.21% | val_loss 1.6368 val_acc 47.86% | time 13.8s\n",
            "Epoch 40/150 | train_loss 0.4487 train_acc 84.46% | val_loss 1.8941 val_acc 50.71% | time 13.8s\n",
            "Epoch 41/150 | train_loss 0.4418 train_acc 85.54% | val_loss 1.5747 val_acc 56.79% | time 13.8s\n",
            "Early stopping\n"
          ]
        }
      ],
      "id": "R0hJ95BpZ56S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation of Resuls"
      ],
      "metadata": {
        "id": "SSthZRQT7bEb"
      },
      "id": "SSthZRQT7bEb"
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "9lyv7oQS-WYT"
      },
      "id": "9lyv7oQS-WYT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 32\n",
        "fixed_T = 100\n",
        "\n",
        "best_models =[]\n",
        "best_models =[\"stgcn_best_fold_1_final.pth\", \"stgcn_best_fold_2_final.pth\",\"stgcn_best_fold_3_final.pth\", \"stgcn_best_fold_4_final.pth\", \"stgcn_best_fold_5_final.pth\"]\n",
        "\n",
        "with open('best_models.json', 'w') as f:\n",
        "    json.dump(best_models, f)\n",
        "\n",
        "\n",
        "best_models = json.load(open('best_models.json'))\n",
        "\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_val_indices = [val_idx.copy() for _, val_idx in skf.split(X, y)]\n",
        "\n",
        "per_fold_trues = []\n",
        "per_fold_preds = []\n",
        "\n",
        "for fold_idx, ckpt_path in enumerate(best_models):\n",
        "    print(f\"Evaluating fold {fold_idx+1}/{len(best_models)} -> {ckpt_path}\")\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "\n",
        "\n",
        "    model = STGCN(in_channels=C, num_class=num_classes, A=A_torch,\n",
        "                  base_channels=64, dropout=0.5).to(device)\n",
        "    model.load_state_dict(ckpt['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    val_idx = np.asarray(fold_val_indices[fold_idx])\n",
        "    X_val = X[val_idx]\n",
        "    y_val = y[val_idx]\n",
        "\n",
        "    val_ds = STGCNDataset(X_val, y_val, train=False, augment=False, fixed_T=fixed_T)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, drop_last=False)\n",
        "\n",
        "    fold_preds = []\n",
        "    fold_trues = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device)\n",
        "            logits = model(xb)\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            fold_preds.append(preds)\n",
        "            fold_trues.append(yb.numpy())\n",
        "\n",
        "    fold_preds = np.concatenate(fold_preds, axis=0)\n",
        "    fold_trues = np.concatenate(fold_trues, axis=0)\n",
        "    acc = accuracy_score(fold_trues, fold_preds)\n",
        "    print(f\"  fold acc: {acc:.4f}  (#val samples: {len(fold_trues)})\")\n",
        "\n",
        "    per_fold_trues.append(fold_trues)\n",
        "    per_fold_preds.append(fold_preds)\n",
        "\n",
        "model_name = 'STGCN_cv'\n",
        "results_per_fold = {\n",
        "    model_name: {\n",
        "        'y_trues': per_fold_trues,\n",
        "        'y_preds': per_fold_preds\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGuL1agQ7ZSv",
        "outputId": "113fca3d-02b9-4c8c-d91b-5f055fbd9f27"
      },
      "id": "NGuL1agQ7ZSv",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating fold 1/5 -> stgcn_best_fold_1_final.pth\n",
            "  fold acc: 0.5302  (#val samples: 281)\n",
            "Evaluating fold 2/5 -> stgcn_best_fold_2_final.pth\n",
            "  fold acc: 0.5500  (#val samples: 280)\n",
            "Evaluating fold 3/5 -> stgcn_best_fold_3_final.pth\n",
            "  fold acc: 0.6286  (#val samples: 280)\n",
            "Evaluating fold 4/5 -> stgcn_best_fold_4_final.pth\n",
            "  fold acc: 0.5571  (#val samples: 280)\n",
            "Evaluating fold 5/5 -> stgcn_best_fold_5_final.pth\n",
            "  fold acc: 0.5679  (#val samples: 280)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('results_per_fold_stgcn.npy', results_per_fold)"
      ],
      "metadata": {
        "id": "gbivh-fm7kkr"
      },
      "id": "gbivh-fm7kkr",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_aggregated_confusion_matrix(results_dict, save_path='confusion_matrix_stgcn.png', normalize=True, cmap='Blues'):\n",
        "\n",
        "    model_name = 'STGCN_cv'\n",
        "\n",
        "\n",
        "    result = results_dict[model_name]\n",
        "    y_true_per_fold = result['y_trues']\n",
        "    y_pred_per_fold = result['y_preds']\n",
        "\n",
        "    y_true_all = np.concatenate(y_true_per_fold, axis=0)\n",
        "    y_pred_all = np.concatenate(y_pred_per_fold, axis=0)\n",
        "\n",
        "\n",
        "    num_classes = int(np.max(y_true_all)) + 1\n",
        "    emotion_dict = {\n",
        "        0: 'Angry',\n",
        "        1: 'Disgust',\n",
        "        2: 'Fearful',\n",
        "        3: 'Happy',\n",
        "        4: 'Neutral',\n",
        "        5: 'Sad',\n",
        "        6: 'Surprise'\n",
        "    }\n",
        "    emotion_classes = [emotion_dict[i] for i in range(num_classes)]\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
        "\n",
        "    cm = confusion_matrix(y_true_all, y_pred_all, labels=np.arange(num_classes))\n",
        "\n",
        "\n",
        "    if normalize:\n",
        "        with np.errstate(all='ignore'):\n",
        "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cm_normalized = np.nan_to_num(cm_normalized)\n",
        "        display_matrix = cm_normalized\n",
        "        fmt = '.2f'\n",
        "        cbar_label = 'Proportion of Actual Class'\n",
        "    else:\n",
        "        display_matrix = cm\n",
        "        fmt = 'd'\n",
        "        cbar_label = 'Count'\n",
        "\n",
        "\n",
        "    sns.heatmap(display_matrix, annot=True, fmt=fmt, cmap=cmap,\n",
        "                xticklabels=emotion_classes, yticklabels=emotion_classes,\n",
        "                ax=ax, cbar_kws={'label': cbar_label, 'orientation': 'vertical'})\n",
        "\n",
        "    acc = np.mean(y_true_all == y_pred_all)\n",
        "    acc_str = f\"{acc:.3f}\"\n",
        "\n",
        "    ax.set_title(f'{model_name} (Aggregated Accuracy: {acc_str})', fontweight='bold', fontsize=14)\n",
        "    ax.set_xlabel('Predicted Label', fontweight='bold')\n",
        "    ax.set_ylabel('Actual Label', fontweight='bold')\n",
        "\n",
        "    plt.suptitle('Confusion Matrix (Aggregated across 5 Folds)', fontsize=16, fontweight='bold', y=1.05)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Saved aggregated confusion matrix to {save_path}\")\n",
        "    print(f\"Aggregated Accuracy: {acc_str}\")\n",
        "    return acc\n",
        "\n",
        "results_dict = np.load('results_per_fold_stgcn.npy', allow_pickle=True).item()\n",
        "\n",
        "accuracy = plot_aggregated_confusion_matrix(results_dict)\n",
        "print(f\"Overall Cross-Validation Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQYKvyLj74W4",
        "outputId": "4d2cd67f-32cc-49ee-ae1a-d97d63b19085"
      },
      "id": "KQYKvyLj74W4",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved aggregated confusion matrix to confusion_matrix_stgcn.png\n",
            "Aggregated Accuracy: 0.567\n",
            "Overall Cross-Validation Accuracy: 0.5667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_per_fold_confusion_matrices(results_dict, normalize=True, cmap='Blues'):\n",
        "    model_name = 'STGCN_cv'\n",
        "\n",
        "    result = results_dict[model_name]\n",
        "    y_true_per_fold = result['y_trues']\n",
        "    y_pred_per_fold = result['y_preds']\n",
        "    n_folds = len(y_true_per_fold)\n",
        "\n",
        "\n",
        "    y_true_all = np.concatenate(y_true_per_fold, axis=0)\n",
        "    num_classes = int(np.max(y_true_all)) + 1\n",
        "    emotion_dict = {\n",
        "        0: 'Angry',\n",
        "        1: 'Disgust',\n",
        "        2: 'Fearful',\n",
        "        3: 'Happy',\n",
        "        4: 'Neutral',\n",
        "        5: 'Sad',\n",
        "        6: 'Surprise'\n",
        "    }\n",
        "    emotion_classes = [emotion_dict[i] for i in range(num_classes)]\n",
        "\n",
        "    print(f\"Generating {n_folds} confusion matrices for model {model_name}...\")\n",
        "\n",
        "\n",
        "    fold_accuracies = []\n",
        "\n",
        "    for fold_idx in range(n_folds):\n",
        "        y_true_fold = y_true_per_fold[fold_idx]\n",
        "        y_pred_fold = y_pred_per_fold[fold_idx]\n",
        "\n",
        "        acc = np.mean(y_true_fold == y_pred_fold)\n",
        "        fold_accuracies.append(acc)\n",
        "        acc_str = f\"{acc:.3f}\"\n",
        "\n",
        "        cm = confusion_matrix(y_true_fold, y_pred_fold, labels=np.arange(num_classes))\n",
        "\n",
        "        if normalize:\n",
        "            with np.errstate(all='ignore'):\n",
        "                cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "                cm_normalized = np.nan_to_num(cm_normalized)\n",
        "            display_matrix = cm_normalized\n",
        "            fmt = '.2f'\n",
        "            cbar_label = 'Proportion of Actual Class'\n",
        "        else:\n",
        "            display_matrix = cm\n",
        "            fmt = 'd'\n",
        "            cbar_label = 'Count'\n",
        "\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
        "\n",
        "        sns.heatmap(display_matrix, annot=True, fmt=fmt, cmap=cmap,\n",
        "                    xticklabels=emotion_classes, yticklabels=emotion_classes,\n",
        "                    ax=ax, cbar_kws={'label': cbar_label, 'orientation': 'vertical'})\n",
        "\n",
        "        title = f'{model_name} - Fold {fold_idx + 1}\\n(Accuracy: {acc_str})'\n",
        "        ax.set_title(title, fontweight='bold', fontsize=14)\n",
        "        ax.set_xlabel('Predicted Label', fontweight='bold')\n",
        "        ax.set_ylabel('Actual Label', fontweight='bold')\n",
        "\n",
        "        save_path = f'confusion_matrix_stgcn_fold_{fold_idx + 1}.png'\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "\n",
        "        print(f\"Saved confusion matrix for Fold {fold_idx + 1} to {save_path}\")\n",
        "\n",
        "    return fold_accuracies\n",
        "\n",
        "results_dict = np.load('results_per_fold_stgcn.npy', allow_pickle=True).item()\n",
        "\n",
        "\n",
        "accuracies = plot_per_fold_confusion_matrices(results_dict)\n",
        "\n",
        "print(\"\\n--- Summary of Fold Accuracies ---\")\n",
        "for i, acc in enumerate(accuracies):\n",
        "    print(f\"Fold {i+1}: {acc:.4f}\")\n",
        "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Std Dev Accuracy: {np.std(accuracies):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV69dy8Z8C8c",
        "outputId": "31fa39f8-88b1-4d51-c2a6-70807f2e08de"
      },
      "id": "VV69dy8Z8C8c",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 5 confusion matrices for model STGCN_cv...\n",
            "Saved confusion matrix for Fold 1 to confusion_matrix_stgcn_fold_1.png\n",
            "Saved confusion matrix for Fold 2 to confusion_matrix_stgcn_fold_2.png\n",
            "Saved confusion matrix for Fold 3 to confusion_matrix_stgcn_fold_3.png\n",
            "Saved confusion matrix for Fold 4 to confusion_matrix_stgcn_fold_4.png\n",
            "Saved confusion matrix for Fold 5 to confusion_matrix_stgcn_fold_5.png\n",
            "\n",
            "--- Summary of Fold Accuracies ---\n",
            "Fold 1: 0.5302\n",
            "Fold 2: 0.5500\n",
            "Fold 3: 0.6286\n",
            "Fold 4: 0.5571\n",
            "Fold 5: 0.5679\n",
            "Mean Accuracy: 0.5668\n",
            "Std Dev Accuracy: 0.0333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_overall_per_class_metrics(results_dict, save_path='per_class_metrics_overall_stgcn.png', cmap='Blues'):\n",
        "\n",
        "    model_name = 'STGCN_cv'\n",
        "    result = results_dict[model_name]\n",
        "    y_true_per_fold = result['y_trues']\n",
        "    y_pred_per_fold = result['y_preds']\n",
        "\n",
        "    y_true_all = np.concatenate(y_true_per_fold, axis=0)\n",
        "    num_classes = int(np.max(y_true_all)) + 1\n",
        "    emotion_dict = {\n",
        "        0: 'Angry',\n",
        "        1: 'Disgust',\n",
        "        2: 'Fearful',\n",
        "        3: 'Happy',\n",
        "        4: 'Neutral',\n",
        "        5: 'Sad',\n",
        "        6: 'Surprise'\n",
        "    }\n",
        "    emotion_classes = [emotion_dict[i] for i in range(num_classes)]\n",
        "\n",
        "\n",
        "    all_precision, all_recall, all_f1 = [], [], []\n",
        "    for y_true_f, y_pred_f in zip(y_true_per_fold, y_pred_per_fold):\n",
        "        p, r, f1, _ = precision_recall_fscore_support(y_true_f, y_pred_f,\n",
        "                                                      labels=np.arange(num_classes),\n",
        "                                                      zero_division=0)\n",
        "        all_precision.append(p)\n",
        "        all_recall.append(r)\n",
        "        all_f1.append(f1)\n",
        "\n",
        "\n",
        "    metrics_data = {\n",
        "        'Precision': (np.stack(all_precision, axis=0).mean(axis=0), np.stack(all_precision, axis=0).std(axis=0)),\n",
        "        'Recall': (np.stack(all_recall, axis=0).mean(axis=0), np.stack(all_recall, axis=0).std(axis=0)),\n",
        "        'F1-Score': (np.stack(all_f1, axis=0).mean(axis=0), np.stack(all_f1, axis=0).std(axis=0))\n",
        "    }\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "    fig.suptitle('Per-Class Performance Metrics (Mean $\\pm$ Std Dev across Folds)',\n",
        "                 fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "    metric_names = ['Precision', 'Recall', 'F1-Score']\n",
        "    x = np.arange(num_classes)\n",
        "    width = 0.5\n",
        "\n",
        "    for ax, metric_name in zip(axes, metric_names):\n",
        "        mean_scores, std_scores = metrics_data[metric_name]\n",
        "\n",
        "        ax.bar(x, mean_scores, width, yerr=std_scores, capsize=5,\n",
        "               color=plt.cm.get_cmap(cmap)(0.5), alpha=0.85)\n",
        "\n",
        "        ax.set_xlabel('Class Label', fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel(metric_name, fontsize=12, fontweight='bold')\n",
        "        ax.set_title(f'{metric_name} by Class', fontsize=13, fontweight='bold')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(emotion_classes, rotation=45, ha='right')\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "        ax.set_ylim([0, 1])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved overall per-class metrics to {save_path}\")\n",
        "\n",
        "results_dict = np.load('results_per_fold_stgcn.npy', allow_pickle=True).item()\n",
        "\n",
        "plot_overall_per_class_metrics(results_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a0WEP008GRy",
        "outputId": "6500168a-6fa2-46da-adda-bf9e0777ddb5"
      },
      "id": "7a0WEP008GRy",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved overall per-class metrics to per_class_metrics_overall_stgcn.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_per_fold_individual_metrics(results_dict, save_path='per_class_metrics_per_fold.png', cmap='viridis'):\n",
        "\n",
        "    model_name = 'STGCN_cv'\n",
        "    result = results_dict[model_name]\n",
        "    y_true_per_fold = result['y_trues']\n",
        "    y_pred_per_fold = result['y_preds']\n",
        "    n_folds = len(y_true_per_fold)\n",
        "\n",
        "    y_true_all = np.concatenate(y_true_per_fold, axis=0)\n",
        "    num_classes = int(np.max(y_true_all)) + 1\n",
        "    emotion_dict = {\n",
        "        0: 'Angry',\n",
        "        1: 'Disgust',\n",
        "        2: 'Fearful',\n",
        "        3: 'Happy',\n",
        "        4: 'Neutral',\n",
        "        5: 'Sad',\n",
        "        6: 'Surprise'\n",
        "    }\n",
        "    emotion_classes = [emotion_dict[i] for i in range(num_classes)]\n",
        "\n",
        "\n",
        "    all_precision, all_recall, all_f1 = [], [], []\n",
        "    for y_true_f, y_pred_f in zip(y_true_per_fold, y_pred_per_fold):\n",
        "        p, r, f1, _ = precision_recall_fscore_support(y_true_f, y_pred_f,\n",
        "                                                      labels=np.arange(num_classes),\n",
        "                                                      zero_division=0)\n",
        "        all_precision.append(p)\n",
        "        all_recall.append(r)\n",
        "        all_f1.append(f1)\n",
        "\n",
        "    metrics_data = {\n",
        "        'Precision': np.stack(all_precision, axis=0),\n",
        "        'Recall': np.stack(all_recall, axis=0),\n",
        "        'F1-Score': np.stack(all_f1, axis=0)\n",
        "    }\n",
        "\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(21, 7))\n",
        "    fig.suptitle('Per-Class Performance Metrics (Individual Folds)',\n",
        "                 fontsize=18, fontweight='bold', y=1.02)\n",
        "\n",
        "    metric_names = ['Precision', 'Recall', 'F1-Score']\n",
        "    x = np.arange(num_classes)\n",
        "\n",
        "    group_width = 0.8\n",
        "    bar_width = group_width / n_folds\n",
        "\n",
        "    colors = plt.cm.get_cmap(cmap, n_folds)\n",
        "\n",
        "    for ax, metric_name in zip(axes, metric_names):\n",
        "        scores_matrix = metrics_data[metric_name] # (n_folds, n_classes)\n",
        "\n",
        "        for fold_idx in range(n_folds):\n",
        "            offset = (fold_idx - (n_folds - 1) / 2) * bar_width\n",
        "\n",
        "            ax.bar(x + offset, scores_matrix[fold_idx, :], bar_width,\n",
        "                   label=f'Fold {fold_idx + 1}', color=colors(fold_idx), alpha=0.8)\n",
        "\n",
        "        ax.set_xlabel('Class Label', fontsize=14, fontweight='bold')\n",
        "        ax.set_ylabel(metric_name, fontsize=14, fontweight='bold')\n",
        "        ax.set_title(f'{metric_name} by Class', fontsize=15, fontweight='bold')\n",
        "\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(emotion_classes, rotation=45, ha='right', fontsize=12)\n",
        "        ax.legend(fontsize=10)\n",
        "        ax.grid(axis='y', alpha=0.3)\n",
        "        ax.set_ylim([0, 1])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved per-class metrics per fold to {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "results_dict = np.load('results_per_fold_stgcn.npy', allow_pickle=True).item()\n",
        "\n",
        "plot_per_fold_individual_metrics(results_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4JyYkzD8IcO",
        "outputId": "fcee4c66-ed98-41ac-8424-8bedfcdac569"
      },
      "id": "Z4JyYkzD8IcO",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved per-class metrics per fold to per_class_metrics_per_fold.png\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}