{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## Without Augmentation and selected useful features only\n",
        "## Removed the early stopping to see how far can it result in the increase in accuracy\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, PowerTransformer\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "\n",
        "DATA_CSV = \"features_dataset.csv\"\n",
        "RANDOM_SEED = 42\n",
        "N_SPLITS = 5\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 250\n",
        "LR = 1e-1\n",
        "WEIGHT_DECAY = 1e-5\n",
        "PATIENCE = 8\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "\n",
        "def seed_all(seed=RANDOM_SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if DEVICE.startswith(\"cuda\"):\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "seed_all()\n",
        "\n",
        "df = pd.read_csv(DATA_CSV)\n",
        "print(\"Raw shape:\", df.shape)\n",
        "\n",
        "# Drop unecessarily columns\n",
        "drop_cols = []\n",
        "for c in [\"filename\", \"actor_ID\", \"num_frames\", \"duration\"]:\n",
        "    if c in df.columns:\n",
        "        drop_cols.append(c)\n",
        "\n",
        "# Keep metadata columns optionally (gender) - encode gender if present\n",
        "metadata_cols = []\n",
        "if \"gender\" in df.columns:\n",
        "    metadata_cols.append(\"gender\")\n",
        "\n",
        "label_col = \"emotion\"\n",
        "if label_col not in df.columns:\n",
        "    raise RuntimeError(f\"Label column '{label_col}' not found in CSV\")\n",
        "\n",
        "\n",
        "numeric_cols = ['Neck_speed_max',\n",
        " 'Spine2_speed_std',\n",
        " 'Spine1_range',\n",
        " 'RightUpLeg_speed_max',\n",
        " 'LeftLeg_speed_max',\n",
        " 'LeftLeg_speed_std',\n",
        " 'Spine3_acc_mean',\n",
        " 'LeftUpLeg_speed_max',\n",
        " 'LeftShoulder_speed_max',\n",
        " 'LeftFoot_speed_max',\n",
        " 'Spine3_speed_mean',\n",
        " 'RightUpLeg_speed_std',\n",
        " 'RightShoulder_speed_max',\n",
        " 'RightLeg_speed_max',\n",
        " 'Spine_speed_max',\n",
        " 'Neck_speed_std',\n",
        " 'Spine1_acc_mean',\n",
        " 'Spine_range',\n",
        " 'RightUpLeg_range',\n",
        " 'Spine2_speed_mean',\n",
        " 'LeftFoot_speed_std',\n",
        " 'LeftUpLeg_speed_std',\n",
        " 'LeftArm_speed_max',\n",
        " 'Spine_speed_std',\n",
        " 'LeftUpLeg_range',\n",
        " 'RightLeg_range',\n",
        " 'overall_speed_max',\n",
        " 'LeftHand_speed_max',\n",
        " 'RightFoot_speed_std',\n",
        " 'RightLeg_speed_std',\n",
        " 'RightFoot_speed_max',\n",
        " 'LeftArm_range',\n",
        " 'LeftForeArm_speed_std',\n",
        " 'Neck_acc_mean',\n",
        " 'Spine_acc_mean',\n",
        " 'LeftFoot_speed_mean',\n",
        " 'LeftForeArm_speed_max',\n",
        " 'LeftHand_speed_std',\n",
        " 'RightFoot_acc_mean',\n",
        " 'RightFoot_speed_mean',\n",
        " 'overall_speed_std',\n",
        " 'RightArm_speed_max',\n",
        " 'LeftFoot_range',\n",
        " 'RightForeArm_speed_max',\n",
        " 'LeftShoulder_range',\n",
        " 'LeftShoulder_speed_std',\n",
        " 'LeftForeArm_range',\n",
        " 'RightShoulder_speed_std',\n",
        " 'RightLeg_acc_mean',\n",
        " 'RightLeg_speed_mean',\n",
        " 'LeftFoot_acc_mean',\n",
        " 'LeftArm_speed_std',\n",
        " 'LeftArm_acc_mean',\n",
        " 'Spine_speed_mean',\n",
        " 'RightFoot_range',\n",
        " 'LeftHand_range',\n",
        " 'Spine1_speed_mean',\n",
        " 'LeftLeg_acc_mean',\n",
        " 'RightShoulder_range',\n",
        " 'RightShoulder_acc_mean',\n",
        " 'LeftUpLeg_acc_mean',\n",
        " 'LeftLeg_speed_mean',\n",
        " 'RightHand_speed_max',\n",
        " 'Head_speed_max',\n",
        " 'LeftArm_speed_mean',\n",
        " 'RightForeArm_range',\n",
        " 'LeftUpLeg_speed_mean',\n",
        " 'LeftHand_acc_mean',\n",
        " 'RightHand_range',\n",
        " 'RightArm_speed_std',\n",
        " 'RightArm_range',\n",
        " 'LeftForeArm_speed_mean',\n",
        " 'RightUpLeg_acc_mean',\n",
        " 'RightForeArm_speed_std',\n",
        " 'RightShoulder_speed_mean',\n",
        " 'LeftHand_speed_mean',\n",
        " 'Head_speed_std',\n",
        " 'Head_speed_mean',\n",
        " 'LeftForeArm_acc_mean',\n",
        " 'RightHand_speed_std',\n",
        " 'LeftShoulder_acc_mean',\n",
        " 'RightUpLeg_speed_mean',\n",
        " 'Head_acc_mean',\n",
        " 'RightArm_speed_mean',\n",
        " 'overall_speed_mean',\n",
        " 'Hips_speed_max',\n",
        " 'movement_intensity',\n",
        " 'Hips_range',\n",
        " 'Neck_speed_mean',\n",
        " 'RightArm_acc_mean',\n",
        " 'RightForeArm_acc_mean',\n",
        " 'LeftShoulder_speed_mean',\n",
        " 'RightHand_acc_mean',\n",
        " 'Hips_speed_mean',\n",
        " 'Neck_range',\n",
        " 'RightForeArm_speed_mean',\n",
        " 'Hips_speed_std',\n",
        " 'RightHand_speed_mean',\n",
        " 'Head_range',\n",
        " 'Hips_acc_mean']\n",
        "\n",
        "\n",
        "numeric_cols = [c for c in numeric_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
        "\n",
        "print(\"Using numeric features:\", len(numeric_cols))\n",
        "X_num = df[numeric_cols].fillna(0).values\n",
        "\n",
        "\n",
        "X_meta = None\n",
        "if \"gender\" in metadata_cols:\n",
        "    # simple map Female->0 Male->1 else nan->-1\n",
        "    gmap = {\"Female\": 0, \"Male\": 1}\n",
        "    g = df[\"gender\"].map(gmap).fillna(-1).astype(np.float32).values.reshape(-1,1)\n",
        "    X_meta = g\n",
        "\n",
        "\n",
        "if X_meta is not None:\n",
        "    X = np.hstack([X_num, X_meta])\n",
        "else:\n",
        "    X = X_num\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df[label_col].astype(str).values)\n",
        "class_names = le.classes_\n",
        "print(\"Classes:\", list(class_names))\n",
        "print(\"Counts:\", dict(pd.Series(y).map(lambda v: class_names[v]).value_counts()))\n",
        "\n",
        "\n",
        "class TabularDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X.astype(np.float32)\n",
        "        self.y = y.astype(np.int64)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "class MLP_small(nn.Module):\n",
        "    def __init__(self, in_dim, n_classes, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(256,128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128,64),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, n_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    if alpha <= 0:\n",
        "        return x, y, None, None, 1.0\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size, device=x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, index, lam\n",
        "\n",
        "def mixup_criterion(criterion, preds, y_a, y_b, lam):\n",
        "    return lam * criterion(preds, y_a) + (1 - lam) * criterion(preds, y_b)\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, weight=None):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.weight = weight\n",
        "    def forward(self, inputs, targets):\n",
        "        ce = nn.functional.cross_entropy(inputs, targets, weight=self.weight, reduction='none')\n",
        "        pt = torch.exp(-ce)\n",
        "        loss = ((1-pt)**self.gamma * ce).mean()\n",
        "        return loss\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device); yb = yb.to(device)\n",
        "        preds = model(xb)\n",
        "        loss = criterion(preds, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def eval_model(model, loader, device):\n",
        "    model.eval()\n",
        "    preds_all = []\n",
        "    ys_all = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb = xb.to(device)\n",
        "            out = model(xb)\n",
        "            preds_all.append(out.softmax(dim=1).cpu().numpy())\n",
        "            ys_all.append(yb.numpy())\n",
        "    preds_all = np.vstack(preds_all)\n",
        "    ys_all = np.concatenate(ys_all)\n",
        "    preds_labels = preds_all.argmax(axis=1)\n",
        "    acc = (preds_labels == ys_all).mean()\n",
        "    return acc, preds_labels, ys_all, preds_all\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
        "fold_results = []\n",
        "all_preds = []\n",
        "all_trues = []\n",
        "best_models = []\n",
        "\n",
        "for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    print(f\"\\n=== Fold {fold+1}/{N_SPLITS} ===\")\n",
        "    X_tr, X_val = X[tr_idx], X[val_idx]\n",
        "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
        "\n",
        "    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "    X_tr = pt.fit_transform(X_tr)\n",
        "    X_val = pt.transform(X_val)\n",
        "\n",
        "    train_ds = TabularDataset(X_tr, y_tr)\n",
        "    val_ds = TabularDataset(X_val, y_val)\n",
        "\n",
        "    vals, counts = np.unique(y_tr, return_counts=True)\n",
        "    inv_freq = 1.0 / (counts + 1e-12)\n",
        "    weight_vec = np.zeros(len(class_names), dtype=np.float32)\n",
        "    for cls_i, inv in zip(vals, inv_freq):\n",
        "        weight_vec[cls_i] = inv\n",
        "    weight_tensor = torch.tensor(weight_vec, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "    sample_weights = np.array([weight_vec[yv] for yv in y_tr], dtype=np.float32)\n",
        "    sample_weights = sample_weights / sample_weights.sum()\n",
        "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "    tr_loader = DataLoader(train_ds, batch_size=128, sampler=sampler, num_workers=0)\n",
        "\n",
        "    val_loader = DataLoader(val_ds, batch_size=256, shuffle=False, num_workers=0)\n",
        "\n",
        "    model = MLP_small(in_dim=X_tr.shape[1], n_classes=len(class_names), dropout=0.2).to(DEVICE)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=weight_tensor, label_smoothing=0.08)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "    steps_per_epoch = max(1, len(tr_loader))\n",
        "    scheduler = OneCycleLR(optimizer, max_lr=1e-2, steps_per_epoch=steps_per_epoch, epochs=EPOCHS)\n",
        "\n",
        "    best_val = 0.0\n",
        "    epochs_no_improve = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for xb, yb in tr_loader:\n",
        "            xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
        "\n",
        "            xb_m, ya, yb_mix, _, lam = mixup_data(xb, yb, alpha=0.2)\n",
        "            preds = model(xb_m)\n",
        "\n",
        "            if lam is None:\n",
        "                loss = criterion(preds, yb)\n",
        "            else:\n",
        "                loss = mixup_criterion(criterion, preds, ya, yb_mix, lam)\n",
        "\n",
        "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "            total_loss += loss.item() * xb.size(0)\n",
        "            scheduler.step()\n",
        "\n",
        "        avg_loss = total_loss / len(tr_loader.dataset)\n",
        "        val_acc, val_preds, val_trues, _ = eval_model(model, val_loader, DEVICE)\n",
        "        print(f\"Epoch {epoch+1}: train_loss={avg_loss:.4f} val_acc={val_acc:.4f} best={best_val:.4f}\")\n",
        "\n",
        "        if val_acc > best_val + 1e-5:\n",
        "            best_val = val_acc\n",
        "            epochs_no_improve = 0\n",
        "            # torch.save(model.state_dict(), f\"best_mlp_fold{fold}.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7vOCyP_chnb",
        "outputId": "16b70066-e4b5-4111-ff40-478d5928029e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw shape: (1401, 305)\n",
            "Using numeric features: 100\n",
            "Classes: ['Angry', 'Disgust', 'Fearful', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
            "Counts: {'Fearful': np.int64(216), 'Happy': np.int64(216), 'Surprise': np.int64(212), 'Disgust': np.int64(210), 'Sad': np.int64(202), 'Angry': np.int64(200), 'Neutral': np.int64(145)}\n",
            "\n",
            "=== Fold 1/5 ===\n",
            "Epoch 1: train_loss=1.9358 val_acc=0.2491 best=0.0000\n",
            "Epoch 2: train_loss=1.8737 val_acc=0.2633 best=0.2491\n",
            "Epoch 3: train_loss=1.8055 val_acc=0.2740 best=0.2633\n",
            "Epoch 4: train_loss=1.7659 val_acc=0.2705 best=0.2740\n",
            "Epoch 5: train_loss=1.7321 val_acc=0.3203 best=0.2740\n",
            "Epoch 6: train_loss=1.7044 val_acc=0.3167 best=0.3203\n",
            "Epoch 7: train_loss=1.7050 val_acc=0.3488 best=0.3203\n",
            "Epoch 8: train_loss=1.6175 val_acc=0.3452 best=0.3488\n",
            "Epoch 9: train_loss=1.6026 val_acc=0.3701 best=0.3488\n",
            "Epoch 10: train_loss=1.5497 val_acc=0.4021 best=0.3701\n",
            "Epoch 11: train_loss=1.6120 val_acc=0.4128 best=0.4021\n",
            "Epoch 12: train_loss=1.5464 val_acc=0.4235 best=0.4128\n",
            "Epoch 13: train_loss=1.4942 val_acc=0.4270 best=0.4235\n",
            "Epoch 14: train_loss=1.4973 val_acc=0.4306 best=0.4270\n",
            "Epoch 15: train_loss=1.5574 val_acc=0.4555 best=0.4306\n",
            "Epoch 16: train_loss=1.4489 val_acc=0.4662 best=0.4555\n",
            "Epoch 17: train_loss=1.4502 val_acc=0.4769 best=0.4662\n",
            "Epoch 18: train_loss=1.4373 val_acc=0.4484 best=0.4769\n",
            "Epoch 19: train_loss=1.3682 val_acc=0.5053 best=0.4769\n",
            "Epoch 20: train_loss=1.2980 val_acc=0.4769 best=0.5053\n",
            "Epoch 21: train_loss=1.3991 val_acc=0.4840 best=0.5053\n",
            "Epoch 22: train_loss=1.3759 val_acc=0.4769 best=0.5053\n",
            "Epoch 23: train_loss=1.2697 val_acc=0.4662 best=0.5053\n",
            "Epoch 24: train_loss=1.3019 val_acc=0.4947 best=0.5053\n",
            "Epoch 25: train_loss=1.2224 val_acc=0.5125 best=0.5053\n",
            "Epoch 26: train_loss=1.3773 val_acc=0.4982 best=0.5125\n",
            "Epoch 27: train_loss=1.2677 val_acc=0.4875 best=0.5125\n",
            "Epoch 28: train_loss=1.1845 val_acc=0.4804 best=0.5125\n",
            "Epoch 29: train_loss=1.3140 val_acc=0.4947 best=0.5125\n",
            "Epoch 30: train_loss=1.1849 val_acc=0.5089 best=0.5125\n",
            "Epoch 31: train_loss=1.1857 val_acc=0.5053 best=0.5125\n",
            "Epoch 32: train_loss=1.3133 val_acc=0.5053 best=0.5125\n",
            "Epoch 33: train_loss=1.1959 val_acc=0.5160 best=0.5125\n",
            "Epoch 34: train_loss=1.2738 val_acc=0.4911 best=0.5160\n",
            "Epoch 35: train_loss=1.0717 val_acc=0.5125 best=0.5160\n",
            "Epoch 36: train_loss=1.0563 val_acc=0.4947 best=0.5160\n",
            "Epoch 37: train_loss=1.1537 val_acc=0.5089 best=0.5160\n",
            "Epoch 38: train_loss=1.1733 val_acc=0.4840 best=0.5160\n",
            "Epoch 39: train_loss=1.1654 val_acc=0.5089 best=0.5160\n",
            "Epoch 40: train_loss=1.1314 val_acc=0.5445 best=0.5160\n",
            "Epoch 41: train_loss=1.1662 val_acc=0.4804 best=0.5445\n",
            "Epoch 42: train_loss=1.2051 val_acc=0.5196 best=0.5445\n",
            "Epoch 43: train_loss=1.1656 val_acc=0.5018 best=0.5445\n",
            "Epoch 44: train_loss=1.1565 val_acc=0.5231 best=0.5445\n",
            "Epoch 45: train_loss=1.1425 val_acc=0.5302 best=0.5445\n",
            "Epoch 46: train_loss=1.0863 val_acc=0.5409 best=0.5445\n",
            "Epoch 47: train_loss=0.9830 val_acc=0.5302 best=0.5445\n",
            "Epoch 48: train_loss=1.0937 val_acc=0.4662 best=0.5445\n",
            "Epoch 49: train_loss=0.9536 val_acc=0.4875 best=0.5445\n",
            "Epoch 50: train_loss=1.2098 val_acc=0.5196 best=0.5445\n",
            "Epoch 51: train_loss=1.1253 val_acc=0.5338 best=0.5445\n",
            "Epoch 52: train_loss=1.1068 val_acc=0.4875 best=0.5445\n",
            "Epoch 53: train_loss=1.1597 val_acc=0.4947 best=0.5445\n",
            "Epoch 54: train_loss=1.0904 val_acc=0.5018 best=0.5445\n",
            "Epoch 55: train_loss=1.0000 val_acc=0.5018 best=0.5445\n",
            "Epoch 56: train_loss=1.1881 val_acc=0.4769 best=0.5445\n",
            "Epoch 57: train_loss=1.0054 val_acc=0.5053 best=0.5445\n",
            "Epoch 58: train_loss=1.1242 val_acc=0.5089 best=0.5445\n",
            "Epoch 59: train_loss=1.2082 val_acc=0.5053 best=0.5445\n",
            "Epoch 60: train_loss=1.1827 val_acc=0.5018 best=0.5445\n",
            "Epoch 61: train_loss=1.1241 val_acc=0.5125 best=0.5445\n",
            "Epoch 62: train_loss=1.0333 val_acc=0.5053 best=0.5445\n",
            "Epoch 63: train_loss=0.8671 val_acc=0.5302 best=0.5445\n",
            "Epoch 64: train_loss=0.9998 val_acc=0.4840 best=0.5445\n",
            "Epoch 65: train_loss=0.9974 val_acc=0.4698 best=0.5445\n",
            "Epoch 66: train_loss=1.2155 val_acc=0.5338 best=0.5445\n",
            "Epoch 67: train_loss=0.9975 val_acc=0.5053 best=0.5445\n",
            "Epoch 68: train_loss=1.0060 val_acc=0.5125 best=0.5445\n",
            "Epoch 69: train_loss=1.1346 val_acc=0.4982 best=0.5445\n",
            "Epoch 70: train_loss=1.0874 val_acc=0.5089 best=0.5445\n",
            "Epoch 71: train_loss=1.0509 val_acc=0.5053 best=0.5445\n",
            "Epoch 72: train_loss=1.0205 val_acc=0.5089 best=0.5445\n",
            "Epoch 73: train_loss=1.0119 val_acc=0.5125 best=0.5445\n",
            "Epoch 74: train_loss=1.0126 val_acc=0.4840 best=0.5445\n",
            "Epoch 75: train_loss=1.0599 val_acc=0.4947 best=0.5445\n",
            "Epoch 76: train_loss=1.0125 val_acc=0.5018 best=0.5445\n",
            "Epoch 77: train_loss=1.1732 val_acc=0.4804 best=0.5445\n",
            "Epoch 78: train_loss=1.0218 val_acc=0.5125 best=0.5445\n",
            "Epoch 79: train_loss=1.1050 val_acc=0.5160 best=0.5445\n",
            "Epoch 80: train_loss=1.3074 val_acc=0.5231 best=0.5445\n",
            "Epoch 81: train_loss=0.9776 val_acc=0.4733 best=0.5445\n",
            "Epoch 82: train_loss=0.8045 val_acc=0.4911 best=0.5445\n",
            "Epoch 83: train_loss=1.1664 val_acc=0.5267 best=0.5445\n",
            "Epoch 84: train_loss=1.0492 val_acc=0.5196 best=0.5445\n",
            "Epoch 85: train_loss=0.9246 val_acc=0.5196 best=0.5445\n",
            "Epoch 86: train_loss=0.8664 val_acc=0.5089 best=0.5445\n",
            "Epoch 87: train_loss=0.8749 val_acc=0.5089 best=0.5445\n",
            "Epoch 88: train_loss=1.1046 val_acc=0.5160 best=0.5445\n",
            "Epoch 89: train_loss=0.8708 val_acc=0.5018 best=0.5445\n",
            "Epoch 90: train_loss=0.8626 val_acc=0.5409 best=0.5445\n",
            "Epoch 91: train_loss=0.9142 val_acc=0.5018 best=0.5445\n",
            "Epoch 92: train_loss=1.0773 val_acc=0.4982 best=0.5445\n",
            "Epoch 93: train_loss=0.8558 val_acc=0.5018 best=0.5445\n",
            "Epoch 94: train_loss=0.8973 val_acc=0.4982 best=0.5445\n",
            "Epoch 95: train_loss=1.0264 val_acc=0.4911 best=0.5445\n",
            "Epoch 96: train_loss=0.9297 val_acc=0.4840 best=0.5445\n",
            "Epoch 97: train_loss=1.0452 val_acc=0.4733 best=0.5445\n",
            "Epoch 98: train_loss=1.0406 val_acc=0.5267 best=0.5445\n",
            "Epoch 99: train_loss=0.9497 val_acc=0.5196 best=0.5445\n",
            "Epoch 100: train_loss=1.0137 val_acc=0.4875 best=0.5445\n",
            "Epoch 101: train_loss=0.6942 val_acc=0.5053 best=0.5445\n",
            "Epoch 102: train_loss=1.0507 val_acc=0.5125 best=0.5445\n",
            "Epoch 103: train_loss=1.1187 val_acc=0.5196 best=0.5445\n",
            "Epoch 104: train_loss=1.0028 val_acc=0.5125 best=0.5445\n",
            "Epoch 105: train_loss=0.9988 val_acc=0.4698 best=0.5445\n",
            "Epoch 106: train_loss=0.9183 val_acc=0.4875 best=0.5445\n",
            "Epoch 107: train_loss=0.7958 val_acc=0.5160 best=0.5445\n",
            "Epoch 108: train_loss=0.9068 val_acc=0.4982 best=0.5445\n",
            "Epoch 109: train_loss=1.1259 val_acc=0.5302 best=0.5445\n",
            "Epoch 110: train_loss=0.8227 val_acc=0.5302 best=0.5445\n",
            "Epoch 111: train_loss=0.8879 val_acc=0.5445 best=0.5445\n",
            "Epoch 112: train_loss=0.7902 val_acc=0.4875 best=0.5445\n",
            "Epoch 113: train_loss=0.8907 val_acc=0.5053 best=0.5445\n",
            "Epoch 114: train_loss=0.9812 val_acc=0.5018 best=0.5445\n",
            "Epoch 115: train_loss=0.6945 val_acc=0.5018 best=0.5445\n",
            "Epoch 116: train_loss=0.9919 val_acc=0.5160 best=0.5445\n",
            "Epoch 117: train_loss=0.8875 val_acc=0.5160 best=0.5445\n",
            "Epoch 118: train_loss=0.9193 val_acc=0.5018 best=0.5445\n",
            "Epoch 119: train_loss=0.7555 val_acc=0.5374 best=0.5445\n",
            "Epoch 120: train_loss=1.1220 val_acc=0.5053 best=0.5445\n",
            "Epoch 121: train_loss=0.7618 val_acc=0.5053 best=0.5445\n",
            "Epoch 122: train_loss=0.7514 val_acc=0.4947 best=0.5445\n",
            "Epoch 123: train_loss=0.9071 val_acc=0.5231 best=0.5445\n",
            "Epoch 124: train_loss=0.8373 val_acc=0.5267 best=0.5445\n",
            "Epoch 125: train_loss=0.6950 val_acc=0.5267 best=0.5445\n",
            "Epoch 126: train_loss=0.8124 val_acc=0.4840 best=0.5445\n",
            "Epoch 127: train_loss=0.8634 val_acc=0.5196 best=0.5445\n",
            "Epoch 128: train_loss=0.7733 val_acc=0.5480 best=0.5445\n",
            "Epoch 129: train_loss=0.7437 val_acc=0.5018 best=0.5480\n",
            "Epoch 130: train_loss=0.9711 val_acc=0.5089 best=0.5480\n",
            "Epoch 131: train_loss=1.0123 val_acc=0.5053 best=0.5480\n",
            "Epoch 132: train_loss=0.6761 val_acc=0.5125 best=0.5480\n",
            "Epoch 133: train_loss=0.9739 val_acc=0.5231 best=0.5480\n",
            "Epoch 134: train_loss=0.8656 val_acc=0.5160 best=0.5480\n",
            "Epoch 135: train_loss=0.9420 val_acc=0.4947 best=0.5480\n",
            "Epoch 136: train_loss=0.8728 val_acc=0.5053 best=0.5480\n",
            "Epoch 137: train_loss=0.8676 val_acc=0.5231 best=0.5480\n",
            "Epoch 138: train_loss=0.8303 val_acc=0.5089 best=0.5480\n",
            "Epoch 139: train_loss=0.7136 val_acc=0.5267 best=0.5480\n",
            "Epoch 140: train_loss=1.0060 val_acc=0.5196 best=0.5480\n",
            "Epoch 141: train_loss=0.8310 val_acc=0.5160 best=0.5480\n",
            "Epoch 142: train_loss=0.5649 val_acc=0.5445 best=0.5480\n",
            "Epoch 143: train_loss=0.8188 val_acc=0.5018 best=0.5480\n",
            "Epoch 144: train_loss=0.8800 val_acc=0.4947 best=0.5480\n",
            "Epoch 145: train_loss=0.7450 val_acc=0.5374 best=0.5480\n",
            "Epoch 146: train_loss=0.8711 val_acc=0.5409 best=0.5480\n",
            "Epoch 147: train_loss=0.7016 val_acc=0.5552 best=0.5480\n",
            "Epoch 148: train_loss=0.5578 val_acc=0.5196 best=0.5552\n",
            "Epoch 149: train_loss=0.7445 val_acc=0.5374 best=0.5552\n",
            "Epoch 150: train_loss=0.5823 val_acc=0.5196 best=0.5552\n",
            "Epoch 151: train_loss=0.5917 val_acc=0.5302 best=0.5552\n",
            "Epoch 152: train_loss=0.7622 val_acc=0.5160 best=0.5552\n",
            "Epoch 153: train_loss=0.8043 val_acc=0.5231 best=0.5552\n",
            "Epoch 154: train_loss=0.6375 val_acc=0.5267 best=0.5552\n",
            "Epoch 155: train_loss=0.8009 val_acc=0.5125 best=0.5552\n",
            "Epoch 156: train_loss=0.8362 val_acc=0.5516 best=0.5552\n",
            "Epoch 157: train_loss=0.8752 val_acc=0.5302 best=0.5552\n",
            "Epoch 158: train_loss=0.8282 val_acc=0.5267 best=0.5552\n",
            "Epoch 159: train_loss=0.6944 val_acc=0.5409 best=0.5552\n",
            "Epoch 160: train_loss=0.7172 val_acc=0.5445 best=0.5552\n",
            "Epoch 161: train_loss=0.8285 val_acc=0.5302 best=0.5552\n",
            "Epoch 162: train_loss=0.8667 val_acc=0.5231 best=0.5552\n",
            "Epoch 163: train_loss=0.8166 val_acc=0.5196 best=0.5552\n",
            "Epoch 164: train_loss=0.6206 val_acc=0.5231 best=0.5552\n",
            "Epoch 165: train_loss=0.6303 val_acc=0.5516 best=0.5552\n",
            "Epoch 166: train_loss=1.0230 val_acc=0.5160 best=0.5552\n",
            "Epoch 167: train_loss=0.8074 val_acc=0.5231 best=0.5552\n",
            "Epoch 168: train_loss=0.6144 val_acc=0.5267 best=0.5552\n",
            "Epoch 169: train_loss=1.1065 val_acc=0.5053 best=0.5552\n",
            "Epoch 170: train_loss=0.8767 val_acc=0.4911 best=0.5552\n",
            "Epoch 171: train_loss=0.6698 val_acc=0.5125 best=0.5552\n",
            "Epoch 172: train_loss=0.9847 val_acc=0.4840 best=0.5552\n",
            "Epoch 173: train_loss=0.5534 val_acc=0.5053 best=0.5552\n",
            "Epoch 174: train_loss=0.9857 val_acc=0.5053 best=0.5552\n",
            "Epoch 175: train_loss=0.5523 val_acc=0.5196 best=0.5552\n",
            "Epoch 176: train_loss=0.8067 val_acc=0.5374 best=0.5552\n",
            "Epoch 177: train_loss=1.1165 val_acc=0.5196 best=0.5552\n",
            "Epoch 178: train_loss=0.7292 val_acc=0.5480 best=0.5552\n",
            "Epoch 179: train_loss=0.7812 val_acc=0.5516 best=0.5552\n",
            "Epoch 180: train_loss=0.5550 val_acc=0.5480 best=0.5552\n",
            "Epoch 181: train_loss=0.8055 val_acc=0.5338 best=0.5552\n",
            "Epoch 182: train_loss=0.8076 val_acc=0.5338 best=0.5552\n",
            "Epoch 183: train_loss=0.6898 val_acc=0.5480 best=0.5552\n",
            "Epoch 184: train_loss=0.9494 val_acc=0.5338 best=0.5552\n",
            "Epoch 185: train_loss=0.6843 val_acc=0.5480 best=0.5552\n",
            "Epoch 186: train_loss=0.5162 val_acc=0.5516 best=0.5552\n",
            "Epoch 187: train_loss=0.7808 val_acc=0.5302 best=0.5552\n",
            "Epoch 188: train_loss=0.5961 val_acc=0.5160 best=0.5552\n",
            "Epoch 189: train_loss=0.7363 val_acc=0.5267 best=0.5552\n",
            "Epoch 190: train_loss=0.8340 val_acc=0.5267 best=0.5552\n",
            "Epoch 191: train_loss=0.6277 val_acc=0.5338 best=0.5552\n",
            "Epoch 192: train_loss=0.7355 val_acc=0.5338 best=0.5552\n",
            "Epoch 193: train_loss=0.7420 val_acc=0.5267 best=0.5552\n",
            "Epoch 194: train_loss=0.7841 val_acc=0.5160 best=0.5552\n",
            "Epoch 195: train_loss=0.5675 val_acc=0.5267 best=0.5552\n",
            "Epoch 196: train_loss=0.6494 val_acc=0.5338 best=0.5552\n",
            "Epoch 197: train_loss=0.6199 val_acc=0.5302 best=0.5552\n",
            "Epoch 198: train_loss=0.8644 val_acc=0.5267 best=0.5552\n",
            "Epoch 199: train_loss=0.6002 val_acc=0.5053 best=0.5552\n",
            "Epoch 200: train_loss=0.8341 val_acc=0.5196 best=0.5552\n",
            "Epoch 201: train_loss=0.6049 val_acc=0.5267 best=0.5552\n",
            "Epoch 202: train_loss=0.8029 val_acc=0.5267 best=0.5552\n",
            "Epoch 203: train_loss=0.6652 val_acc=0.5089 best=0.5552\n",
            "Epoch 204: train_loss=0.6202 val_acc=0.5231 best=0.5552\n",
            "Epoch 205: train_loss=0.6013 val_acc=0.5302 best=0.5552\n",
            "Epoch 206: train_loss=0.7408 val_acc=0.5302 best=0.5552\n",
            "Epoch 207: train_loss=0.6489 val_acc=0.5338 best=0.5552\n",
            "Epoch 208: train_loss=0.6636 val_acc=0.5374 best=0.5552\n",
            "Epoch 209: train_loss=0.7078 val_acc=0.5267 best=0.5552\n",
            "Epoch 210: train_loss=0.5620 val_acc=0.5338 best=0.5552\n",
            "Epoch 211: train_loss=0.8010 val_acc=0.5302 best=0.5552\n",
            "Epoch 212: train_loss=0.7122 val_acc=0.5267 best=0.5552\n",
            "Epoch 213: train_loss=0.7899 val_acc=0.5196 best=0.5552\n",
            "Epoch 214: train_loss=0.7181 val_acc=0.5267 best=0.5552\n",
            "Epoch 215: train_loss=0.6200 val_acc=0.5231 best=0.5552\n",
            "Epoch 216: train_loss=0.8395 val_acc=0.5231 best=0.5552\n",
            "Epoch 217: train_loss=0.5480 val_acc=0.5231 best=0.5552\n",
            "Epoch 218: train_loss=0.6754 val_acc=0.5267 best=0.5552\n",
            "Epoch 219: train_loss=0.8946 val_acc=0.5338 best=0.5552\n",
            "Epoch 220: train_loss=0.6995 val_acc=0.5302 best=0.5552\n",
            "Epoch 221: train_loss=0.6487 val_acc=0.5267 best=0.5552\n",
            "Epoch 222: train_loss=0.9064 val_acc=0.5267 best=0.5552\n",
            "Epoch 223: train_loss=0.6316 val_acc=0.5267 best=0.5552\n",
            "Epoch 224: train_loss=0.7463 val_acc=0.5338 best=0.5552\n",
            "Epoch 225: train_loss=0.5813 val_acc=0.5374 best=0.5552\n",
            "Epoch 226: train_loss=0.7658 val_acc=0.5338 best=0.5552\n",
            "Epoch 227: train_loss=0.8566 val_acc=0.5409 best=0.5552\n",
            "Epoch 228: train_loss=0.7884 val_acc=0.5445 best=0.5552\n",
            "Epoch 229: train_loss=0.7484 val_acc=0.5374 best=0.5552\n",
            "Epoch 230: train_loss=0.6393 val_acc=0.5409 best=0.5552\n",
            "Epoch 231: train_loss=0.7606 val_acc=0.5374 best=0.5552\n",
            "Epoch 232: train_loss=0.7222 val_acc=0.5374 best=0.5552\n",
            "Epoch 233: train_loss=0.7332 val_acc=0.5338 best=0.5552\n",
            "Epoch 234: train_loss=0.7558 val_acc=0.5374 best=0.5552\n",
            "Epoch 235: train_loss=0.7068 val_acc=0.5338 best=0.5552\n",
            "Epoch 236: train_loss=0.7595 val_acc=0.5338 best=0.5552\n",
            "Epoch 237: train_loss=0.8411 val_acc=0.5338 best=0.5552\n",
            "Epoch 238: train_loss=0.8429 val_acc=0.5338 best=0.5552\n",
            "Epoch 239: train_loss=0.6101 val_acc=0.5302 best=0.5552\n",
            "Epoch 240: train_loss=0.7539 val_acc=0.5302 best=0.5552\n",
            "Epoch 241: train_loss=0.9309 val_acc=0.5267 best=0.5552\n",
            "Epoch 242: train_loss=0.7515 val_acc=0.5231 best=0.5552\n",
            "Epoch 243: train_loss=0.7671 val_acc=0.5231 best=0.5552\n",
            "Epoch 244: train_loss=0.6430 val_acc=0.5231 best=0.5552\n",
            "Epoch 245: train_loss=0.7781 val_acc=0.5231 best=0.5552\n",
            "Epoch 246: train_loss=0.7919 val_acc=0.5231 best=0.5552\n",
            "Epoch 247: train_loss=0.6992 val_acc=0.5231 best=0.5552\n",
            "Epoch 248: train_loss=0.7674 val_acc=0.5231 best=0.5552\n",
            "Epoch 249: train_loss=0.8349 val_acc=0.5231 best=0.5552\n",
            "Epoch 250: train_loss=0.8714 val_acc=0.5231 best=0.5552\n",
            "\n",
            "=== Fold 2/5 ===\n",
            "Epoch 1: train_loss=1.9300 val_acc=0.2536 best=0.0000\n",
            "Epoch 2: train_loss=1.8771 val_acc=0.2286 best=0.2536\n",
            "Epoch 3: train_loss=1.7853 val_acc=0.2214 best=0.2536\n",
            "Epoch 4: train_loss=1.8070 val_acc=0.2393 best=0.2536\n",
            "Epoch 5: train_loss=1.7214 val_acc=0.2643 best=0.2536\n",
            "Epoch 6: train_loss=1.7702 val_acc=0.3143 best=0.2643\n",
            "Epoch 7: train_loss=1.6738 val_acc=0.3286 best=0.3143\n",
            "Epoch 8: train_loss=1.6444 val_acc=0.3643 best=0.3286\n",
            "Epoch 9: train_loss=1.6524 val_acc=0.4036 best=0.3643\n",
            "Epoch 10: train_loss=1.5581 val_acc=0.4214 best=0.4036\n",
            "Epoch 11: train_loss=1.5599 val_acc=0.4143 best=0.4214\n",
            "Epoch 12: train_loss=1.6520 val_acc=0.4107 best=0.4214\n",
            "Epoch 13: train_loss=1.5077 val_acc=0.4250 best=0.4214\n",
            "Epoch 14: train_loss=1.5162 val_acc=0.4393 best=0.4250\n",
            "Epoch 15: train_loss=1.5434 val_acc=0.4607 best=0.4393\n",
            "Epoch 16: train_loss=1.5082 val_acc=0.4643 best=0.4607\n",
            "Epoch 17: train_loss=1.4989 val_acc=0.4750 best=0.4643\n",
            "Epoch 18: train_loss=1.4880 val_acc=0.4714 best=0.4750\n",
            "Epoch 19: train_loss=1.4023 val_acc=0.5000 best=0.4750\n",
            "Epoch 20: train_loss=1.3467 val_acc=0.5036 best=0.5000\n",
            "Epoch 21: train_loss=1.3873 val_acc=0.4964 best=0.5036\n",
            "Epoch 22: train_loss=1.3055 val_acc=0.4893 best=0.5036\n",
            "Epoch 23: train_loss=1.3588 val_acc=0.5464 best=0.5036\n",
            "Epoch 24: train_loss=1.3213 val_acc=0.5000 best=0.5464\n",
            "Epoch 25: train_loss=1.2764 val_acc=0.5393 best=0.5464\n",
            "Epoch 26: train_loss=1.3107 val_acc=0.5321 best=0.5464\n",
            "Epoch 27: train_loss=1.1999 val_acc=0.5321 best=0.5464\n",
            "Epoch 28: train_loss=1.2625 val_acc=0.5000 best=0.5464\n",
            "Epoch 29: train_loss=1.3298 val_acc=0.5107 best=0.5464\n",
            "Epoch 30: train_loss=1.1417 val_acc=0.5214 best=0.5464\n",
            "Epoch 31: train_loss=1.1749 val_acc=0.5321 best=0.5464\n",
            "Epoch 32: train_loss=1.2919 val_acc=0.4964 best=0.5464\n",
            "Epoch 33: train_loss=1.3260 val_acc=0.5393 best=0.5464\n",
            "Epoch 34: train_loss=1.1894 val_acc=0.5214 best=0.5464\n",
            "Epoch 35: train_loss=1.1641 val_acc=0.5000 best=0.5464\n",
            "Epoch 36: train_loss=1.2028 val_acc=0.5143 best=0.5464\n",
            "Epoch 37: train_loss=1.0900 val_acc=0.5107 best=0.5464\n",
            "Epoch 38: train_loss=1.2266 val_acc=0.5643 best=0.5464\n",
            "Epoch 39: train_loss=1.0794 val_acc=0.4857 best=0.5643\n",
            "Epoch 40: train_loss=1.1647 val_acc=0.5357 best=0.5643\n",
            "Epoch 41: train_loss=1.0202 val_acc=0.5357 best=0.5643\n",
            "Epoch 42: train_loss=1.1877 val_acc=0.5250 best=0.5643\n",
            "Epoch 43: train_loss=1.1804 val_acc=0.5464 best=0.5643\n",
            "Epoch 44: train_loss=1.1755 val_acc=0.5500 best=0.5643\n",
            "Epoch 45: train_loss=1.1568 val_acc=0.5679 best=0.5643\n",
            "Epoch 46: train_loss=1.2174 val_acc=0.5286 best=0.5679\n",
            "Epoch 47: train_loss=1.2376 val_acc=0.5250 best=0.5679\n",
            "Epoch 48: train_loss=1.1337 val_acc=0.5464 best=0.5679\n",
            "Epoch 49: train_loss=1.2962 val_acc=0.5429 best=0.5679\n",
            "Epoch 50: train_loss=1.3226 val_acc=0.5179 best=0.5679\n",
            "Epoch 51: train_loss=1.0666 val_acc=0.5500 best=0.5679\n",
            "Epoch 52: train_loss=1.1590 val_acc=0.5107 best=0.5679\n",
            "Epoch 53: train_loss=1.0908 val_acc=0.5464 best=0.5679\n",
            "Epoch 54: train_loss=1.0060 val_acc=0.5107 best=0.5679\n",
            "Epoch 55: train_loss=1.1031 val_acc=0.5179 best=0.5679\n",
            "Epoch 56: train_loss=1.1552 val_acc=0.5500 best=0.5679\n",
            "Epoch 57: train_loss=0.9186 val_acc=0.5429 best=0.5679\n",
            "Epoch 58: train_loss=0.8814 val_acc=0.5536 best=0.5679\n",
            "Epoch 59: train_loss=1.1962 val_acc=0.5036 best=0.5679\n",
            "Epoch 60: train_loss=1.0721 val_acc=0.5536 best=0.5679\n",
            "Epoch 61: train_loss=1.1348 val_acc=0.5321 best=0.5679\n",
            "Epoch 62: train_loss=1.3067 val_acc=0.5571 best=0.5679\n",
            "Epoch 63: train_loss=1.0583 val_acc=0.5250 best=0.5679\n",
            "Epoch 64: train_loss=0.9712 val_acc=0.5786 best=0.5679\n",
            "Epoch 65: train_loss=1.1192 val_acc=0.5536 best=0.5786\n",
            "Epoch 66: train_loss=1.2896 val_acc=0.5571 best=0.5786\n",
            "Epoch 67: train_loss=1.0647 val_acc=0.5143 best=0.5786\n",
            "Epoch 68: train_loss=1.0393 val_acc=0.5500 best=0.5786\n",
            "Epoch 69: train_loss=1.0201 val_acc=0.5571 best=0.5786\n",
            "Epoch 70: train_loss=0.8713 val_acc=0.5357 best=0.5786\n",
            "Epoch 71: train_loss=1.0660 val_acc=0.5143 best=0.5786\n",
            "Epoch 72: train_loss=1.2715 val_acc=0.5786 best=0.5786\n",
            "Epoch 73: train_loss=0.9331 val_acc=0.5143 best=0.5786\n",
            "Epoch 74: train_loss=0.9296 val_acc=0.5214 best=0.5786\n",
            "Epoch 75: train_loss=1.0092 val_acc=0.5179 best=0.5786\n",
            "Epoch 76: train_loss=1.0501 val_acc=0.5571 best=0.5786\n",
            "Epoch 77: train_loss=1.1390 val_acc=0.5536 best=0.5786\n",
            "Epoch 78: train_loss=0.9073 val_acc=0.5250 best=0.5786\n",
            "Epoch 79: train_loss=1.0730 val_acc=0.5321 best=0.5786\n",
            "Epoch 80: train_loss=1.1245 val_acc=0.5321 best=0.5786\n",
            "Epoch 81: train_loss=0.9868 val_acc=0.5214 best=0.5786\n",
            "Epoch 82: train_loss=1.0733 val_acc=0.5357 best=0.5786\n",
            "Epoch 83: train_loss=0.9439 val_acc=0.5643 best=0.5786\n",
            "Epoch 84: train_loss=0.9168 val_acc=0.5607 best=0.5786\n",
            "Epoch 85: train_loss=1.1182 val_acc=0.5464 best=0.5786\n",
            "Epoch 86: train_loss=1.0339 val_acc=0.5571 best=0.5786\n",
            "Epoch 87: train_loss=1.0009 val_acc=0.5571 best=0.5786\n",
            "Epoch 88: train_loss=1.0100 val_acc=0.5714 best=0.5786\n",
            "Epoch 89: train_loss=1.1212 val_acc=0.5571 best=0.5786\n",
            "Epoch 90: train_loss=0.9465 val_acc=0.5393 best=0.5786\n",
            "Epoch 91: train_loss=0.8457 val_acc=0.5536 best=0.5786\n",
            "Epoch 92: train_loss=0.9349 val_acc=0.5821 best=0.5786\n",
            "Epoch 93: train_loss=0.8231 val_acc=0.5571 best=0.5821\n",
            "Epoch 94: train_loss=0.9966 val_acc=0.5571 best=0.5821\n",
            "Epoch 95: train_loss=0.7234 val_acc=0.5750 best=0.5821\n",
            "Epoch 96: train_loss=1.2202 val_acc=0.5750 best=0.5821\n",
            "Epoch 97: train_loss=0.8471 val_acc=0.5714 best=0.5821\n",
            "Epoch 98: train_loss=0.9798 val_acc=0.5679 best=0.5821\n",
            "Epoch 99: train_loss=0.8657 val_acc=0.5964 best=0.5821\n",
            "Epoch 100: train_loss=0.7516 val_acc=0.5964 best=0.5964\n",
            "Epoch 101: train_loss=0.9073 val_acc=0.5857 best=0.5964\n",
            "Epoch 102: train_loss=1.0862 val_acc=0.5643 best=0.5964\n",
            "Epoch 103: train_loss=0.9473 val_acc=0.5714 best=0.5964\n",
            "Epoch 104: train_loss=0.9990 val_acc=0.5536 best=0.5964\n",
            "Epoch 105: train_loss=0.8724 val_acc=0.5607 best=0.5964\n",
            "Epoch 106: train_loss=1.0996 val_acc=0.5643 best=0.5964\n",
            "Epoch 107: train_loss=0.8385 val_acc=0.5536 best=0.5964\n",
            "Epoch 108: train_loss=0.7295 val_acc=0.5464 best=0.5964\n",
            "Epoch 109: train_loss=0.7907 val_acc=0.5714 best=0.5964\n",
            "Epoch 110: train_loss=0.7753 val_acc=0.5821 best=0.5964\n",
            "Epoch 111: train_loss=0.8742 val_acc=0.5929 best=0.5964\n",
            "Epoch 112: train_loss=0.9711 val_acc=0.5750 best=0.5964\n",
            "Epoch 113: train_loss=0.8243 val_acc=0.5643 best=0.5964\n",
            "Epoch 114: train_loss=0.9008 val_acc=0.5464 best=0.5964\n",
            "Epoch 115: train_loss=0.7718 val_acc=0.5500 best=0.5964\n",
            "Epoch 116: train_loss=0.7068 val_acc=0.5500 best=0.5964\n",
            "Epoch 117: train_loss=0.9207 val_acc=0.5429 best=0.5964\n",
            "Epoch 118: train_loss=0.8121 val_acc=0.5750 best=0.5964\n",
            "Epoch 119: train_loss=0.8852 val_acc=0.5857 best=0.5964\n",
            "Epoch 120: train_loss=0.9387 val_acc=0.5857 best=0.5964\n",
            "Epoch 121: train_loss=0.8897 val_acc=0.5643 best=0.5964\n",
            "Epoch 122: train_loss=0.9150 val_acc=0.5750 best=0.5964\n",
            "Epoch 123: train_loss=0.9075 val_acc=0.5357 best=0.5964\n",
            "Epoch 124: train_loss=0.8455 val_acc=0.5643 best=0.5964\n",
            "Epoch 125: train_loss=0.7405 val_acc=0.5607 best=0.5964\n",
            "Epoch 126: train_loss=1.0328 val_acc=0.5607 best=0.5964\n",
            "Epoch 127: train_loss=0.7344 val_acc=0.5607 best=0.5964\n",
            "Epoch 128: train_loss=0.7882 val_acc=0.5857 best=0.5964\n",
            "Epoch 129: train_loss=0.7797 val_acc=0.5750 best=0.5964\n",
            "Epoch 130: train_loss=0.7795 val_acc=0.5821 best=0.5964\n",
            "Epoch 131: train_loss=0.8405 val_acc=0.5929 best=0.5964\n",
            "Epoch 132: train_loss=0.9580 val_acc=0.5821 best=0.5964\n",
            "Epoch 133: train_loss=0.6146 val_acc=0.6000 best=0.5964\n",
            "Epoch 134: train_loss=0.7212 val_acc=0.5571 best=0.6000\n",
            "Epoch 135: train_loss=0.8746 val_acc=0.5536 best=0.6000\n",
            "Epoch 136: train_loss=0.7234 val_acc=0.5750 best=0.6000\n",
            "Epoch 137: train_loss=0.6255 val_acc=0.5643 best=0.6000\n",
            "Epoch 138: train_loss=0.6510 val_acc=0.5750 best=0.6000\n",
            "Epoch 139: train_loss=0.6023 val_acc=0.5750 best=0.6000\n",
            "Epoch 140: train_loss=0.9050 val_acc=0.5750 best=0.6000\n",
            "Epoch 141: train_loss=0.9067 val_acc=0.5607 best=0.6000\n",
            "Epoch 142: train_loss=0.7947 val_acc=0.5643 best=0.6000\n",
            "Epoch 143: train_loss=0.6801 val_acc=0.5607 best=0.6000\n",
            "Epoch 144: train_loss=0.9137 val_acc=0.5857 best=0.6000\n",
            "Epoch 145: train_loss=0.9940 val_acc=0.5679 best=0.6000\n",
            "Epoch 146: train_loss=0.8344 val_acc=0.5750 best=0.6000\n",
            "Epoch 147: train_loss=0.8618 val_acc=0.5750 best=0.6000\n",
            "Epoch 148: train_loss=0.7586 val_acc=0.5964 best=0.6000\n",
            "Epoch 149: train_loss=0.9486 val_acc=0.5750 best=0.6000\n",
            "Epoch 150: train_loss=0.9038 val_acc=0.5750 best=0.6000\n",
            "Epoch 151: train_loss=0.8516 val_acc=0.5893 best=0.6000\n",
            "Epoch 152: train_loss=0.7219 val_acc=0.6107 best=0.6000\n",
            "Epoch 153: train_loss=0.7810 val_acc=0.5821 best=0.6107\n",
            "Epoch 154: train_loss=0.6524 val_acc=0.6036 best=0.6107\n",
            "Epoch 155: train_loss=0.6586 val_acc=0.5786 best=0.6107\n",
            "Epoch 156: train_loss=0.7590 val_acc=0.5964 best=0.6107\n",
            "Epoch 157: train_loss=0.8450 val_acc=0.6000 best=0.6107\n",
            "Epoch 158: train_loss=1.0083 val_acc=0.5786 best=0.6107\n",
            "Epoch 159: train_loss=0.6946 val_acc=0.5929 best=0.6107\n",
            "Epoch 160: train_loss=0.6477 val_acc=0.5893 best=0.6107\n",
            "Epoch 161: train_loss=0.5064 val_acc=0.5857 best=0.6107\n",
            "Epoch 162: train_loss=0.5602 val_acc=0.5857 best=0.6107\n",
            "Epoch 163: train_loss=0.8052 val_acc=0.6107 best=0.6107\n",
            "Epoch 164: train_loss=0.5689 val_acc=0.5964 best=0.6107\n",
            "Epoch 165: train_loss=0.8130 val_acc=0.5893 best=0.6107\n",
            "Epoch 166: train_loss=0.6738 val_acc=0.5857 best=0.6107\n",
            "Epoch 167: train_loss=0.7466 val_acc=0.5929 best=0.6107\n",
            "Epoch 168: train_loss=0.6445 val_acc=0.5964 best=0.6107\n",
            "Epoch 169: train_loss=0.6602 val_acc=0.5964 best=0.6107\n",
            "Epoch 170: train_loss=0.6680 val_acc=0.5857 best=0.6107\n",
            "Epoch 171: train_loss=0.6431 val_acc=0.5714 best=0.6107\n",
            "Epoch 172: train_loss=0.9054 val_acc=0.6000 best=0.6107\n",
            "Epoch 173: train_loss=0.6907 val_acc=0.5929 best=0.6107\n",
            "Epoch 174: train_loss=0.5485 val_acc=0.5750 best=0.6107\n",
            "Epoch 175: train_loss=1.0046 val_acc=0.5964 best=0.6107\n",
            "Epoch 176: train_loss=0.6519 val_acc=0.5750 best=0.6107\n",
            "Epoch 177: train_loss=0.7548 val_acc=0.5643 best=0.6107\n",
            "Epoch 178: train_loss=0.4614 val_acc=0.5893 best=0.6107\n",
            "Epoch 179: train_loss=0.7936 val_acc=0.5929 best=0.6107\n",
            "Epoch 180: train_loss=1.0988 val_acc=0.5893 best=0.6107\n",
            "Epoch 181: train_loss=0.7189 val_acc=0.5786 best=0.6107\n",
            "Epoch 182: train_loss=0.6731 val_acc=0.5821 best=0.6107\n",
            "Epoch 183: train_loss=0.5620 val_acc=0.5893 best=0.6107\n",
            "Epoch 184: train_loss=0.6066 val_acc=0.5857 best=0.6107\n",
            "Epoch 185: train_loss=0.8679 val_acc=0.5821 best=0.6107\n",
            "Epoch 186: train_loss=0.6574 val_acc=0.5929 best=0.6107\n",
            "Epoch 187: train_loss=0.5366 val_acc=0.6071 best=0.6107\n",
            "Epoch 188: train_loss=0.6756 val_acc=0.6000 best=0.6107\n",
            "Epoch 189: train_loss=0.7872 val_acc=0.5786 best=0.6107\n",
            "Epoch 190: train_loss=0.6757 val_acc=0.5643 best=0.6107\n",
            "Epoch 191: train_loss=0.6486 val_acc=0.5750 best=0.6107\n",
            "Epoch 192: train_loss=0.7661 val_acc=0.5679 best=0.6107\n",
            "Epoch 193: train_loss=0.6558 val_acc=0.5786 best=0.6107\n",
            "Epoch 194: train_loss=0.6887 val_acc=0.5786 best=0.6107\n",
            "Epoch 195: train_loss=0.6270 val_acc=0.5821 best=0.6107\n",
            "Epoch 196: train_loss=0.7168 val_acc=0.5679 best=0.6107\n",
            "Epoch 197: train_loss=0.7968 val_acc=0.5893 best=0.6107\n",
            "Epoch 198: train_loss=0.6648 val_acc=0.5786 best=0.6107\n",
            "Epoch 199: train_loss=0.4825 val_acc=0.5821 best=0.6107\n",
            "Epoch 200: train_loss=0.6441 val_acc=0.5750 best=0.6107\n",
            "Epoch 201: train_loss=0.7029 val_acc=0.5750 best=0.6107\n",
            "Epoch 202: train_loss=0.7091 val_acc=0.5750 best=0.6107\n",
            "Epoch 203: train_loss=0.7178 val_acc=0.5679 best=0.6107\n",
            "Epoch 204: train_loss=0.7868 val_acc=0.5643 best=0.6107\n",
            "Epoch 205: train_loss=0.7836 val_acc=0.5643 best=0.6107\n",
            "Epoch 206: train_loss=1.0222 val_acc=0.5750 best=0.6107\n",
            "Epoch 207: train_loss=0.7501 val_acc=0.5607 best=0.6107\n",
            "Epoch 208: train_loss=0.8265 val_acc=0.5643 best=0.6107\n",
            "Epoch 209: train_loss=0.4682 val_acc=0.5750 best=0.6107\n",
            "Epoch 210: train_loss=0.8255 val_acc=0.5786 best=0.6107\n",
            "Epoch 211: train_loss=0.7618 val_acc=0.5786 best=0.6107\n",
            "Epoch 212: train_loss=0.4370 val_acc=0.5786 best=0.6107\n",
            "Epoch 213: train_loss=0.8419 val_acc=0.5786 best=0.6107\n",
            "Epoch 214: train_loss=0.7642 val_acc=0.5750 best=0.6107\n",
            "Epoch 215: train_loss=0.6747 val_acc=0.5786 best=0.6107\n",
            "Epoch 216: train_loss=0.8536 val_acc=0.5786 best=0.6107\n",
            "Epoch 217: train_loss=0.6482 val_acc=0.5857 best=0.6107\n",
            "Epoch 218: train_loss=0.6835 val_acc=0.5857 best=0.6107\n",
            "Epoch 219: train_loss=0.5682 val_acc=0.5821 best=0.6107\n",
            "Epoch 220: train_loss=0.7478 val_acc=0.5857 best=0.6107\n",
            "Epoch 221: train_loss=0.6780 val_acc=0.5893 best=0.6107\n",
            "Epoch 222: train_loss=0.6930 val_acc=0.5786 best=0.6107\n",
            "Epoch 223: train_loss=0.6172 val_acc=0.5821 best=0.6107\n",
            "Epoch 224: train_loss=0.6846 val_acc=0.5857 best=0.6107\n",
            "Epoch 225: train_loss=0.9331 val_acc=0.5857 best=0.6107\n",
            "Epoch 226: train_loss=0.6997 val_acc=0.5750 best=0.6107\n",
            "Epoch 227: train_loss=0.8608 val_acc=0.5750 best=0.6107\n",
            "Epoch 228: train_loss=0.7113 val_acc=0.5857 best=0.6107\n",
            "Epoch 229: train_loss=0.8357 val_acc=0.5821 best=0.6107\n",
            "Epoch 230: train_loss=0.7124 val_acc=0.5786 best=0.6107\n",
            "Epoch 231: train_loss=0.5455 val_acc=0.5786 best=0.6107\n",
            "Epoch 232: train_loss=0.5447 val_acc=0.5857 best=0.6107\n",
            "Epoch 233: train_loss=0.7653 val_acc=0.5857 best=0.6107\n",
            "Epoch 234: train_loss=0.8261 val_acc=0.5857 best=0.6107\n",
            "Epoch 235: train_loss=0.5877 val_acc=0.5821 best=0.6107\n",
            "Epoch 236: train_loss=0.7210 val_acc=0.5821 best=0.6107\n",
            "Epoch 237: train_loss=0.6878 val_acc=0.5821 best=0.6107\n",
            "Epoch 238: train_loss=0.8926 val_acc=0.5821 best=0.6107\n",
            "Epoch 239: train_loss=0.7502 val_acc=0.5857 best=0.6107\n",
            "Epoch 240: train_loss=0.7760 val_acc=0.5857 best=0.6107\n",
            "Epoch 241: train_loss=0.5499 val_acc=0.5893 best=0.6107\n",
            "Epoch 242: train_loss=0.7518 val_acc=0.5893 best=0.6107\n",
            "Epoch 243: train_loss=0.8334 val_acc=0.5893 best=0.6107\n",
            "Epoch 244: train_loss=0.6454 val_acc=0.5893 best=0.6107\n",
            "Epoch 245: train_loss=1.0041 val_acc=0.5893 best=0.6107\n",
            "Epoch 246: train_loss=0.6440 val_acc=0.5893 best=0.6107\n",
            "Epoch 247: train_loss=0.7045 val_acc=0.5893 best=0.6107\n",
            "Epoch 248: train_loss=0.8167 val_acc=0.5893 best=0.6107\n",
            "Epoch 249: train_loss=0.6820 val_acc=0.5893 best=0.6107\n",
            "Epoch 250: train_loss=0.6289 val_acc=0.5893 best=0.6107\n",
            "\n",
            "=== Fold 3/5 ===\n",
            "Epoch 1: train_loss=1.9260 val_acc=0.2500 best=0.0000\n",
            "Epoch 2: train_loss=1.8688 val_acc=0.2929 best=0.2500\n",
            "Epoch 3: train_loss=1.8230 val_acc=0.2929 best=0.2929\n",
            "Epoch 4: train_loss=1.7402 val_acc=0.2821 best=0.2929\n",
            "Epoch 5: train_loss=1.7649 val_acc=0.3214 best=0.2929\n",
            "Epoch 6: train_loss=1.7339 val_acc=0.3714 best=0.3214\n",
            "Epoch 7: train_loss=1.7100 val_acc=0.3750 best=0.3714\n",
            "Epoch 8: train_loss=1.6536 val_acc=0.3643 best=0.3750\n",
            "Epoch 9: train_loss=1.6596 val_acc=0.3857 best=0.3750\n",
            "Epoch 10: train_loss=1.6307 val_acc=0.3929 best=0.3857\n",
            "Epoch 11: train_loss=1.5742 val_acc=0.4214 best=0.3929\n",
            "Epoch 12: train_loss=1.5008 val_acc=0.3964 best=0.4214\n",
            "Epoch 13: train_loss=1.5341 val_acc=0.4286 best=0.4214\n",
            "Epoch 14: train_loss=1.5324 val_acc=0.4214 best=0.4286\n",
            "Epoch 15: train_loss=1.4592 val_acc=0.4643 best=0.4286\n",
            "Epoch 16: train_loss=1.4856 val_acc=0.4607 best=0.4643\n",
            "Epoch 17: train_loss=1.5404 val_acc=0.4786 best=0.4643\n",
            "Epoch 18: train_loss=1.4368 val_acc=0.5000 best=0.4786\n",
            "Epoch 19: train_loss=1.4025 val_acc=0.5107 best=0.5000\n",
            "Epoch 20: train_loss=1.3544 val_acc=0.4929 best=0.5107\n",
            "Epoch 21: train_loss=1.4321 val_acc=0.5464 best=0.5107\n",
            "Epoch 22: train_loss=1.3631 val_acc=0.5393 best=0.5464\n",
            "Epoch 23: train_loss=1.4618 val_acc=0.5036 best=0.5464\n",
            "Epoch 24: train_loss=1.2712 val_acc=0.5143 best=0.5464\n",
            "Epoch 25: train_loss=1.2297 val_acc=0.4857 best=0.5464\n",
            "Epoch 26: train_loss=1.3576 val_acc=0.5179 best=0.5464\n",
            "Epoch 27: train_loss=1.2842 val_acc=0.4929 best=0.5464\n",
            "Epoch 28: train_loss=1.2162 val_acc=0.5214 best=0.5464\n",
            "Epoch 29: train_loss=1.3136 val_acc=0.5179 best=0.5464\n",
            "Epoch 30: train_loss=1.4840 val_acc=0.5071 best=0.5464\n",
            "Epoch 31: train_loss=1.2338 val_acc=0.5321 best=0.5464\n",
            "Epoch 32: train_loss=1.2666 val_acc=0.5143 best=0.5464\n",
            "Epoch 33: train_loss=1.2179 val_acc=0.5214 best=0.5464\n",
            "Epoch 34: train_loss=1.1272 val_acc=0.5286 best=0.5464\n",
            "Epoch 35: train_loss=1.1811 val_acc=0.5286 best=0.5464\n",
            "Epoch 36: train_loss=1.1661 val_acc=0.5143 best=0.5464\n",
            "Epoch 37: train_loss=1.1679 val_acc=0.5500 best=0.5464\n",
            "Epoch 38: train_loss=1.0627 val_acc=0.5179 best=0.5500\n",
            "Epoch 39: train_loss=1.1406 val_acc=0.5179 best=0.5500\n",
            "Epoch 40: train_loss=1.1294 val_acc=0.4893 best=0.5500\n",
            "Epoch 41: train_loss=1.4058 val_acc=0.5071 best=0.5500\n",
            "Epoch 42: train_loss=1.3229 val_acc=0.5107 best=0.5500\n",
            "Epoch 43: train_loss=1.2561 val_acc=0.5250 best=0.5500\n",
            "Epoch 44: train_loss=1.1129 val_acc=0.4893 best=0.5500\n",
            "Epoch 45: train_loss=1.2089 val_acc=0.5429 best=0.5500\n",
            "Epoch 46: train_loss=1.0654 val_acc=0.5429 best=0.5500\n",
            "Epoch 47: train_loss=1.2625 val_acc=0.4893 best=0.5500\n",
            "Epoch 48: train_loss=1.1421 val_acc=0.5357 best=0.5500\n",
            "Epoch 49: train_loss=0.9942 val_acc=0.5393 best=0.5500\n",
            "Epoch 50: train_loss=1.1165 val_acc=0.5286 best=0.5500\n",
            "Epoch 51: train_loss=1.1325 val_acc=0.5250 best=0.5500\n",
            "Epoch 52: train_loss=1.2651 val_acc=0.4750 best=0.5500\n",
            "Epoch 53: train_loss=1.2991 val_acc=0.5357 best=0.5500\n",
            "Epoch 54: train_loss=1.2064 val_acc=0.4929 best=0.5500\n",
            "Epoch 55: train_loss=1.0898 val_acc=0.5464 best=0.5500\n",
            "Epoch 56: train_loss=1.1976 val_acc=0.5536 best=0.5500\n",
            "Epoch 57: train_loss=1.1662 val_acc=0.5250 best=0.5536\n",
            "Epoch 58: train_loss=0.9933 val_acc=0.5036 best=0.5536\n",
            "Epoch 59: train_loss=1.1612 val_acc=0.4964 best=0.5536\n",
            "Epoch 60: train_loss=1.2332 val_acc=0.5179 best=0.5536\n",
            "Epoch 61: train_loss=1.2834 val_acc=0.5321 best=0.5536\n",
            "Epoch 62: train_loss=1.0196 val_acc=0.4893 best=0.5536\n",
            "Epoch 63: train_loss=1.1248 val_acc=0.5107 best=0.5536\n",
            "Epoch 64: train_loss=1.3506 val_acc=0.5000 best=0.5536\n",
            "Epoch 65: train_loss=1.1434 val_acc=0.4893 best=0.5536\n",
            "Epoch 66: train_loss=0.9032 val_acc=0.4893 best=0.5536\n",
            "Epoch 67: train_loss=1.0726 val_acc=0.5071 best=0.5536\n",
            "Epoch 68: train_loss=0.9356 val_acc=0.4893 best=0.5536\n",
            "Epoch 69: train_loss=1.0522 val_acc=0.4714 best=0.5536\n",
            "Epoch 70: train_loss=1.0453 val_acc=0.5286 best=0.5536\n",
            "Epoch 71: train_loss=1.1362 val_acc=0.5000 best=0.5536\n",
            "Epoch 72: train_loss=1.0279 val_acc=0.5464 best=0.5536\n",
            "Epoch 73: train_loss=0.9823 val_acc=0.4750 best=0.5536\n",
            "Epoch 74: train_loss=0.9138 val_acc=0.5036 best=0.5536\n",
            "Epoch 75: train_loss=1.1915 val_acc=0.5036 best=0.5536\n",
            "Epoch 76: train_loss=0.9653 val_acc=0.5107 best=0.5536\n",
            "Epoch 77: train_loss=1.0082 val_acc=0.5464 best=0.5536\n",
            "Epoch 78: train_loss=0.9065 val_acc=0.5036 best=0.5536\n",
            "Epoch 79: train_loss=0.9707 val_acc=0.5179 best=0.5536\n",
            "Epoch 80: train_loss=1.0961 val_acc=0.4964 best=0.5536\n",
            "Epoch 81: train_loss=0.8707 val_acc=0.4714 best=0.5536\n",
            "Epoch 82: train_loss=1.0910 val_acc=0.4750 best=0.5536\n",
            "Epoch 83: train_loss=1.0678 val_acc=0.4786 best=0.5536\n",
            "Epoch 84: train_loss=1.0362 val_acc=0.4964 best=0.5536\n",
            "Epoch 85: train_loss=1.1796 val_acc=0.5036 best=0.5536\n",
            "Epoch 86: train_loss=0.9747 val_acc=0.4714 best=0.5536\n",
            "Epoch 87: train_loss=0.9174 val_acc=0.5036 best=0.5536\n",
            "Epoch 88: train_loss=1.0303 val_acc=0.5214 best=0.5536\n",
            "Epoch 89: train_loss=0.9777 val_acc=0.5000 best=0.5536\n",
            "Epoch 90: train_loss=0.9121 val_acc=0.5000 best=0.5536\n",
            "Epoch 91: train_loss=0.8901 val_acc=0.5464 best=0.5536\n",
            "Epoch 92: train_loss=0.7592 val_acc=0.4964 best=0.5536\n",
            "Epoch 93: train_loss=0.9924 val_acc=0.4786 best=0.5536\n",
            "Epoch 94: train_loss=1.1836 val_acc=0.4964 best=0.5536\n",
            "Epoch 95: train_loss=0.9128 val_acc=0.5143 best=0.5536\n",
            "Epoch 96: train_loss=0.8131 val_acc=0.5000 best=0.5536\n",
            "Epoch 97: train_loss=1.1723 val_acc=0.4679 best=0.5536\n",
            "Epoch 98: train_loss=0.8246 val_acc=0.5179 best=0.5536\n",
            "Epoch 99: train_loss=1.0184 val_acc=0.5321 best=0.5536\n",
            "Epoch 100: train_loss=0.9779 val_acc=0.5036 best=0.5536\n",
            "Epoch 101: train_loss=0.7956 val_acc=0.5357 best=0.5536\n",
            "Epoch 102: train_loss=0.8638 val_acc=0.5179 best=0.5536\n",
            "Epoch 103: train_loss=0.8044 val_acc=0.5464 best=0.5536\n",
            "Epoch 104: train_loss=0.7891 val_acc=0.5036 best=0.5536\n",
            "Epoch 105: train_loss=0.8066 val_acc=0.5286 best=0.5536\n",
            "Epoch 106: train_loss=1.0032 val_acc=0.5071 best=0.5536\n",
            "Epoch 107: train_loss=0.9130 val_acc=0.5500 best=0.5536\n",
            "Epoch 108: train_loss=0.7181 val_acc=0.4964 best=0.5536\n",
            "Epoch 109: train_loss=0.8469 val_acc=0.5536 best=0.5536\n",
            "Epoch 110: train_loss=0.6946 val_acc=0.5464 best=0.5536\n",
            "Epoch 111: train_loss=1.0385 val_acc=0.5179 best=0.5536\n",
            "Epoch 112: train_loss=0.9392 val_acc=0.4821 best=0.5536\n",
            "Epoch 113: train_loss=0.9319 val_acc=0.5536 best=0.5536\n",
            "Epoch 114: train_loss=0.9194 val_acc=0.5143 best=0.5536\n",
            "Epoch 115: train_loss=1.0017 val_acc=0.4929 best=0.5536\n",
            "Epoch 116: train_loss=0.8114 val_acc=0.5107 best=0.5536\n",
            "Epoch 117: train_loss=1.1294 val_acc=0.5250 best=0.5536\n",
            "Epoch 118: train_loss=0.6316 val_acc=0.5321 best=0.5536\n",
            "Epoch 119: train_loss=1.2170 val_acc=0.4893 best=0.5536\n",
            "Epoch 120: train_loss=1.0207 val_acc=0.5321 best=0.5536\n",
            "Epoch 121: train_loss=0.7351 val_acc=0.5357 best=0.5536\n",
            "Epoch 122: train_loss=0.8169 val_acc=0.5143 best=0.5536\n",
            "Epoch 123: train_loss=0.7107 val_acc=0.4964 best=0.5536\n",
            "Epoch 124: train_loss=0.9738 val_acc=0.5429 best=0.5536\n",
            "Epoch 125: train_loss=0.7606 val_acc=0.5571 best=0.5536\n",
            "Epoch 126: train_loss=0.8546 val_acc=0.5286 best=0.5571\n",
            "Epoch 127: train_loss=0.9408 val_acc=0.4964 best=0.5571\n",
            "Epoch 128: train_loss=0.6343 val_acc=0.5179 best=0.5571\n",
            "Epoch 129: train_loss=0.7415 val_acc=0.5429 best=0.5571\n",
            "Epoch 130: train_loss=0.9075 val_acc=0.5393 best=0.5571\n",
            "Epoch 131: train_loss=0.8099 val_acc=0.5321 best=0.5571\n",
            "Epoch 132: train_loss=0.8436 val_acc=0.5429 best=0.5571\n",
            "Epoch 133: train_loss=0.8329 val_acc=0.5143 best=0.5571\n",
            "Epoch 134: train_loss=0.6167 val_acc=0.5786 best=0.5571\n",
            "Epoch 135: train_loss=0.7942 val_acc=0.5214 best=0.5786\n",
            "Epoch 136: train_loss=0.9083 val_acc=0.5357 best=0.5786\n",
            "Epoch 137: train_loss=0.6368 val_acc=0.5071 best=0.5786\n",
            "Epoch 138: train_loss=0.6404 val_acc=0.5357 best=0.5786\n",
            "Epoch 139: train_loss=0.7252 val_acc=0.5214 best=0.5786\n",
            "Epoch 140: train_loss=0.8051 val_acc=0.5571 best=0.5786\n",
            "Epoch 141: train_loss=0.8581 val_acc=0.5214 best=0.5786\n",
            "Epoch 142: train_loss=0.7488 val_acc=0.5357 best=0.5786\n",
            "Epoch 143: train_loss=0.9424 val_acc=0.5107 best=0.5786\n",
            "Epoch 144: train_loss=0.7103 val_acc=0.5036 best=0.5786\n",
            "Epoch 145: train_loss=0.7436 val_acc=0.5286 best=0.5786\n",
            "Epoch 146: train_loss=0.7570 val_acc=0.5250 best=0.5786\n",
            "Epoch 147: train_loss=0.7351 val_acc=0.5607 best=0.5786\n",
            "Epoch 148: train_loss=0.9270 val_acc=0.5429 best=0.5786\n",
            "Epoch 149: train_loss=0.6700 val_acc=0.5107 best=0.5786\n",
            "Epoch 150: train_loss=0.8917 val_acc=0.5179 best=0.5786\n",
            "Epoch 151: train_loss=0.7624 val_acc=0.5464 best=0.5786\n",
            "Epoch 152: train_loss=0.7976 val_acc=0.5286 best=0.5786\n",
            "Epoch 153: train_loss=0.7968 val_acc=0.5393 best=0.5786\n",
            "Epoch 154: train_loss=0.7631 val_acc=0.5357 best=0.5786\n",
            "Epoch 155: train_loss=0.7453 val_acc=0.5536 best=0.5786\n",
            "Epoch 156: train_loss=0.5108 val_acc=0.5393 best=0.5786\n",
            "Epoch 157: train_loss=0.7892 val_acc=0.5429 best=0.5786\n",
            "Epoch 158: train_loss=0.6783 val_acc=0.5321 best=0.5786\n",
            "Epoch 159: train_loss=0.7809 val_acc=0.5571 best=0.5786\n",
            "Epoch 160: train_loss=0.6910 val_acc=0.5429 best=0.5786\n",
            "Epoch 161: train_loss=0.6754 val_acc=0.5250 best=0.5786\n",
            "Epoch 162: train_loss=0.7657 val_acc=0.5357 best=0.5786\n",
            "Epoch 163: train_loss=1.0243 val_acc=0.5357 best=0.5786\n",
            "Epoch 164: train_loss=0.6508 val_acc=0.5500 best=0.5786\n",
            "Epoch 165: train_loss=0.7480 val_acc=0.5429 best=0.5786\n",
            "Epoch 166: train_loss=0.5842 val_acc=0.5250 best=0.5786\n",
            "Epoch 167: train_loss=0.6740 val_acc=0.5464 best=0.5786\n",
            "Epoch 168: train_loss=0.8907 val_acc=0.5500 best=0.5786\n",
            "Epoch 169: train_loss=0.8916 val_acc=0.5321 best=0.5786\n",
            "Epoch 170: train_loss=0.9611 val_acc=0.5393 best=0.5786\n",
            "Epoch 171: train_loss=0.8149 val_acc=0.5464 best=0.5786\n",
            "Epoch 172: train_loss=0.7539 val_acc=0.5500 best=0.5786\n",
            "Epoch 173: train_loss=0.8866 val_acc=0.5500 best=0.5786\n",
            "Epoch 174: train_loss=0.8723 val_acc=0.5393 best=0.5786\n",
            "Epoch 175: train_loss=0.8774 val_acc=0.5286 best=0.5786\n",
            "Epoch 176: train_loss=0.9698 val_acc=0.5464 best=0.5786\n",
            "Epoch 177: train_loss=0.7252 val_acc=0.5429 best=0.5786\n",
            "Epoch 178: train_loss=0.6788 val_acc=0.5464 best=0.5786\n",
            "Epoch 179: train_loss=0.8979 val_acc=0.5536 best=0.5786\n",
            "Epoch 180: train_loss=0.8066 val_acc=0.5607 best=0.5786\n",
            "Epoch 181: train_loss=0.7959 val_acc=0.5357 best=0.5786\n",
            "Epoch 182: train_loss=0.5648 val_acc=0.5286 best=0.5786\n",
            "Epoch 183: train_loss=0.7296 val_acc=0.5393 best=0.5786\n",
            "Epoch 184: train_loss=0.7333 val_acc=0.5429 best=0.5786\n",
            "Epoch 185: train_loss=1.0151 val_acc=0.5500 best=0.5786\n",
            "Epoch 186: train_loss=0.7204 val_acc=0.5500 best=0.5786\n",
            "Epoch 187: train_loss=0.6994 val_acc=0.5571 best=0.5786\n",
            "Epoch 188: train_loss=0.9205 val_acc=0.5571 best=0.5786\n",
            "Epoch 189: train_loss=0.6026 val_acc=0.5571 best=0.5786\n",
            "Epoch 190: train_loss=0.5184 val_acc=0.5714 best=0.5786\n",
            "Epoch 191: train_loss=0.6017 val_acc=0.5643 best=0.5786\n",
            "Epoch 192: train_loss=0.7502 val_acc=0.5643 best=0.5786\n",
            "Epoch 193: train_loss=0.7612 val_acc=0.5643 best=0.5786\n",
            "Epoch 194: train_loss=0.6259 val_acc=0.5607 best=0.5786\n",
            "Epoch 195: train_loss=0.7495 val_acc=0.5536 best=0.5786\n",
            "Epoch 196: train_loss=0.6310 val_acc=0.5536 best=0.5786\n",
            "Epoch 197: train_loss=0.7410 val_acc=0.5464 best=0.5786\n",
            "Epoch 198: train_loss=0.4793 val_acc=0.5536 best=0.5786\n",
            "Epoch 199: train_loss=0.6058 val_acc=0.5571 best=0.5786\n",
            "Epoch 200: train_loss=0.8027 val_acc=0.5607 best=0.5786\n",
            "Epoch 201: train_loss=0.5631 val_acc=0.5607 best=0.5786\n",
            "Epoch 202: train_loss=0.6221 val_acc=0.5571 best=0.5786\n",
            "Epoch 203: train_loss=0.6026 val_acc=0.5643 best=0.5786\n",
            "Epoch 204: train_loss=0.7661 val_acc=0.5464 best=0.5786\n",
            "Epoch 205: train_loss=0.8017 val_acc=0.5357 best=0.5786\n",
            "Epoch 206: train_loss=0.6399 val_acc=0.5500 best=0.5786\n",
            "Epoch 207: train_loss=0.6789 val_acc=0.5643 best=0.5786\n",
            "Epoch 208: train_loss=0.6266 val_acc=0.5500 best=0.5786\n",
            "Epoch 209: train_loss=0.7026 val_acc=0.5536 best=0.5786\n",
            "Epoch 210: train_loss=0.7398 val_acc=0.5536 best=0.5786\n",
            "Epoch 211: train_loss=0.6794 val_acc=0.5536 best=0.5786\n",
            "Epoch 212: train_loss=0.6580 val_acc=0.5500 best=0.5786\n",
            "Epoch 213: train_loss=0.7085 val_acc=0.5464 best=0.5786\n",
            "Epoch 214: train_loss=0.7575 val_acc=0.5500 best=0.5786\n",
            "Epoch 215: train_loss=0.6506 val_acc=0.5500 best=0.5786\n",
            "Epoch 216: train_loss=0.6682 val_acc=0.5571 best=0.5786\n",
            "Epoch 217: train_loss=0.5759 val_acc=0.5536 best=0.5786\n",
            "Epoch 218: train_loss=0.6258 val_acc=0.5571 best=0.5786\n",
            "Epoch 219: train_loss=0.6348 val_acc=0.5679 best=0.5786\n",
            "Epoch 220: train_loss=0.6762 val_acc=0.5643 best=0.5786\n",
            "Epoch 221: train_loss=0.7351 val_acc=0.5571 best=0.5786\n",
            "Epoch 222: train_loss=0.6827 val_acc=0.5679 best=0.5786\n",
            "Epoch 223: train_loss=0.8142 val_acc=0.5679 best=0.5786\n",
            "Epoch 224: train_loss=0.7097 val_acc=0.5607 best=0.5786\n",
            "Epoch 225: train_loss=1.0095 val_acc=0.5679 best=0.5786\n",
            "Epoch 226: train_loss=0.8420 val_acc=0.5607 best=0.5786\n",
            "Epoch 227: train_loss=0.5930 val_acc=0.5643 best=0.5786\n",
            "Epoch 228: train_loss=0.5856 val_acc=0.5643 best=0.5786\n",
            "Epoch 229: train_loss=0.7329 val_acc=0.5643 best=0.5786\n",
            "Epoch 230: train_loss=0.7950 val_acc=0.5607 best=0.5786\n",
            "Epoch 231: train_loss=0.5948 val_acc=0.5536 best=0.5786\n",
            "Epoch 232: train_loss=1.0129 val_acc=0.5571 best=0.5786\n",
            "Epoch 233: train_loss=0.9468 val_acc=0.5536 best=0.5786\n",
            "Epoch 234: train_loss=0.5374 val_acc=0.5536 best=0.5786\n",
            "Epoch 235: train_loss=0.5495 val_acc=0.5536 best=0.5786\n",
            "Epoch 236: train_loss=0.7084 val_acc=0.5500 best=0.5786\n",
            "Epoch 237: train_loss=0.7799 val_acc=0.5500 best=0.5786\n",
            "Epoch 238: train_loss=0.6329 val_acc=0.5500 best=0.5786\n",
            "Epoch 239: train_loss=0.7520 val_acc=0.5500 best=0.5786\n",
            "Epoch 240: train_loss=0.7260 val_acc=0.5500 best=0.5786\n",
            "Epoch 241: train_loss=0.5193 val_acc=0.5500 best=0.5786\n",
            "Epoch 242: train_loss=0.7173 val_acc=0.5500 best=0.5786\n",
            "Epoch 243: train_loss=0.6962 val_acc=0.5500 best=0.5786\n",
            "Epoch 244: train_loss=0.8043 val_acc=0.5464 best=0.5786\n",
            "Epoch 245: train_loss=0.6464 val_acc=0.5464 best=0.5786\n",
            "Epoch 246: train_loss=0.5762 val_acc=0.5464 best=0.5786\n",
            "Epoch 247: train_loss=0.6904 val_acc=0.5464 best=0.5786\n",
            "Epoch 248: train_loss=0.4697 val_acc=0.5464 best=0.5786\n",
            "Epoch 249: train_loss=0.9463 val_acc=0.5464 best=0.5786\n",
            "Epoch 250: train_loss=0.7067 val_acc=0.5464 best=0.5786\n",
            "\n",
            "=== Fold 4/5 ===\n",
            "Epoch 1: train_loss=1.9305 val_acc=0.3000 best=0.0000\n",
            "Epoch 2: train_loss=1.8713 val_acc=0.2500 best=0.3000\n",
            "Epoch 3: train_loss=1.7919 val_acc=0.2571 best=0.3000\n",
            "Epoch 4: train_loss=1.7426 val_acc=0.2750 best=0.3000\n",
            "Epoch 5: train_loss=1.7190 val_acc=0.3000 best=0.3000\n",
            "Epoch 6: train_loss=1.7209 val_acc=0.3214 best=0.3000\n",
            "Epoch 7: train_loss=1.6104 val_acc=0.3214 best=0.3214\n",
            "Epoch 8: train_loss=1.6351 val_acc=0.3536 best=0.3214\n",
            "Epoch 9: train_loss=1.6254 val_acc=0.3821 best=0.3536\n",
            "Epoch 10: train_loss=1.6458 val_acc=0.3786 best=0.3821\n",
            "Epoch 11: train_loss=1.6019 val_acc=0.4036 best=0.3821\n",
            "Epoch 12: train_loss=1.4985 val_acc=0.4179 best=0.4036\n",
            "Epoch 13: train_loss=1.5737 val_acc=0.4250 best=0.4179\n",
            "Epoch 14: train_loss=1.5183 val_acc=0.4179 best=0.4250\n",
            "Epoch 15: train_loss=1.5439 val_acc=0.4393 best=0.4250\n",
            "Epoch 16: train_loss=1.4244 val_acc=0.4786 best=0.4393\n",
            "Epoch 17: train_loss=1.4974 val_acc=0.4857 best=0.4786\n",
            "Epoch 18: train_loss=1.3953 val_acc=0.4964 best=0.4857\n",
            "Epoch 19: train_loss=1.4028 val_acc=0.4429 best=0.4964\n",
            "Epoch 20: train_loss=1.4046 val_acc=0.4679 best=0.4964\n",
            "Epoch 21: train_loss=1.3235 val_acc=0.4821 best=0.4964\n",
            "Epoch 22: train_loss=1.4517 val_acc=0.4821 best=0.4964\n",
            "Epoch 23: train_loss=1.3295 val_acc=0.4964 best=0.4964\n",
            "Epoch 24: train_loss=1.3221 val_acc=0.4786 best=0.4964\n",
            "Epoch 25: train_loss=1.4054 val_acc=0.4750 best=0.4964\n",
            "Epoch 26: train_loss=1.3411 val_acc=0.4929 best=0.4964\n",
            "Epoch 27: train_loss=1.3185 val_acc=0.5036 best=0.4964\n",
            "Epoch 28: train_loss=1.2718 val_acc=0.5214 best=0.5036\n",
            "Epoch 29: train_loss=1.1205 val_acc=0.5143 best=0.5214\n",
            "Epoch 30: train_loss=1.1874 val_acc=0.5071 best=0.5214\n",
            "Epoch 31: train_loss=1.2482 val_acc=0.5250 best=0.5214\n",
            "Epoch 32: train_loss=1.1274 val_acc=0.4821 best=0.5250\n",
            "Epoch 33: train_loss=1.2383 val_acc=0.5214 best=0.5250\n",
            "Epoch 34: train_loss=1.2961 val_acc=0.4786 best=0.5250\n",
            "Epoch 35: train_loss=1.1575 val_acc=0.5107 best=0.5250\n",
            "Epoch 36: train_loss=1.1653 val_acc=0.5214 best=0.5250\n",
            "Epoch 37: train_loss=1.2261 val_acc=0.5214 best=0.5250\n",
            "Epoch 38: train_loss=1.2338 val_acc=0.5000 best=0.5250\n",
            "Epoch 39: train_loss=1.0209 val_acc=0.5393 best=0.5250\n",
            "Epoch 40: train_loss=1.1734 val_acc=0.4964 best=0.5393\n",
            "Epoch 41: train_loss=1.2425 val_acc=0.5036 best=0.5393\n",
            "Epoch 42: train_loss=1.0712 val_acc=0.4750 best=0.5393\n",
            "Epoch 43: train_loss=1.0415 val_acc=0.4929 best=0.5393\n",
            "Epoch 44: train_loss=1.2406 val_acc=0.5214 best=0.5393\n",
            "Epoch 45: train_loss=1.2338 val_acc=0.4929 best=0.5393\n",
            "Epoch 46: train_loss=1.1237 val_acc=0.5607 best=0.5393\n",
            "Epoch 47: train_loss=1.0428 val_acc=0.5000 best=0.5607\n",
            "Epoch 48: train_loss=1.1233 val_acc=0.5000 best=0.5607\n",
            "Epoch 49: train_loss=1.1403 val_acc=0.5036 best=0.5607\n",
            "Epoch 50: train_loss=0.8566 val_acc=0.4679 best=0.5607\n",
            "Epoch 51: train_loss=1.0944 val_acc=0.4857 best=0.5607\n",
            "Epoch 52: train_loss=1.0183 val_acc=0.4929 best=0.5607\n",
            "Epoch 53: train_loss=1.0570 val_acc=0.5536 best=0.5607\n",
            "Epoch 54: train_loss=1.1293 val_acc=0.5107 best=0.5607\n",
            "Epoch 55: train_loss=1.2117 val_acc=0.5107 best=0.5607\n",
            "Epoch 56: train_loss=1.1570 val_acc=0.4714 best=0.5607\n",
            "Epoch 57: train_loss=1.1314 val_acc=0.5143 best=0.5607\n",
            "Epoch 58: train_loss=1.0864 val_acc=0.4929 best=0.5607\n",
            "Epoch 59: train_loss=0.9523 val_acc=0.5036 best=0.5607\n",
            "Epoch 60: train_loss=1.0897 val_acc=0.4964 best=0.5607\n",
            "Epoch 61: train_loss=1.1709 val_acc=0.5143 best=0.5607\n",
            "Epoch 62: train_loss=0.9601 val_acc=0.4786 best=0.5607\n",
            "Epoch 63: train_loss=1.1435 val_acc=0.4929 best=0.5607\n",
            "Epoch 64: train_loss=1.0176 val_acc=0.5000 best=0.5607\n",
            "Epoch 65: train_loss=1.0617 val_acc=0.5036 best=0.5607\n",
            "Epoch 66: train_loss=1.0778 val_acc=0.4893 best=0.5607\n",
            "Epoch 67: train_loss=0.9671 val_acc=0.4786 best=0.5607\n",
            "Epoch 68: train_loss=1.1390 val_acc=0.4857 best=0.5607\n",
            "Epoch 69: train_loss=1.0090 val_acc=0.4929 best=0.5607\n",
            "Epoch 70: train_loss=1.1753 val_acc=0.4964 best=0.5607\n",
            "Epoch 71: train_loss=1.1133 val_acc=0.5250 best=0.5607\n",
            "Epoch 72: train_loss=1.0670 val_acc=0.4821 best=0.5607\n",
            "Epoch 73: train_loss=0.9561 val_acc=0.5214 best=0.5607\n",
            "Epoch 74: train_loss=1.0133 val_acc=0.5036 best=0.5607\n",
            "Epoch 75: train_loss=1.0532 val_acc=0.4893 best=0.5607\n",
            "Epoch 76: train_loss=0.9776 val_acc=0.5071 best=0.5607\n",
            "Epoch 77: train_loss=0.9383 val_acc=0.5286 best=0.5607\n",
            "Epoch 78: train_loss=1.1519 val_acc=0.4464 best=0.5607\n",
            "Epoch 79: train_loss=1.2123 val_acc=0.4893 best=0.5607\n",
            "Epoch 80: train_loss=1.1503 val_acc=0.5000 best=0.5607\n",
            "Epoch 81: train_loss=0.9749 val_acc=0.4750 best=0.5607\n",
            "Epoch 82: train_loss=0.9547 val_acc=0.5179 best=0.5607\n",
            "Epoch 83: train_loss=0.9855 val_acc=0.4500 best=0.5607\n",
            "Epoch 84: train_loss=0.8352 val_acc=0.4714 best=0.5607\n",
            "Epoch 85: train_loss=0.9252 val_acc=0.5179 best=0.5607\n",
            "Epoch 86: train_loss=0.9987 val_acc=0.5000 best=0.5607\n",
            "Epoch 87: train_loss=0.9163 val_acc=0.5000 best=0.5607\n",
            "Epoch 88: train_loss=0.8828 val_acc=0.5036 best=0.5607\n",
            "Epoch 89: train_loss=0.9746 val_acc=0.5107 best=0.5607\n",
            "Epoch 90: train_loss=0.8841 val_acc=0.4857 best=0.5607\n",
            "Epoch 91: train_loss=0.9981 val_acc=0.4964 best=0.5607\n",
            "Epoch 92: train_loss=0.8182 val_acc=0.4714 best=0.5607\n",
            "Epoch 93: train_loss=0.8274 val_acc=0.5071 best=0.5607\n",
            "Epoch 94: train_loss=1.0443 val_acc=0.5286 best=0.5607\n",
            "Epoch 95: train_loss=0.9954 val_acc=0.5321 best=0.5607\n",
            "Epoch 96: train_loss=0.7961 val_acc=0.4929 best=0.5607\n",
            "Epoch 97: train_loss=0.8875 val_acc=0.4714 best=0.5607\n",
            "Epoch 98: train_loss=1.0685 val_acc=0.4786 best=0.5607\n",
            "Epoch 99: train_loss=0.9913 val_acc=0.4857 best=0.5607\n",
            "Epoch 100: train_loss=0.7422 val_acc=0.5000 best=0.5607\n",
            "Epoch 101: train_loss=0.8959 val_acc=0.4964 best=0.5607\n",
            "Epoch 102: train_loss=0.9745 val_acc=0.4786 best=0.5607\n",
            "Epoch 103: train_loss=0.7003 val_acc=0.5214 best=0.5607\n",
            "Epoch 104: train_loss=0.9765 val_acc=0.4964 best=0.5607\n",
            "Epoch 105: train_loss=0.7956 val_acc=0.4643 best=0.5607\n",
            "Epoch 106: train_loss=1.0582 val_acc=0.5036 best=0.5607\n",
            "Epoch 107: train_loss=0.7911 val_acc=0.5179 best=0.5607\n",
            "Epoch 108: train_loss=0.9646 val_acc=0.5214 best=0.5607\n",
            "Epoch 109: train_loss=0.8477 val_acc=0.4821 best=0.5607\n",
            "Epoch 110: train_loss=0.9043 val_acc=0.5143 best=0.5607\n",
            "Epoch 111: train_loss=0.6509 val_acc=0.5036 best=0.5607\n",
            "Epoch 112: train_loss=1.0085 val_acc=0.5214 best=0.5607\n",
            "Epoch 113: train_loss=0.6708 val_acc=0.4893 best=0.5607\n",
            "Epoch 114: train_loss=0.6753 val_acc=0.4679 best=0.5607\n",
            "Epoch 115: train_loss=1.1659 val_acc=0.4964 best=0.5607\n",
            "Epoch 116: train_loss=0.8427 val_acc=0.5286 best=0.5607\n",
            "Epoch 117: train_loss=1.0407 val_acc=0.5000 best=0.5607\n",
            "Epoch 118: train_loss=0.6854 val_acc=0.4964 best=0.5607\n",
            "Epoch 119: train_loss=0.9113 val_acc=0.5036 best=0.5607\n",
            "Epoch 120: train_loss=0.8267 val_acc=0.5357 best=0.5607\n",
            "Epoch 121: train_loss=1.0169 val_acc=0.5143 best=0.5607\n",
            "Epoch 122: train_loss=0.8533 val_acc=0.4929 best=0.5607\n",
            "Epoch 123: train_loss=0.8162 val_acc=0.5357 best=0.5607\n",
            "Epoch 124: train_loss=0.6809 val_acc=0.5107 best=0.5607\n",
            "Epoch 125: train_loss=0.7531 val_acc=0.4929 best=0.5607\n",
            "Epoch 126: train_loss=0.6852 val_acc=0.4929 best=0.5607\n",
            "Epoch 127: train_loss=0.8569 val_acc=0.4893 best=0.5607\n",
            "Epoch 128: train_loss=0.9085 val_acc=0.4964 best=0.5607\n",
            "Epoch 129: train_loss=0.8498 val_acc=0.5000 best=0.5607\n",
            "Epoch 130: train_loss=0.9455 val_acc=0.5000 best=0.5607\n",
            "Epoch 131: train_loss=0.7890 val_acc=0.5393 best=0.5607\n",
            "Epoch 132: train_loss=0.6908 val_acc=0.5071 best=0.5607\n",
            "Epoch 133: train_loss=0.7731 val_acc=0.5214 best=0.5607\n",
            "Epoch 134: train_loss=0.6445 val_acc=0.5143 best=0.5607\n",
            "Epoch 135: train_loss=0.7655 val_acc=0.5143 best=0.5607\n",
            "Epoch 136: train_loss=0.9541 val_acc=0.5179 best=0.5607\n",
            "Epoch 137: train_loss=0.7492 val_acc=0.4929 best=0.5607\n",
            "Epoch 138: train_loss=1.0686 val_acc=0.5429 best=0.5607\n",
            "Epoch 139: train_loss=0.8421 val_acc=0.5179 best=0.5607\n",
            "Epoch 140: train_loss=0.9094 val_acc=0.5036 best=0.5607\n",
            "Epoch 141: train_loss=0.9308 val_acc=0.4893 best=0.5607\n",
            "Epoch 142: train_loss=0.8786 val_acc=0.5429 best=0.5607\n",
            "Epoch 143: train_loss=0.6647 val_acc=0.5036 best=0.5607\n",
            "Epoch 144: train_loss=0.9990 val_acc=0.4857 best=0.5607\n",
            "Epoch 145: train_loss=0.7864 val_acc=0.5214 best=0.5607\n",
            "Epoch 146: train_loss=1.1428 val_acc=0.4964 best=0.5607\n",
            "Epoch 147: train_loss=0.7327 val_acc=0.5071 best=0.5607\n",
            "Epoch 148: train_loss=0.7456 val_acc=0.4821 best=0.5607\n",
            "Epoch 149: train_loss=0.8038 val_acc=0.5321 best=0.5607\n",
            "Epoch 150: train_loss=0.9767 val_acc=0.4964 best=0.5607\n",
            "Epoch 151: train_loss=0.7939 val_acc=0.5286 best=0.5607\n",
            "Epoch 152: train_loss=0.8748 val_acc=0.5107 best=0.5607\n",
            "Epoch 153: train_loss=0.9224 val_acc=0.5393 best=0.5607\n",
            "Epoch 154: train_loss=0.6916 val_acc=0.5357 best=0.5607\n",
            "Epoch 155: train_loss=0.7343 val_acc=0.5500 best=0.5607\n",
            "Epoch 156: train_loss=0.7225 val_acc=0.5286 best=0.5607\n",
            "Epoch 157: train_loss=0.9171 val_acc=0.5250 best=0.5607\n",
            "Epoch 158: train_loss=0.6463 val_acc=0.4929 best=0.5607\n",
            "Epoch 159: train_loss=0.9372 val_acc=0.5286 best=0.5607\n",
            "Epoch 160: train_loss=0.8537 val_acc=0.5214 best=0.5607\n",
            "Epoch 161: train_loss=0.8640 val_acc=0.4857 best=0.5607\n",
            "Epoch 162: train_loss=0.8379 val_acc=0.5179 best=0.5607\n",
            "Epoch 163: train_loss=0.6812 val_acc=0.5036 best=0.5607\n",
            "Epoch 164: train_loss=1.0215 val_acc=0.5000 best=0.5607\n",
            "Epoch 165: train_loss=0.7793 val_acc=0.4929 best=0.5607\n",
            "Epoch 166: train_loss=0.8373 val_acc=0.5000 best=0.5607\n",
            "Epoch 167: train_loss=0.9518 val_acc=0.4929 best=0.5607\n",
            "Epoch 168: train_loss=0.8088 val_acc=0.5036 best=0.5607\n",
            "Epoch 169: train_loss=0.6048 val_acc=0.5143 best=0.5607\n",
            "Epoch 170: train_loss=0.8025 val_acc=0.4964 best=0.5607\n",
            "Epoch 171: train_loss=0.7217 val_acc=0.5071 best=0.5607\n",
            "Epoch 172: train_loss=0.8790 val_acc=0.4893 best=0.5607\n",
            "Epoch 173: train_loss=0.8252 val_acc=0.5036 best=0.5607\n",
            "Epoch 174: train_loss=0.6348 val_acc=0.5286 best=0.5607\n",
            "Epoch 175: train_loss=0.6650 val_acc=0.5393 best=0.5607\n",
            "Epoch 176: train_loss=0.5965 val_acc=0.5250 best=0.5607\n",
            "Epoch 177: train_loss=0.6670 val_acc=0.5250 best=0.5607\n",
            "Epoch 178: train_loss=0.8088 val_acc=0.5214 best=0.5607\n",
            "Epoch 179: train_loss=0.7163 val_acc=0.5214 best=0.5607\n",
            "Epoch 180: train_loss=0.7042 val_acc=0.5071 best=0.5607\n",
            "Epoch 181: train_loss=0.7616 val_acc=0.5143 best=0.5607\n",
            "Epoch 182: train_loss=0.8136 val_acc=0.5036 best=0.5607\n",
            "Epoch 183: train_loss=0.8899 val_acc=0.5214 best=0.5607\n",
            "Epoch 184: train_loss=0.6480 val_acc=0.5143 best=0.5607\n",
            "Epoch 185: train_loss=0.9968 val_acc=0.5107 best=0.5607\n",
            "Epoch 186: train_loss=0.6517 val_acc=0.5107 best=0.5607\n",
            "Epoch 187: train_loss=0.8436 val_acc=0.5000 best=0.5607\n",
            "Epoch 188: train_loss=0.7659 val_acc=0.5107 best=0.5607\n",
            "Epoch 189: train_loss=0.6865 val_acc=0.5214 best=0.5607\n",
            "Epoch 190: train_loss=0.8541 val_acc=0.5071 best=0.5607\n",
            "Epoch 191: train_loss=0.7260 val_acc=0.5107 best=0.5607\n",
            "Epoch 192: train_loss=0.8028 val_acc=0.5250 best=0.5607\n",
            "Epoch 193: train_loss=0.6864 val_acc=0.5179 best=0.5607\n",
            "Epoch 194: train_loss=0.7502 val_acc=0.5179 best=0.5607\n",
            "Epoch 195: train_loss=0.6539 val_acc=0.5250 best=0.5607\n",
            "Epoch 196: train_loss=0.6932 val_acc=0.5250 best=0.5607\n",
            "Epoch 197: train_loss=0.6623 val_acc=0.5250 best=0.5607\n",
            "Epoch 198: train_loss=0.8696 val_acc=0.5143 best=0.5607\n",
            "Epoch 199: train_loss=0.7076 val_acc=0.5250 best=0.5607\n",
            "Epoch 200: train_loss=0.7027 val_acc=0.5250 best=0.5607\n",
            "Epoch 201: train_loss=0.8039 val_acc=0.5143 best=0.5607\n",
            "Epoch 202: train_loss=0.8695 val_acc=0.5214 best=0.5607\n",
            "Epoch 203: train_loss=0.5845 val_acc=0.5250 best=0.5607\n",
            "Epoch 204: train_loss=0.5835 val_acc=0.5357 best=0.5607\n",
            "Epoch 205: train_loss=0.8324 val_acc=0.5357 best=0.5607\n",
            "Epoch 206: train_loss=0.8416 val_acc=0.5464 best=0.5607\n",
            "Epoch 207: train_loss=0.7834 val_acc=0.5321 best=0.5607\n",
            "Epoch 208: train_loss=0.8167 val_acc=0.5357 best=0.5607\n",
            "Epoch 209: train_loss=0.6520 val_acc=0.5286 best=0.5607\n",
            "Epoch 210: train_loss=0.6017 val_acc=0.5321 best=0.5607\n",
            "Epoch 211: train_loss=0.8662 val_acc=0.5286 best=0.5607\n",
            "Epoch 212: train_loss=0.7771 val_acc=0.5214 best=0.5607\n",
            "Epoch 213: train_loss=0.8856 val_acc=0.5179 best=0.5607\n",
            "Epoch 214: train_loss=0.5324 val_acc=0.5179 best=0.5607\n",
            "Epoch 215: train_loss=1.0396 val_acc=0.5250 best=0.5607\n",
            "Epoch 216: train_loss=0.7031 val_acc=0.5250 best=0.5607\n",
            "Epoch 217: train_loss=0.5099 val_acc=0.5250 best=0.5607\n",
            "Epoch 218: train_loss=0.6189 val_acc=0.5321 best=0.5607\n",
            "Epoch 219: train_loss=0.7190 val_acc=0.5321 best=0.5607\n",
            "Epoch 220: train_loss=0.6310 val_acc=0.5286 best=0.5607\n",
            "Epoch 221: train_loss=0.5592 val_acc=0.5321 best=0.5607\n",
            "Epoch 222: train_loss=0.7070 val_acc=0.5286 best=0.5607\n",
            "Epoch 223: train_loss=0.8629 val_acc=0.5321 best=0.5607\n",
            "Epoch 224: train_loss=0.7021 val_acc=0.5214 best=0.5607\n",
            "Epoch 225: train_loss=0.7445 val_acc=0.5214 best=0.5607\n",
            "Epoch 226: train_loss=0.8748 val_acc=0.5179 best=0.5607\n",
            "Epoch 227: train_loss=0.6844 val_acc=0.5143 best=0.5607\n",
            "Epoch 228: train_loss=0.5258 val_acc=0.5036 best=0.5607\n",
            "Epoch 229: train_loss=0.7122 val_acc=0.5036 best=0.5607\n",
            "Epoch 230: train_loss=0.8375 val_acc=0.5036 best=0.5607\n",
            "Epoch 231: train_loss=0.8911 val_acc=0.5071 best=0.5607\n",
            "Epoch 232: train_loss=0.7532 val_acc=0.5107 best=0.5607\n",
            "Epoch 233: train_loss=0.7627 val_acc=0.5107 best=0.5607\n",
            "Epoch 234: train_loss=0.9183 val_acc=0.5143 best=0.5607\n",
            "Epoch 235: train_loss=0.5649 val_acc=0.5143 best=0.5607\n",
            "Epoch 236: train_loss=0.7152 val_acc=0.5107 best=0.5607\n",
            "Epoch 237: train_loss=0.7156 val_acc=0.5143 best=0.5607\n",
            "Epoch 238: train_loss=1.0642 val_acc=0.5143 best=0.5607\n",
            "Epoch 239: train_loss=0.8108 val_acc=0.5143 best=0.5607\n",
            "Epoch 240: train_loss=0.6809 val_acc=0.5143 best=0.5607\n",
            "Epoch 241: train_loss=0.7612 val_acc=0.5143 best=0.5607\n",
            "Epoch 242: train_loss=0.5460 val_acc=0.5143 best=0.5607\n",
            "Epoch 243: train_loss=0.6788 val_acc=0.5179 best=0.5607\n",
            "Epoch 244: train_loss=0.8258 val_acc=0.5179 best=0.5607\n",
            "Epoch 245: train_loss=0.8341 val_acc=0.5179 best=0.5607\n",
            "Epoch 246: train_loss=0.7354 val_acc=0.5179 best=0.5607\n",
            "Epoch 247: train_loss=0.5807 val_acc=0.5179 best=0.5607\n",
            "Epoch 248: train_loss=0.7155 val_acc=0.5179 best=0.5607\n",
            "Epoch 249: train_loss=0.5924 val_acc=0.5179 best=0.5607\n",
            "Epoch 250: train_loss=0.5186 val_acc=0.5179 best=0.5607\n",
            "\n",
            "=== Fold 5/5 ===\n",
            "Epoch 1: train_loss=1.9275 val_acc=0.2679 best=0.0000\n",
            "Epoch 2: train_loss=1.8807 val_acc=0.2857 best=0.2679\n",
            "Epoch 3: train_loss=1.8083 val_acc=0.2893 best=0.2857\n",
            "Epoch 4: train_loss=1.7581 val_acc=0.2893 best=0.2893\n",
            "Epoch 5: train_loss=1.7588 val_acc=0.3000 best=0.2893\n",
            "Epoch 6: train_loss=1.7408 val_acc=0.3393 best=0.3000\n",
            "Epoch 7: train_loss=1.7316 val_acc=0.3464 best=0.3393\n",
            "Epoch 8: train_loss=1.6078 val_acc=0.3750 best=0.3464\n",
            "Epoch 9: train_loss=1.6398 val_acc=0.3893 best=0.3750\n",
            "Epoch 10: train_loss=1.5550 val_acc=0.4107 best=0.3893\n",
            "Epoch 11: train_loss=1.5478 val_acc=0.4500 best=0.4107\n",
            "Epoch 12: train_loss=1.5065 val_acc=0.4536 best=0.4500\n",
            "Epoch 13: train_loss=1.5536 val_acc=0.4500 best=0.4536\n",
            "Epoch 14: train_loss=1.5313 val_acc=0.4679 best=0.4536\n",
            "Epoch 15: train_loss=1.5046 val_acc=0.4964 best=0.4679\n",
            "Epoch 16: train_loss=1.4896 val_acc=0.5000 best=0.4964\n",
            "Epoch 17: train_loss=1.3889 val_acc=0.5107 best=0.5000\n",
            "Epoch 18: train_loss=1.4360 val_acc=0.5107 best=0.5107\n",
            "Epoch 19: train_loss=1.4231 val_acc=0.5179 best=0.5107\n",
            "Epoch 20: train_loss=1.4565 val_acc=0.5357 best=0.5179\n",
            "Epoch 21: train_loss=1.5000 val_acc=0.4929 best=0.5357\n",
            "Epoch 22: train_loss=1.4456 val_acc=0.5179 best=0.5357\n",
            "Epoch 23: train_loss=1.2717 val_acc=0.5571 best=0.5357\n",
            "Epoch 24: train_loss=1.4454 val_acc=0.5643 best=0.5571\n",
            "Epoch 25: train_loss=1.3225 val_acc=0.5679 best=0.5643\n",
            "Epoch 26: train_loss=1.4221 val_acc=0.5607 best=0.5679\n",
            "Epoch 27: train_loss=1.3946 val_acc=0.5786 best=0.5679\n",
            "Epoch 28: train_loss=1.2536 val_acc=0.5393 best=0.5786\n",
            "Epoch 29: train_loss=1.3759 val_acc=0.5357 best=0.5786\n",
            "Epoch 30: train_loss=1.2597 val_acc=0.5679 best=0.5786\n",
            "Epoch 31: train_loss=1.2464 val_acc=0.5643 best=0.5786\n",
            "Epoch 32: train_loss=1.2647 val_acc=0.5357 best=0.5786\n",
            "Epoch 33: train_loss=1.3889 val_acc=0.4893 best=0.5786\n",
            "Epoch 34: train_loss=1.2365 val_acc=0.5607 best=0.5786\n",
            "Epoch 35: train_loss=1.1594 val_acc=0.5607 best=0.5786\n",
            "Epoch 36: train_loss=1.1539 val_acc=0.5500 best=0.5786\n",
            "Epoch 37: train_loss=1.2371 val_acc=0.5500 best=0.5786\n",
            "Epoch 38: train_loss=1.2038 val_acc=0.5143 best=0.5786\n",
            "Epoch 39: train_loss=1.2182 val_acc=0.5179 best=0.5786\n",
            "Epoch 40: train_loss=1.1107 val_acc=0.5214 best=0.5786\n",
            "Epoch 41: train_loss=1.2343 val_acc=0.5286 best=0.5786\n",
            "Epoch 42: train_loss=1.2332 val_acc=0.5179 best=0.5786\n",
            "Epoch 43: train_loss=1.1039 val_acc=0.5536 best=0.5786\n",
            "Epoch 44: train_loss=1.2630 val_acc=0.5143 best=0.5786\n",
            "Epoch 45: train_loss=1.3468 val_acc=0.5643 best=0.5786\n",
            "Epoch 46: train_loss=1.0618 val_acc=0.5214 best=0.5786\n",
            "Epoch 47: train_loss=1.1181 val_acc=0.5321 best=0.5786\n",
            "Epoch 48: train_loss=1.0880 val_acc=0.5286 best=0.5786\n",
            "Epoch 49: train_loss=1.1459 val_acc=0.5143 best=0.5786\n",
            "Epoch 50: train_loss=1.1230 val_acc=0.5464 best=0.5786\n",
            "Epoch 51: train_loss=1.0662 val_acc=0.5607 best=0.5786\n",
            "Epoch 52: train_loss=1.2261 val_acc=0.5286 best=0.5786\n",
            "Epoch 53: train_loss=0.9252 val_acc=0.5357 best=0.5786\n",
            "Epoch 54: train_loss=1.1605 val_acc=0.5321 best=0.5786\n",
            "Epoch 55: train_loss=1.1045 val_acc=0.5179 best=0.5786\n",
            "Epoch 56: train_loss=1.3213 val_acc=0.5321 best=0.5786\n",
            "Epoch 57: train_loss=1.1201 val_acc=0.5250 best=0.5786\n",
            "Epoch 58: train_loss=1.0008 val_acc=0.5536 best=0.5786\n",
            "Epoch 59: train_loss=1.0589 val_acc=0.5286 best=0.5786\n",
            "Epoch 60: train_loss=0.9532 val_acc=0.5036 best=0.5786\n",
            "Epoch 61: train_loss=1.0843 val_acc=0.5607 best=0.5786\n",
            "Epoch 62: train_loss=1.0921 val_acc=0.5107 best=0.5786\n",
            "Epoch 63: train_loss=1.2590 val_acc=0.5393 best=0.5786\n",
            "Epoch 64: train_loss=1.3307 val_acc=0.5214 best=0.5786\n",
            "Epoch 65: train_loss=1.0218 val_acc=0.5464 best=0.5786\n",
            "Epoch 66: train_loss=1.1248 val_acc=0.5393 best=0.5786\n",
            "Epoch 67: train_loss=1.2106 val_acc=0.5429 best=0.5786\n",
            "Epoch 68: train_loss=0.9946 val_acc=0.4714 best=0.5786\n",
            "Epoch 69: train_loss=1.1003 val_acc=0.5214 best=0.5786\n",
            "Epoch 70: train_loss=0.9974 val_acc=0.5036 best=0.5786\n",
            "Epoch 71: train_loss=0.9963 val_acc=0.5179 best=0.5786\n",
            "Epoch 72: train_loss=1.2071 val_acc=0.5071 best=0.5786\n",
            "Epoch 73: train_loss=0.9283 val_acc=0.5500 best=0.5786\n",
            "Epoch 74: train_loss=1.1590 val_acc=0.5107 best=0.5786\n",
            "Epoch 75: train_loss=1.1678 val_acc=0.4929 best=0.5786\n",
            "Epoch 76: train_loss=0.9477 val_acc=0.4857 best=0.5786\n",
            "Epoch 77: train_loss=0.9625 val_acc=0.5393 best=0.5786\n",
            "Epoch 78: train_loss=0.9314 val_acc=0.5357 best=0.5786\n",
            "Epoch 79: train_loss=0.9820 val_acc=0.5500 best=0.5786\n",
            "Epoch 80: train_loss=1.1299 val_acc=0.5357 best=0.5786\n",
            "Epoch 81: train_loss=1.0588 val_acc=0.5500 best=0.5786\n",
            "Epoch 82: train_loss=1.0899 val_acc=0.5179 best=0.5786\n",
            "Epoch 83: train_loss=0.8733 val_acc=0.5036 best=0.5786\n",
            "Epoch 84: train_loss=0.9249 val_acc=0.5286 best=0.5786\n",
            "Epoch 85: train_loss=1.0154 val_acc=0.5250 best=0.5786\n",
            "Epoch 86: train_loss=0.7848 val_acc=0.5000 best=0.5786\n",
            "Epoch 87: train_loss=0.8963 val_acc=0.5179 best=0.5786\n",
            "Epoch 88: train_loss=1.0650 val_acc=0.5036 best=0.5786\n",
            "Epoch 89: train_loss=1.1005 val_acc=0.5429 best=0.5786\n",
            "Epoch 90: train_loss=1.0511 val_acc=0.5321 best=0.5786\n",
            "Epoch 91: train_loss=1.0868 val_acc=0.5143 best=0.5786\n",
            "Epoch 92: train_loss=0.9089 val_acc=0.5321 best=0.5786\n",
            "Epoch 93: train_loss=0.9929 val_acc=0.5214 best=0.5786\n",
            "Epoch 94: train_loss=0.9085 val_acc=0.5179 best=0.5786\n",
            "Epoch 95: train_loss=0.8381 val_acc=0.5286 best=0.5786\n",
            "Epoch 96: train_loss=0.7089 val_acc=0.5250 best=0.5786\n",
            "Epoch 97: train_loss=1.1031 val_acc=0.5214 best=0.5786\n",
            "Epoch 98: train_loss=0.8989 val_acc=0.5679 best=0.5786\n",
            "Epoch 99: train_loss=0.8596 val_acc=0.5571 best=0.5786\n",
            "Epoch 100: train_loss=1.0615 val_acc=0.5321 best=0.5786\n",
            "Epoch 101: train_loss=0.7618 val_acc=0.5071 best=0.5786\n",
            "Epoch 102: train_loss=0.9405 val_acc=0.5571 best=0.5786\n",
            "Epoch 103: train_loss=1.0874 val_acc=0.5000 best=0.5786\n",
            "Epoch 104: train_loss=0.7957 val_acc=0.5214 best=0.5786\n",
            "Epoch 105: train_loss=0.9599 val_acc=0.5643 best=0.5786\n",
            "Epoch 106: train_loss=1.1782 val_acc=0.5607 best=0.5786\n",
            "Epoch 107: train_loss=0.9602 val_acc=0.5393 best=0.5786\n",
            "Epoch 108: train_loss=0.9484 val_acc=0.5536 best=0.5786\n",
            "Epoch 109: train_loss=1.0169 val_acc=0.5321 best=0.5786\n",
            "Epoch 110: train_loss=0.8079 val_acc=0.5429 best=0.5786\n",
            "Epoch 111: train_loss=0.9975 val_acc=0.5464 best=0.5786\n",
            "Epoch 112: train_loss=0.9233 val_acc=0.5321 best=0.5786\n",
            "Epoch 113: train_loss=1.1439 val_acc=0.5321 best=0.5786\n",
            "Epoch 114: train_loss=0.8140 val_acc=0.5250 best=0.5786\n",
            "Epoch 115: train_loss=0.7783 val_acc=0.5536 best=0.5786\n",
            "Epoch 116: train_loss=0.7256 val_acc=0.5571 best=0.5786\n",
            "Epoch 117: train_loss=0.8654 val_acc=0.5536 best=0.5786\n",
            "Epoch 118: train_loss=0.9728 val_acc=0.5393 best=0.5786\n",
            "Epoch 119: train_loss=0.8511 val_acc=0.5571 best=0.5786\n",
            "Epoch 120: train_loss=0.8665 val_acc=0.5714 best=0.5786\n",
            "Epoch 121: train_loss=0.9901 val_acc=0.5464 best=0.5786\n",
            "Epoch 122: train_loss=0.7949 val_acc=0.5393 best=0.5786\n",
            "Epoch 123: train_loss=0.7722 val_acc=0.5643 best=0.5786\n",
            "Epoch 124: train_loss=0.7831 val_acc=0.6000 best=0.5786\n",
            "Epoch 125: train_loss=0.9112 val_acc=0.5321 best=0.6000\n",
            "Epoch 126: train_loss=1.1112 val_acc=0.4786 best=0.6000\n",
            "Epoch 127: train_loss=0.8730 val_acc=0.5179 best=0.6000\n",
            "Epoch 128: train_loss=0.8369 val_acc=0.5821 best=0.6000\n",
            "Epoch 129: train_loss=0.8910 val_acc=0.5500 best=0.6000\n",
            "Epoch 130: train_loss=0.8879 val_acc=0.5571 best=0.6000\n",
            "Epoch 131: train_loss=0.9229 val_acc=0.5321 best=0.6000\n",
            "Epoch 132: train_loss=0.7803 val_acc=0.5214 best=0.6000\n",
            "Epoch 133: train_loss=0.9776 val_acc=0.5250 best=0.6000\n",
            "Epoch 134: train_loss=0.9466 val_acc=0.5286 best=0.6000\n",
            "Epoch 135: train_loss=0.8267 val_acc=0.5250 best=0.6000\n",
            "Epoch 136: train_loss=0.8533 val_acc=0.5500 best=0.6000\n",
            "Epoch 137: train_loss=0.7767 val_acc=0.5571 best=0.6000\n",
            "Epoch 138: train_loss=0.6289 val_acc=0.5607 best=0.6000\n",
            "Epoch 139: train_loss=0.8478 val_acc=0.5357 best=0.6000\n",
            "Epoch 140: train_loss=0.5780 val_acc=0.5500 best=0.6000\n",
            "Epoch 141: train_loss=0.9251 val_acc=0.5393 best=0.6000\n",
            "Epoch 142: train_loss=0.7711 val_acc=0.5750 best=0.6000\n",
            "Epoch 143: train_loss=0.8219 val_acc=0.5429 best=0.6000\n",
            "Epoch 144: train_loss=0.6397 val_acc=0.5143 best=0.6000\n",
            "Epoch 145: train_loss=0.7547 val_acc=0.5357 best=0.6000\n",
            "Epoch 146: train_loss=0.7007 val_acc=0.5250 best=0.6000\n",
            "Epoch 147: train_loss=0.7413 val_acc=0.5536 best=0.6000\n",
            "Epoch 148: train_loss=0.8113 val_acc=0.5143 best=0.6000\n",
            "Epoch 149: train_loss=0.7477 val_acc=0.5643 best=0.6000\n",
            "Epoch 150: train_loss=0.7079 val_acc=0.5500 best=0.6000\n",
            "Epoch 151: train_loss=0.8146 val_acc=0.5429 best=0.6000\n",
            "Epoch 152: train_loss=0.6764 val_acc=0.5750 best=0.6000\n",
            "Epoch 153: train_loss=0.7492 val_acc=0.5750 best=0.6000\n",
            "Epoch 154: train_loss=0.9851 val_acc=0.5571 best=0.6000\n",
            "Epoch 155: train_loss=0.8070 val_acc=0.5393 best=0.6000\n",
            "Epoch 156: train_loss=0.8583 val_acc=0.5679 best=0.6000\n",
            "Epoch 157: train_loss=0.8955 val_acc=0.5179 best=0.6000\n",
            "Epoch 158: train_loss=0.8411 val_acc=0.5571 best=0.6000\n",
            "Epoch 159: train_loss=0.6951 val_acc=0.5536 best=0.6000\n",
            "Epoch 160: train_loss=0.7846 val_acc=0.5429 best=0.6000\n",
            "Epoch 161: train_loss=0.7318 val_acc=0.5500 best=0.6000\n",
            "Epoch 162: train_loss=0.8841 val_acc=0.5214 best=0.6000\n",
            "Epoch 163: train_loss=0.7368 val_acc=0.5393 best=0.6000\n",
            "Epoch 164: train_loss=0.8459 val_acc=0.5607 best=0.6000\n",
            "Epoch 165: train_loss=0.7023 val_acc=0.5429 best=0.6000\n",
            "Epoch 166: train_loss=0.7951 val_acc=0.5643 best=0.6000\n",
            "Epoch 167: train_loss=0.7892 val_acc=0.5429 best=0.6000\n",
            "Epoch 168: train_loss=0.6246 val_acc=0.5286 best=0.6000\n",
            "Epoch 169: train_loss=0.8274 val_acc=0.5214 best=0.6000\n",
            "Epoch 170: train_loss=0.7056 val_acc=0.5500 best=0.6000\n",
            "Epoch 171: train_loss=0.7785 val_acc=0.5607 best=0.6000\n",
            "Epoch 172: train_loss=0.8338 val_acc=0.5571 best=0.6000\n",
            "Epoch 173: train_loss=0.8107 val_acc=0.5250 best=0.6000\n",
            "Epoch 174: train_loss=0.5975 val_acc=0.5321 best=0.6000\n",
            "Epoch 175: train_loss=0.6903 val_acc=0.5500 best=0.6000\n",
            "Epoch 176: train_loss=0.7847 val_acc=0.5536 best=0.6000\n",
            "Epoch 177: train_loss=0.7570 val_acc=0.5393 best=0.6000\n",
            "Epoch 178: train_loss=0.7903 val_acc=0.5214 best=0.6000\n",
            "Epoch 179: train_loss=0.6976 val_acc=0.5571 best=0.6000\n",
            "Epoch 180: train_loss=0.8530 val_acc=0.5679 best=0.6000\n",
            "Epoch 181: train_loss=0.6139 val_acc=0.5500 best=0.6000\n",
            "Epoch 182: train_loss=0.8198 val_acc=0.5321 best=0.6000\n",
            "Epoch 183: train_loss=0.6977 val_acc=0.5536 best=0.6000\n",
            "Epoch 184: train_loss=0.7883 val_acc=0.5500 best=0.6000\n",
            "Epoch 185: train_loss=0.7932 val_acc=0.5536 best=0.6000\n",
            "Epoch 186: train_loss=0.6605 val_acc=0.5714 best=0.6000\n",
            "Epoch 187: train_loss=0.6174 val_acc=0.5821 best=0.6000\n",
            "Epoch 188: train_loss=0.9105 val_acc=0.5893 best=0.6000\n",
            "Epoch 189: train_loss=0.7123 val_acc=0.5821 best=0.6000\n",
            "Epoch 190: train_loss=0.8719 val_acc=0.5750 best=0.6000\n",
            "Epoch 191: train_loss=0.8382 val_acc=0.5679 best=0.6000\n",
            "Epoch 192: train_loss=0.9813 val_acc=0.5643 best=0.6000\n",
            "Epoch 193: train_loss=0.8368 val_acc=0.5500 best=0.6000\n",
            "Epoch 194: train_loss=0.7598 val_acc=0.5643 best=0.6000\n",
            "Epoch 195: train_loss=0.7059 val_acc=0.5607 best=0.6000\n",
            "Epoch 196: train_loss=0.6118 val_acc=0.5607 best=0.6000\n",
            "Epoch 197: train_loss=0.8321 val_acc=0.5607 best=0.6000\n",
            "Epoch 198: train_loss=0.8295 val_acc=0.5464 best=0.6000\n",
            "Epoch 199: train_loss=0.7332 val_acc=0.5607 best=0.6000\n",
            "Epoch 200: train_loss=0.7284 val_acc=0.5536 best=0.6000\n",
            "Epoch 201: train_loss=0.9183 val_acc=0.5607 best=0.6000\n",
            "Epoch 202: train_loss=0.9726 val_acc=0.5536 best=0.6000\n",
            "Epoch 203: train_loss=0.9963 val_acc=0.5393 best=0.6000\n",
            "Epoch 204: train_loss=0.6107 val_acc=0.5464 best=0.6000\n",
            "Epoch 205: train_loss=0.6317 val_acc=0.5571 best=0.6000\n",
            "Epoch 206: train_loss=0.5871 val_acc=0.5571 best=0.6000\n",
            "Epoch 207: train_loss=0.6918 val_acc=0.5607 best=0.6000\n",
            "Epoch 208: train_loss=0.9574 val_acc=0.5429 best=0.6000\n",
            "Epoch 209: train_loss=0.5520 val_acc=0.5393 best=0.6000\n",
            "Epoch 210: train_loss=0.8563 val_acc=0.5429 best=0.6000\n",
            "Epoch 211: train_loss=0.5516 val_acc=0.5500 best=0.6000\n",
            "Epoch 212: train_loss=0.7198 val_acc=0.5500 best=0.6000\n",
            "Epoch 213: train_loss=0.6830 val_acc=0.5357 best=0.6000\n",
            "Epoch 214: train_loss=0.5713 val_acc=0.5357 best=0.6000\n",
            "Epoch 215: train_loss=0.6824 val_acc=0.5464 best=0.6000\n",
            "Epoch 216: train_loss=0.7010 val_acc=0.5643 best=0.6000\n",
            "Epoch 217: train_loss=0.8495 val_acc=0.5536 best=0.6000\n",
            "Epoch 218: train_loss=0.7587 val_acc=0.5464 best=0.6000\n",
            "Epoch 219: train_loss=0.7002 val_acc=0.5536 best=0.6000\n",
            "Epoch 220: train_loss=0.8221 val_acc=0.5571 best=0.6000\n",
            "Epoch 221: train_loss=0.7942 val_acc=0.5607 best=0.6000\n",
            "Epoch 222: train_loss=0.6776 val_acc=0.5679 best=0.6000\n",
            "Epoch 223: train_loss=0.9175 val_acc=0.5679 best=0.6000\n",
            "Epoch 224: train_loss=0.6418 val_acc=0.5679 best=0.6000\n",
            "Epoch 225: train_loss=0.7963 val_acc=0.5643 best=0.6000\n",
            "Epoch 226: train_loss=0.6809 val_acc=0.5607 best=0.6000\n",
            "Epoch 227: train_loss=0.6633 val_acc=0.5643 best=0.6000\n",
            "Epoch 228: train_loss=0.4539 val_acc=0.5643 best=0.6000\n",
            "Epoch 229: train_loss=0.7905 val_acc=0.5643 best=0.6000\n",
            "Epoch 230: train_loss=0.6190 val_acc=0.5643 best=0.6000\n",
            "Epoch 231: train_loss=0.6765 val_acc=0.5607 best=0.6000\n",
            "Epoch 232: train_loss=0.7468 val_acc=0.5679 best=0.6000\n",
            "Epoch 233: train_loss=0.7782 val_acc=0.5643 best=0.6000\n",
            "Epoch 234: train_loss=0.4773 val_acc=0.5643 best=0.6000\n",
            "Epoch 235: train_loss=0.5849 val_acc=0.5643 best=0.6000\n",
            "Epoch 236: train_loss=0.8882 val_acc=0.5643 best=0.6000\n",
            "Epoch 237: train_loss=0.7218 val_acc=0.5643 best=0.6000\n",
            "Epoch 238: train_loss=0.6402 val_acc=0.5643 best=0.6000\n",
            "Epoch 239: train_loss=0.5404 val_acc=0.5643 best=0.6000\n",
            "Epoch 240: train_loss=0.9228 val_acc=0.5643 best=0.6000\n",
            "Epoch 241: train_loss=0.7849 val_acc=0.5607 best=0.6000\n",
            "Epoch 242: train_loss=0.5654 val_acc=0.5607 best=0.6000\n",
            "Epoch 243: train_loss=0.5586 val_acc=0.5607 best=0.6000\n",
            "Epoch 244: train_loss=0.5967 val_acc=0.5607 best=0.6000\n",
            "Epoch 245: train_loss=0.5943 val_acc=0.5607 best=0.6000\n",
            "Epoch 246: train_loss=0.6640 val_acc=0.5607 best=0.6000\n",
            "Epoch 247: train_loss=0.6254 val_acc=0.5607 best=0.6000\n",
            "Epoch 248: train_loss=0.6918 val_acc=0.5607 best=0.6000\n",
            "Epoch 249: train_loss=0.6953 val_acc=0.5607 best=0.6000\n",
            "Epoch 250: train_loss=0.6725 val_acc=0.5607 best=0.6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Applying Augmentation to the minority classes\n",
        "### Not a significant change after applying augmentation so removing the early stopping in order to increase the accuracy and changing the epochs to 200\n",
        "### Changing the Hyperparameters based upon the optuna hyperparameter tuning\n",
        "## {'lr': 0.006308297609579304, 'dropout': 0.40732238402293397, 'hidden_dim': 512, 'weight_decay': 2.217794034655606e-05, 'label_smoothing': 0.15558780521663396}\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.preprocessing import PowerTransformer, LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "# Config\n",
        "DATA_CSV = \"features dataset.csv\"\n",
        "RANDOM_SEED = 42\n",
        "N_SPLITS = 5\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 500\n",
        "PATIENCE = 25\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def seed_all(seed=RANDOM_SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if DEVICE.startswith(\"cuda\"):\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "seed_all()\n",
        "\n",
        "# ============ FEATURE ENGINEERING ============\n",
        "def add_derived_features(df):\n",
        "\n",
        "    # Symmetry features (asymmetric movements may indicate certain emotions)\n",
        "    df['arm_asymmetry'] = abs(df['RightArm_speed_max'] - df['LeftArm_speed_max'])\n",
        "    df['leg_asymmetry'] = abs(df['RightLeg_speed_max'] - df['LeftLeg_speed_max'])\n",
        "    df['shoulder_asymmetry'] = abs(df['RightShoulder_speed_max'] - df['LeftShoulder_speed_max'])\n",
        "\n",
        "    # Body region ratios\n",
        "    upper_speed = df['RightArm_speed_max'] + df['LeftArm_speed_max'] + df['Head_speed_max']\n",
        "    lower_speed = df['RightLeg_speed_max'] + df['LeftLeg_speed_max'] + 1e-6\n",
        "    df['upper_lower_ratio'] = upper_speed / lower_speed\n",
        "\n",
        "    # Movement coordination (std across limbs)\n",
        "    limb_cols = ['RightArm_speed_std', 'LeftArm_speed_std',\n",
        "                 'RightLeg_speed_std', 'LeftLeg_speed_std']\n",
        "    df['limb_coordination'] = df[limb_cols].std(axis=1)\n",
        "\n",
        "    # Core body movement\n",
        "    core_cols = ['Spine_speed_max', 'Spine1_speed_max', 'Spine2_speed_max']\n",
        "    df['core_movement_intensity'] = df[core_cols].mean(axis=1)\n",
        "\n",
        "    # Extremity movement variance\n",
        "    extremity_cols = ['RightHand_speed_max', 'LeftHand_speed_max',\n",
        "                      'RightFoot_speed_max', 'LeftFoot_speed_max']\n",
        "    df['extremity_variation'] = df[extremity_cols].std(axis=1)\n",
        "\n",
        "    # Upper body expressiveness\n",
        "    expressive_cols = ['Head_speed_max', 'Neck_speed_max',\n",
        "                       'RightArm_speed_max', 'LeftArm_speed_max']\n",
        "    df['upper_expressiveness'] = df[expressive_cols].mean(axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "df = pd.read_csv(DATA_CSV)\n",
        "print(\"Raw shape:\", df.shape)\n",
        "\n",
        "df = add_derived_features(df)\n",
        "\n",
        "\n",
        "drop_cols = [\"filename\", \"actor_ID\", \"num_frames\", \"duration\"]\n",
        "drop_cols = [c for c in drop_cols if c in df.columns]\n",
        "\n",
        "label_col = \"emotion\"\n",
        "metadata_cols = [\"gender\"] if \"gender\" in df.columns else []\n",
        "\n",
        "numeric_cols = [c for c in df.columns\n",
        "                if c not in drop_cols + [label_col] + metadata_cols\n",
        "                and pd.api.types.is_numeric_dtype(df[c])]\n",
        "\n",
        "print(f\"Using {len(numeric_cols)} features (including engineered)\")\n",
        "\n",
        "X_num = df[numeric_cols].fillna(0).values\n",
        "\n",
        "\n",
        "X_meta = None\n",
        "if \"gender\" in metadata_cols:\n",
        "    gmap = {\"Female\": 0, \"Male\": 1}\n",
        "    g = df[\"gender\"].map(gmap).fillna(-1).astype(np.float32).values.reshape(-1,1)\n",
        "    X_meta = g\n",
        "\n",
        "X = np.hstack([X_num, X_meta]) if X_meta is not None else X_num\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df[label_col].astype(str).values)\n",
        "class_names = le.classes_\n",
        "print(\"Classes:\", list(class_names))\n",
        "print(\"Distribution:\", dict(pd.Series(y).value_counts()))\n",
        "\n",
        "def augment_emotion_data(X, y, emotion_id, n_augment=100):\n",
        "\n",
        "    mask = y == emotion_id\n",
        "    X_emotion = X[mask]\n",
        "\n",
        "    augmented = []\n",
        "    for _ in range(n_augment):\n",
        "        idx1, idx2 = np.random.choice(len(X_emotion), 2, replace=False)\n",
        "\n",
        "        alpha = np.random.beta(2, 2)  # Center-weighted\n",
        "        new_sample = alpha * X_emotion[idx1] + (1-alpha) * X_emotion[idx2]\n",
        "\n",
        "        noise = np.random.normal(0, 0.01, new_sample.shape)\n",
        "        augmented.append(new_sample + noise)\n",
        "\n",
        "    return np.array(augmented)\n",
        "\n",
        "\n",
        "for emotion_id in range(len(class_names)):\n",
        "    if np.sum(y == emotion_id) < 180:\n",
        "        aug_X = augment_emotion_data(X, y, emotion_id, n_augment=50)\n",
        "        aug_y = np.full(50, emotion_id)\n",
        "        X_tr = np.vstack([X, aug_X])\n",
        "        y_tr = np.concatenate([y, aug_y])\n",
        "\n",
        "X = X_tr\n",
        "y = y_tr\n",
        "class_names = le.classes_\n",
        "print(\"Classes After Augmentation:\", list(class_names))\n",
        "print(\"Distribution after Augmentation:\", dict(pd.Series(y).value_counts()))\n",
        "\n",
        "\n",
        "class TabularDataset(Dataset):\n",
        "    def __init__(self, X, y, augment=False):\n",
        "        self.X = X.astype(np.float32)\n",
        "        self.y = y.astype(np.int64)\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]\n",
        "        if self.augment:\n",
        "            noise = np.random.normal(0, 0.02, x.shape).astype(np.float32)\n",
        "            x = x + noise\n",
        "        return x, self.y[idx]\n",
        "\n",
        "\n",
        "class ImprovedMLP(nn.Module):\n",
        "    def __init__(self, in_dim, n_classes, dropout=0.3):\n",
        "      super().__init__()\n",
        "      self.net = nn.Sequential(\n",
        "          nn.Linear(in_dim, 512),\n",
        "          nn.BatchNorm1d(512),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout),\n",
        "\n",
        "          nn.Linear(512, 256),\n",
        "          nn.BatchNorm1d(256),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout),\n",
        "\n",
        "          nn.Linear(256, 128),\n",
        "          nn.BatchNorm1d(128),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout),\n",
        "\n",
        "          nn.Linear(128, 64),\n",
        "          nn.BatchNorm1d(64),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(dropout),\n",
        "\n",
        "          nn.Linear(64, n_classes)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    if alpha <= 0:\n",
        "        return x, y, None, None, 1.0\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size, device=x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, index, lam\n",
        "\n",
        "def mixup_criterion(criterion, preds, y_a, y_b, lam):\n",
        "    return lam * criterion(preds, y_a) + (1 - lam) * criterion(preds, y_b)\n",
        "\n",
        "def eval_model(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_trues, all_probs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_trues.append(yb.cpu().numpy())\n",
        "            all_probs.append(probs.cpu().numpy())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_trues = np.concatenate(all_trues)\n",
        "    all_probs = np.concatenate(all_probs)\n",
        "    acc = accuracy_score(all_trues, all_preds)\n",
        "    return acc, all_preds, all_trues, all_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp5I28ixkGDY",
        "outputId": "d78de93f-fefe-4b74-e572-8fc0dd97c83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw shape: (1401, 305)\n",
            "Using 307 features (including engineered)\n",
            "Classes: ['Angry', 'Disgust', 'Fearful', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
            "Distribution: {2: np.int64(216), 3: np.int64(216), 6: np.int64(212), 1: np.int64(210), 5: np.int64(202), 0: np.int64(200), 4: np.int64(145)}\n",
            "Classes After Augmentation: ['Angry', 'Disgust', 'Fearful', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
            "Distribution after Augmentation: {2: np.int64(216), 3: np.int64(216), 6: np.int64(212), 1: np.int64(210), 5: np.int64(202), 0: np.int64(200), 4: np.int64(195)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
        "fold_results = []\n",
        "all_fold_preds = []\n",
        "all_fold_trues = []\n",
        "\n",
        "for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"FOLD {fold+1}/{N_SPLITS}\")\n",
        "    print('='*50)\n",
        "\n",
        "    X_tr, X_val = X[tr_idx], X[val_idx]\n",
        "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
        "\n",
        "\n",
        "    mi_scores = mutual_info_classif(X_tr, y_tr, random_state=RANDOM_SEED)\n",
        "    n_select = min(150, len(mi_scores))\n",
        "    top_features = np.argsort(mi_scores)[-n_select:]\n",
        "\n",
        "    X_tr = X_tr[:, top_features]\n",
        "    X_val = X_val[:, top_features]\n",
        "\n",
        "\n",
        "    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "    X_tr = pt.fit_transform(X_tr)\n",
        "    X_val = pt.transform(X_val)\n",
        "\n",
        "\n",
        "    train_ds = TabularDataset(X_tr, y_tr, augment=True)\n",
        "    val_ds = TabularDataset(X_val, y_val, augment=False)\n",
        "\n",
        "\n",
        "    vals, counts = np.unique(y_tr, return_counts=True)\n",
        "    inv_freq = 1.0 / (counts + 1e-12)\n",
        "    weight_vec = np.zeros(len(class_names), dtype=np.float32)\n",
        "    for cls_i, inv in zip(vals, inv_freq):\n",
        "        weight_vec[cls_i] = inv\n",
        "\n",
        "    sample_weights = np.array([weight_vec[yv] for yv in y_tr], dtype=np.float32)\n",
        "    sample_weights = sample_weights / sample_weights.sum()\n",
        "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights),\n",
        "                                  replacement=True)\n",
        "\n",
        "    tr_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0)\n",
        "    val_loader = DataLoader(val_ds, batch_size=256, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "    model = ImprovedMLP(in_dim=X_tr.shape[1], n_classes=len(class_names), dropout=0.40732238402293397).to(DEVICE)\n",
        "\n",
        "\n",
        "    weight_tensor = torch.tensor(weight_vec, dtype=torch.float32).to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss(weight=weight_tensor, label_smoothing=0.15558780521663396)\n",
        "\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.006308297609579304, weight_decay=2.217794034655606e-05)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2)\n",
        "\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "\n",
        "    EPOCHS = 200\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for xb, yb in tr_loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "\n",
        "            # Mixup augmentation\n",
        "            xb_m, ya, yb_mix, _, lam = mixup_data(xb, yb, alpha=0.2)\n",
        "            preds = model(xb_m)\n",
        "\n",
        "            if lam is None:\n",
        "                loss = criterion(preds, yb)\n",
        "            else:\n",
        "                loss = mixup_criterion(criterion, preds, ya, yb_mix, lam)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        avg_loss = total_loss / len(tr_loader.dataset)\n",
        "        val_acc, val_preds, val_trues, _ = eval_model(model, val_loader, DEVICE)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{EPOCHS}: loss={avg_loss:.4f} val_acc={val_acc:.4f} best={best_val_acc:.4f}\")\n",
        "\n",
        "\n",
        "        if val_acc > best_val_acc + 1e-9:\n",
        "            best_val_acc = val_acc\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), f\"best_mlp_fold{fold}.pth\")\n",
        "\n",
        "\n",
        "    model.load_state_dict(torch.load(f\"best_mlp_fold{fold}.pth\", map_location=DEVICE))\n",
        "    val_acc, val_preds, val_trues, val_probs = eval_model(model, val_loader, DEVICE)\n",
        "\n",
        "    print(f\"\\nFold {fold+1} Best Validation Accuracy: {val_acc:.4f}\")\n",
        "    fold_results.append(val_acc)\n",
        "    all_fold_preds.append(val_preds)\n",
        "    all_fold_trues.append(val_trues)\n",
        "\n",
        "mean_acc = np.mean(fold_results)\n",
        "std_acc = np.std(fold_results)\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"CROSS-VALIDATION RESULTS\")\n",
        "print('='*50)\n",
        "print(f\"Mean Accuracy: {mean_acc:.4f}  {std_acc:.4f}\")\n",
        "print(f\"Fold Accuracies: {[f'{acc:.4f}' for acc in fold_results]}\")\n",
        "\n",
        "\n",
        "all_preds = np.concatenate(all_fold_preds)\n",
        "all_trues = np.concatenate(all_fold_trues)\n",
        "cm = confusion_matrix(all_trues, all_preds)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.title(f\"Confusion Matrix - Overall Accuracy: {mean_acc:.4f}\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_trues, all_preds, target_names=class_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "122w_Gqlm1pe",
        "outputId": "7965cb59-488e-4eba-f2a7-6d7ccff53f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "Epoch 1/200: loss=1.8864 val_acc=0.2852 best=0.0000\n",
            "Epoch 11/200: loss=1.6362 val_acc=0.4674 best=0.4777\n",
            "Epoch 21/200: loss=1.6093 val_acc=0.4227 best=0.5120\n",
            "Epoch 31/200: loss=1.6500 val_acc=0.5086 best=0.5120\n",
            "Epoch 41/200: loss=1.4880 val_acc=0.5430 best=0.5189\n",
            "Epoch 51/200: loss=1.5393 val_acc=0.5361 best=0.5533\n",
            "Epoch 61/200: loss=1.4970 val_acc=0.5258 best=0.5533\n",
            "Epoch 71/200: loss=1.6232 val_acc=0.4983 best=0.5533\n",
            "Epoch 81/200: loss=1.4473 val_acc=0.5464 best=0.5601\n",
            "Epoch 91/200: loss=1.5689 val_acc=0.5017 best=0.5601\n",
            "Epoch 101/200: loss=1.3412 val_acc=0.5292 best=0.5601\n",
            "Epoch 111/200: loss=1.4411 val_acc=0.5086 best=0.5601\n",
            "Epoch 121/200: loss=1.4278 val_acc=0.5567 best=0.5636\n",
            "Epoch 131/200: loss=1.3667 val_acc=0.5498 best=0.5636\n",
            "Epoch 141/200: loss=1.3314 val_acc=0.5189 best=0.5636\n",
            "Epoch 151/200: loss=1.3823 val_acc=0.5326 best=0.5636\n",
            "Epoch 161/200: loss=1.4474 val_acc=0.5326 best=0.5636\n",
            "Epoch 171/200: loss=1.5420 val_acc=0.4880 best=0.5739\n",
            "Epoch 181/200: loss=1.4106 val_acc=0.5670 best=0.5739\n",
            "Epoch 191/200: loss=1.4149 val_acc=0.5533 best=0.5739\n",
            "\n",
            "Fold 1 Best Validation Accuracy: 0.5773\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "Epoch 1/200: loss=1.8619 val_acc=0.3414 best=0.0000\n",
            "Epoch 11/200: loss=1.6077 val_acc=0.4379 best=0.4690\n",
            "Epoch 21/200: loss=1.5554 val_acc=0.4828 best=0.4793\n",
            "Epoch 31/200: loss=1.6233 val_acc=0.4724 best=0.5138\n",
            "Epoch 41/200: loss=1.5647 val_acc=0.5276 best=0.5586\n",
            "Epoch 51/200: loss=1.5742 val_acc=0.5241 best=0.5586\n",
            "Epoch 61/200: loss=1.5666 val_acc=0.5276 best=0.5655\n",
            "Epoch 71/200: loss=1.5530 val_acc=0.5345 best=0.5655\n",
            "Epoch 81/200: loss=1.4966 val_acc=0.5448 best=0.5655\n",
            "Epoch 91/200: loss=1.4433 val_acc=0.5414 best=0.5655\n",
            "Epoch 101/200: loss=1.4408 val_acc=0.5690 best=0.5793\n",
            "Epoch 111/200: loss=1.3290 val_acc=0.5828 best=0.5793\n",
            "Epoch 121/200: loss=1.3459 val_acc=0.5931 best=0.5828\n",
            "Epoch 131/200: loss=1.4088 val_acc=0.5828 best=0.5931\n",
            "Epoch 141/200: loss=1.4536 val_acc=0.5655 best=0.5931\n",
            "Epoch 151/200: loss=1.4442 val_acc=0.5586 best=0.5931\n",
            "Epoch 161/200: loss=1.3749 val_acc=0.5621 best=0.5931\n",
            "Epoch 171/200: loss=1.4434 val_acc=0.5793 best=0.5931\n",
            "Epoch 181/200: loss=1.3578 val_acc=0.6034 best=0.6000\n",
            "Epoch 191/200: loss=1.2834 val_acc=0.5966 best=0.6069\n",
            "\n",
            "Fold 2 Best Validation Accuracy: 0.6103\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "Epoch 1/200: loss=1.9127 val_acc=0.3207 best=0.0000\n",
            "Epoch 11/200: loss=1.6466 val_acc=0.5207 best=0.5000\n",
            "Epoch 21/200: loss=1.6089 val_acc=0.4931 best=0.5207\n",
            "Epoch 31/200: loss=1.5902 val_acc=0.5552 best=0.5276\n",
            "Epoch 41/200: loss=1.5870 val_acc=0.5621 best=0.5552\n",
            "Epoch 51/200: loss=1.6582 val_acc=0.5690 best=0.5621\n",
            "Epoch 61/200: loss=1.5699 val_acc=0.5655 best=0.5862\n",
            "Epoch 71/200: loss=1.5116 val_acc=0.5310 best=0.5862\n",
            "Epoch 81/200: loss=1.5255 val_acc=0.5724 best=0.5966\n",
            "Epoch 91/200: loss=1.4875 val_acc=0.5448 best=0.5966\n",
            "Epoch 101/200: loss=1.4651 val_acc=0.5759 best=0.5966\n",
            "Epoch 111/200: loss=1.3631 val_acc=0.5690 best=0.6000\n",
            "Epoch 121/200: loss=1.4236 val_acc=0.5862 best=0.6000\n",
            "Epoch 131/200: loss=1.4077 val_acc=0.5966 best=0.6103\n",
            "Epoch 141/200: loss=1.4665 val_acc=0.5655 best=0.6103\n",
            "Epoch 151/200: loss=1.3698 val_acc=0.5414 best=0.6103\n",
            "Epoch 161/200: loss=1.4834 val_acc=0.5586 best=0.6103\n",
            "Epoch 171/200: loss=1.3915 val_acc=0.5862 best=0.6103\n",
            "Epoch 181/200: loss=1.4826 val_acc=0.5621 best=0.6103\n",
            "Epoch 191/200: loss=1.3954 val_acc=0.5690 best=0.6103\n",
            "\n",
            "Fold 3 Best Validation Accuracy: 0.6103\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "Epoch 1/200: loss=1.8793 val_acc=0.2931 best=0.0000\n",
            "Epoch 11/200: loss=1.6543 val_acc=0.5069 best=0.4828\n",
            "Epoch 21/200: loss=1.5908 val_acc=0.5241 best=0.5310\n",
            "Epoch 31/200: loss=1.6415 val_acc=0.5276 best=0.5310\n",
            "Epoch 41/200: loss=1.4207 val_acc=0.5586 best=0.5655\n",
            "Epoch 51/200: loss=1.4383 val_acc=0.5759 best=0.5724\n",
            "Epoch 61/200: loss=1.5200 val_acc=0.5690 best=0.5759\n",
            "Epoch 71/200: loss=1.5189 val_acc=0.5310 best=0.5759\n",
            "Epoch 81/200: loss=1.5751 val_acc=0.5552 best=0.5759\n",
            "Epoch 91/200: loss=1.4301 val_acc=0.5207 best=0.5759\n",
            "Epoch 101/200: loss=1.4582 val_acc=0.5621 best=0.5759\n",
            "Epoch 111/200: loss=1.4209 val_acc=0.5448 best=0.5759\n",
            "Epoch 121/200: loss=1.4307 val_acc=0.5379 best=0.6000\n",
            "Epoch 131/200: loss=1.4056 val_acc=0.5483 best=0.6000\n",
            "Epoch 141/200: loss=1.4514 val_acc=0.5759 best=0.6000\n",
            "Epoch 151/200: loss=1.3958 val_acc=0.5724 best=0.6000\n",
            "Epoch 161/200: loss=1.4493 val_acc=0.5207 best=0.6000\n",
            "Epoch 171/200: loss=1.4191 val_acc=0.5000 best=0.6000\n",
            "Epoch 181/200: loss=1.3477 val_acc=0.5448 best=0.6000\n",
            "Epoch 191/200: loss=1.3196 val_acc=0.5310 best=0.6000\n",
            "\n",
            "Fold 4 Best Validation Accuracy: 0.6000\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n",
            "Epoch 1/200: loss=1.9166 val_acc=0.2828 best=0.0000\n",
            "Epoch 11/200: loss=1.5418 val_acc=0.4310 best=0.4759\n",
            "Epoch 21/200: loss=1.6498 val_acc=0.4931 best=0.5000\n",
            "Epoch 31/200: loss=1.6468 val_acc=0.5103 best=0.5241\n",
            "Epoch 41/200: loss=1.5229 val_acc=0.5241 best=0.5310\n",
            "Epoch 51/200: loss=1.5476 val_acc=0.5414 best=0.5517\n",
            "Epoch 61/200: loss=1.5038 val_acc=0.5103 best=0.5517\n",
            "Epoch 71/200: loss=1.5404 val_acc=0.5379 best=0.5517\n",
            "Epoch 81/200: loss=1.4742 val_acc=0.4897 best=0.5517\n",
            "Epoch 91/200: loss=1.4631 val_acc=0.5621 best=0.5586\n",
            "Epoch 101/200: loss=1.5430 val_acc=0.5621 best=0.5621\n",
            "Epoch 111/200: loss=1.4521 val_acc=0.5828 best=0.5655\n",
            "Epoch 121/200: loss=1.4692 val_acc=0.5448 best=0.5828\n",
            "Epoch 131/200: loss=1.3614 val_acc=0.5724 best=0.5828\n",
            "Epoch 141/200: loss=1.4155 val_acc=0.5345 best=0.5828\n",
            "Epoch 151/200: loss=1.5203 val_acc=0.5552 best=0.5897\n",
            "Epoch 161/200: loss=1.4250 val_acc=0.5517 best=0.5897\n",
            "Epoch 171/200: loss=1.4241 val_acc=0.5517 best=0.5931\n",
            "Epoch 181/200: loss=1.3767 val_acc=0.5552 best=0.6000\n",
            "Epoch 191/200: loss=1.4038 val_acc=0.5414 best=0.6000\n",
            "\n",
            "Fold 5 Best Validation Accuracy: 0.6000\n",
            "\n",
            "==================================================\n",
            "CROSS-VALIDATION RESULTS\n",
            "==================================================\n",
            "Mean Accuracy: 0.5996  0.0121\n",
            "Fold Accuracies: ['0.5773', '0.6103', '0.6103', '0.6000', '0.6000']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.51      0.48      0.50       200\n",
            "     Disgust       0.53      0.48      0.51       210\n",
            "     Fearful       0.65      0.68      0.67       216\n",
            "       Happy       0.60      0.65      0.62       216\n",
            "     Neutral       0.81      0.82      0.81       195\n",
            "         Sad       0.59      0.69      0.64       202\n",
            "    Surprise       0.47      0.41      0.44       212\n",
            "\n",
            "    accuracy                           0.60      1451\n",
            "   macro avg       0.60      0.60      0.60      1451\n",
            "weighted avg       0.59      0.60      0.60      1451\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Optuna Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "w75fEd_aYHLe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
        "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
        "  hidden_dim = trial.suggest_categorical('hidden_dim', [256, 512, 768])\n",
        "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
        "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n",
        "\n",
        "\n",
        "  skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
        "  fold_results = []\n",
        "  all_fold_preds = []\n",
        "  all_fold_trues = []\n",
        "\n",
        "  for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "      print(f\"\\n{'='*50}\")\n",
        "      print(f\"FOLD {fold+1}/{N_SPLITS}\")\n",
        "      print('='*50)\n",
        "\n",
        "      X_tr, X_val = X[tr_idx], X[val_idx]\n",
        "      y_tr, y_val = y[tr_idx], y[val_idx]\n",
        "\n",
        "      mi_scores = mutual_info_classif(X_tr, y_tr, random_state=RANDOM_SEED)\n",
        "      n_select = min(150, len(mi_scores))\n",
        "      top_features = np.argsort(mi_scores)[-n_select:]\n",
        "\n",
        "      X_tr = X_tr[:, top_features]\n",
        "      X_val = X_val[:, top_features]\n",
        "\n",
        "\n",
        "      pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "      X_tr = pt.fit_transform(X_tr)\n",
        "      X_val = pt.transform(X_val)\n",
        "\n",
        "\n",
        "      train_ds = TabularDataset(X_tr, y_tr, augment=True)\n",
        "      val_ds = TabularDataset(X_val, y_val, augment=False)\n",
        "\n",
        "\n",
        "      vals, counts = np.unique(y_tr, return_counts=True)\n",
        "      inv_freq = 1.0 / (counts + 1e-12)\n",
        "      weight_vec = np.zeros(len(class_names), dtype=np.float32)\n",
        "      for cls_i, inv in zip(vals, inv_freq):\n",
        "          weight_vec[cls_i] = inv\n",
        "\n",
        "\n",
        "      sample_weights = np.array([weight_vec[yv] for yv in y_tr], dtype=np.float32)\n",
        "      sample_weights = sample_weights / sample_weights.sum()\n",
        "      sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights),\n",
        "                                    replacement=True)\n",
        "\n",
        "      tr_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0)\n",
        "      val_loader = DataLoader(val_ds, batch_size=256, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "      model = ImprovedMLP(in_dim=X_tr.shape[1], n_classes=len(class_names), dropout=0.3).to(DEVICE)\n",
        "\n",
        "\n",
        "      weight_tensor = torch.tensor(weight_vec, dtype=torch.float32).to(DEVICE)\n",
        "      criterion = nn.CrossEntropyLoss(weight=weight_tensor, label_smoothing=0.1)\n",
        "\n",
        "\n",
        "      optimizer = optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-4)\n",
        "      scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2)\n",
        "\n",
        "\n",
        "      best_val_acc = 0.0\n",
        "      epochs_no_improve = 0\n",
        "\n",
        "      for epoch in range(EPOCHS):\n",
        "          model.train()\n",
        "          total_loss = 0.0\n",
        "\n",
        "          for xb, yb in tr_loader:\n",
        "              xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "\n",
        "              xb_m, ya, yb_mix, _, lam = mixup_data(xb, yb, alpha=0.2)\n",
        "              preds = model(xb_m)\n",
        "\n",
        "              if lam is None:\n",
        "                  loss = criterion(preds, yb)\n",
        "              else:\n",
        "                  loss = mixup_criterion(criterion, preds, ya, yb_mix, lam)\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "          scheduler.step()\n",
        "\n",
        "          avg_loss = total_loss / len(tr_loader.dataset)\n",
        "          val_acc, val_preds, val_trues, _ = eval_model(model, val_loader, DEVICE)\n",
        "\n",
        "  return val_acc\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "print(\"Best hyperparameters:\", study.best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_TL-htmY4EV",
        "outputId": "0b3b60b8-076a-4098-f556-e12b66f03419"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 20:28:52,528] A new study created in memory with name: no-name-ef683e1f-03af-415c-a9bc-d6ac9c6a74a1\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 20:34:19,816] Trial 0 finished with value: 0.5392857142857143 and parameters: {'lr': 0.0001093583852398236, 'dropout': 0.385159699102071, 'hidden_dim': 768, 'weight_decay': 2.2432619820019648e-05, 'label_smoothing': 0.14958264459838616}. Best is trial 0 with value: 0.5392857142857143.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 20:39:32,813] Trial 1 finished with value: 0.5535714285714286 and parameters: {'lr': 0.0005232815691718069, 'dropout': 0.4202305368045831, 'hidden_dim': 512, 'weight_decay': 8.39422649077822e-06, 'label_smoothing': 0.18477074444245822}. Best is trial 1 with value: 0.5535714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 20:44:46,649] Trial 2 finished with value: 0.5428571428571428 and parameters: {'lr': 0.004265753268941966, 'dropout': 0.37340945571891204, 'hidden_dim': 512, 'weight_decay': 2.064626705221874e-05, 'label_smoothing': 0.13851751432712958}. Best is trial 1 with value: 0.5535714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 20:49:58,888] Trial 3 finished with value: 0.5392857142857143 and parameters: {'lr': 0.00023062024232513577, 'dropout': 0.42546276832288005, 'hidden_dim': 512, 'weight_decay': 1.042295176513955e-06, 'label_smoothing': 0.09713258738919145}. Best is trial 1 with value: 0.5535714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 20:55:14,910] Trial 4 finished with value: 0.5392857142857143 and parameters: {'lr': 0.0012867162444341058, 'dropout': 0.47207398879196477, 'hidden_dim': 256, 'weight_decay': 1.3889805078079793e-05, 'label_smoothing': 0.0820216521895075}. Best is trial 1 with value: 0.5535714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:00:32,328] Trial 5 finished with value: 0.5464285714285714 and parameters: {'lr': 0.0006420663291381136, 'dropout': 0.30741452566371175, 'hidden_dim': 256, 'weight_decay': 3.7079045143568945e-05, 'label_smoothing': 0.05863376386291727}. Best is trial 1 with value: 0.5535714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:05:44,884] Trial 6 finished with value: 0.5357142857142857 and parameters: {'lr': 0.0018892350798535315, 'dropout': 0.3112228671788869, 'hidden_dim': 768, 'weight_decay': 3.332174453907458e-06, 'label_smoothing': 0.08442981697813447}. Best is trial 1 with value: 0.5535714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:10:55,836] Trial 7 finished with value: 0.5607142857142857 and parameters: {'lr': 0.0006577990694131069, 'dropout': 0.2945145346451839, 'hidden_dim': 768, 'weight_decay': 0.00010393199742017537, 'label_smoothing': 0.11754544840807471}. Best is trial 7 with value: 0.5607142857142857.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:16:09,328] Trial 8 finished with value: 0.5642857142857143 and parameters: {'lr': 0.00011418267914050485, 'dropout': 0.4939489590741553, 'hidden_dim': 256, 'weight_decay': 1.26711415909089e-05, 'label_smoothing': 0.17343859897233532}. Best is trial 8 with value: 0.5642857142857143.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:21:23,115] Trial 9 finished with value: 0.5607142857142857 and parameters: {'lr': 0.0008451870660211066, 'dropout': 0.4711368185677354, 'hidden_dim': 256, 'weight_decay': 1.600003509747021e-06, 'label_smoothing': 0.11129252164304326}. Best is trial 8 with value: 0.5642857142857143.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:26:33,059] Trial 10 finished with value: 0.55 and parameters: {'lr': 0.00010054680814428207, 'dropout': 0.23380095206832419, 'hidden_dim': 256, 'weight_decay': 0.000992763132540997, 'label_smoothing': 0.1894365640941635}. Best is trial 8 with value: 0.5642857142857143.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:31:44,299] Trial 11 finished with value: 0.5535714285714286 and parameters: {'lr': 0.008945891282467736, 'dropout': 0.23449842384756675, 'hidden_dim': 768, 'weight_decay': 0.00015430637345283148, 'label_smoothing': 0.16048634936838777}. Best is trial 8 with value: 0.5642857142857143.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:36:54,547] Trial 12 finished with value: 0.5142857142857142 and parameters: {'lr': 0.00027865182820454345, 'dropout': 0.3203914569797567, 'hidden_dim': 768, 'weight_decay': 0.0001333417520889863, 'label_smoothing': 0.12494964597556744}. Best is trial 8 with value: 0.5642857142857143.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:42:05,146] Trial 13 finished with value: 0.5571428571428572 and parameters: {'lr': 0.00028753903922410136, 'dropout': 0.27649881236356155, 'hidden_dim': 256, 'weight_decay': 0.0001197958187733221, 'label_smoothing': 0.1710580299591504}. Best is trial 8 with value: 0.5642857142857143.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:47:14,956] Trial 14 finished with value: 0.5571428571428572 and parameters: {'lr': 0.0020825263543983695, 'dropout': 0.20358042925985909, 'hidden_dim': 768, 'weight_decay': 0.0005247270575477257, 'label_smoothing': 0.12857532487131104}. Best is trial 8 with value: 0.5642857142857143.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:52:25,124] Trial 15 finished with value: 0.5535714285714286 and parameters: {'lr': 0.0001837594817807152, 'dropout': 0.34985869348208165, 'hidden_dim': 256, 'weight_decay': 6.144307478991405e-05, 'label_smoothing': 0.1986766471315913}. Best is trial 8 with value: 0.5642857142857143.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 21:57:35,532] Trial 16 finished with value: 0.5607142857142857 and parameters: {'lr': 0.0005464383051655719, 'dropout': 0.27175000603576605, 'hidden_dim': 768, 'weight_decay': 5.322538755813762e-06, 'label_smoothing': 0.11005947402939151}. Best is trial 8 with value: 0.5642857142857143.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:02:47,615] Trial 17 finished with value: 0.5678571428571428 and parameters: {'lr': 0.004100951289077328, 'dropout': 0.41492096262481415, 'hidden_dim': 768, 'weight_decay': 5.411401243128219e-05, 'label_smoothing': 0.16752225784564118}. Best is trial 17 with value: 0.5678571428571428.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:07:57,159] Trial 18 finished with value: 0.5321428571428571 and parameters: {'lr': 0.00447614767170728, 'dropout': 0.4980008760591982, 'hidden_dim': 256, 'weight_decay': 0.00026948845221612166, 'label_smoothing': 0.16685482792154102}. Best is trial 17 with value: 0.5678571428571428.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:13:06,654] Trial 19 finished with value: 0.5464285714285714 and parameters: {'lr': 0.009946086467946424, 'dropout': 0.4311840488178034, 'hidden_dim': 512, 'weight_decay': 4.6454306768451244e-05, 'label_smoothing': 0.14701559746602386}. Best is trial 17 with value: 0.5678571428571428.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:18:14,421] Trial 20 finished with value: 0.525 and parameters: {'lr': 0.004328461312052517, 'dropout': 0.45446255836347393, 'hidden_dim': 768, 'weight_decay': 1.0999216368360756e-05, 'label_smoothing': 0.17778469791312934}. Best is trial 17 with value: 0.5678571428571428.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:23:22,919] Trial 21 finished with value: 0.5571428571428572 and parameters: {'lr': 0.0021487254425659563, 'dropout': 0.3998859390342003, 'hidden_dim': 768, 'weight_decay': 8.137466276562765e-05, 'label_smoothing': 0.15647053877472133}. Best is trial 17 with value: 0.5678571428571428.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:28:32,481] Trial 22 finished with value: 0.5392857142857143 and parameters: {'lr': 0.00039319326575123267, 'dropout': 0.35932956476811156, 'hidden_dim': 768, 'weight_decay': 0.0003108947018379466, 'label_smoothing': 0.13123831595410704}. Best is trial 17 with value: 0.5678571428571428.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:33:42,863] Trial 23 finished with value: 0.5428571428571428 and parameters: {'lr': 0.0012142210578506268, 'dropout': 0.4946956337891349, 'hidden_dim': 768, 'weight_decay': 2.3019581144503828e-05, 'label_smoothing': 0.10781997143726577}. Best is trial 17 with value: 0.5678571428571428.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:38:54,586] Trial 24 finished with value: 0.525 and parameters: {'lr': 0.0028348009268728156, 'dropout': 0.4448691825429091, 'hidden_dim': 768, 'weight_decay': 8.534736884894299e-05, 'label_smoothing': 0.197599695261229}. Best is trial 17 with value: 0.5678571428571428.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:44:08,098] Trial 25 finished with value: 0.5428571428571428 and parameters: {'lr': 0.00017184004307664645, 'dropout': 0.33317359548790304, 'hidden_dim': 256, 'weight_decay': 3.952832688863354e-05, 'label_smoothing': 0.18019638081393077}. Best is trial 17 with value: 0.5678571428571428.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:49:19,752] Trial 26 finished with value: 0.5535714285714286 and parameters: {'lr': 0.00038942831977589927, 'dropout': 0.2862879918880194, 'hidden_dim': 768, 'weight_decay': 5.6471851032164395e-06, 'label_smoothing': 0.14112983445354724}. Best is trial 17 with value: 0.5678571428571428.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:54:32,506] Trial 27 finished with value: 0.5464285714285714 and parameters: {'lr': 0.00760515603217199, 'dropout': 0.3938006902059144, 'hidden_dim': 768, 'weight_decay': 0.0001928066171752809, 'label_smoothing': 0.12152584513446028}. Best is trial 17 with value: 0.5678571428571428.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 22:59:44,910] Trial 28 finished with value: 0.5714285714285714 and parameters: {'lr': 0.000825859273529576, 'dropout': 0.4050472873430277, 'hidden_dim': 512, 'weight_decay': 5.878094091461419e-05, 'label_smoothing': 0.16927667685513773}. Best is trial 28 with value: 0.5714285714285714.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 23:04:57,477] Trial 29 finished with value: 0.5678571428571428 and parameters: {'lr': 0.00015973029628847804, 'dropout': 0.4052254736491052, 'hidden_dim': 512, 'weight_decay': 2.2233411960036785e-05, 'label_smoothing': 0.15488740921649535}. Best is trial 28 with value: 0.5714285714285714.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 23:10:12,555] Trial 30 finished with value: 0.5785714285714286 and parameters: {'lr': 0.006308297609579304, 'dropout': 0.40732238402293397, 'hidden_dim': 512, 'weight_decay': 2.217794034655606e-05, 'label_smoothing': 0.15558780521663396}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 23:15:24,553] Trial 31 finished with value: 0.5428571428571428 and parameters: {'lr': 0.005934237295007318, 'dropout': 0.40638507299637316, 'hidden_dim': 512, 'weight_decay': 2.2923658294052377e-05, 'label_smoothing': 0.15142776449200102}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 23:20:37,197] Trial 32 finished with value: 0.5214285714285715 and parameters: {'lr': 0.00311201567494257, 'dropout': 0.3761068406771266, 'hidden_dim': 512, 'weight_decay': 2.4390688928198386e-05, 'label_smoothing': 0.1617599242230668}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 23:25:46,454] Trial 33 finished with value: 0.5178571428571429 and parameters: {'lr': 0.005775077942042546, 'dropout': 0.41137232187394845, 'hidden_dim': 512, 'weight_decay': 5.558768382050031e-05, 'label_smoothing': 0.14095928899605922}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 23:30:57,379] Trial 34 finished with value: 0.55 and parameters: {'lr': 0.0015402283017336641, 'dropout': 0.3837694753794969, 'hidden_dim': 512, 'weight_decay': 3.108919390881099e-05, 'label_smoothing': 0.15445864632884324}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 23:36:08,818] Trial 35 finished with value: 0.5535714285714286 and parameters: {'lr': 0.0009445287750632312, 'dropout': 0.434186794893624, 'hidden_dim': 512, 'weight_decay': 1.61026068731456e-05, 'label_smoothing': 0.18924081701789244}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 23:41:17,894] Trial 36 finished with value: 0.5642857142857143 and parameters: {'lr': 0.003208811039779612, 'dropout': 0.36429006911414014, 'hidden_dim': 512, 'weight_decay': 8.19662988400168e-06, 'label_smoothing': 0.1668108165216953}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 23:46:28,937] Trial 37 finished with value: 0.5392857142857143 and parameters: {'lr': 0.006718018310198021, 'dropout': 0.41667629949003854, 'hidden_dim': 512, 'weight_decay': 6.57812012991821e-05, 'label_smoothing': 0.14731115238911507}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 23:51:40,575] Trial 38 finished with value: 0.55 and parameters: {'lr': 0.0025965537631062385, 'dropout': 0.3455352823874626, 'hidden_dim': 512, 'weight_decay': 3.6962057678307886e-05, 'label_smoothing': 0.18115577301782776}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-23 23:56:50,862] Trial 39 finished with value: 0.5607142857142857 and parameters: {'lr': 0.00013873813571610048, 'dropout': 0.4576728573032062, 'hidden_dim': 512, 'weight_decay': 1.5370555297454e-05, 'label_smoothing': 0.1330364056375588}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-24 00:01:58,459] Trial 40 finished with value: 0.5642857142857143 and parameters: {'lr': 0.003814907934352694, 'dropout': 0.38502835138116, 'hidden_dim': 512, 'weight_decay': 8.036769663694547e-06, 'label_smoothing': 0.16304579753615975}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-24 00:07:05,774] Trial 41 finished with value: 0.55 and parameters: {'lr': 0.00013384101918935642, 'dropout': 0.4720265713938949, 'hidden_dim': 512, 'weight_decay': 2.844525163334046e-05, 'label_smoothing': 0.17408902074348687}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-24 00:12:14,349] Trial 42 finished with value: 0.55 and parameters: {'lr': 0.00011487437354736943, 'dropout': 0.4253099443539326, 'hidden_dim': 512, 'weight_decay': 1.0738779500724513e-05, 'label_smoothing': 0.18754157283907566}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-24 00:17:24,580] Trial 43 finished with value: 0.5428571428571428 and parameters: {'lr': 0.00020451979189629126, 'dropout': 0.3957453868523761, 'hidden_dim': 256, 'weight_decay': 1.9548078307634387e-05, 'label_smoothing': 0.05117718680951194}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-24 00:22:36,436] Trial 44 finished with value: 0.5607142857142857 and parameters: {'lr': 0.00027489995548363486, 'dropout': 0.44383672955375264, 'hidden_dim': 512, 'weight_decay': 2.602503143527542e-06, 'label_smoothing': 0.17648951124357465}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-24 00:27:48,316] Trial 45 finished with value: 0.5607142857142857 and parameters: {'lr': 0.0007005267591042003, 'dropout': 0.3682389612740938, 'hidden_dim': 256, 'weight_decay': 5.464493627007753e-06, 'label_smoothing': 0.16928612927046005}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-24 00:33:00,969] Trial 46 finished with value: 0.5785714285714286 and parameters: {'lr': 0.00041691120365531294, 'dropout': 0.47620238140017, 'hidden_dim': 512, 'weight_decay': 1.2534012839834714e-05, 'label_smoothing': 0.15537298895937734}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-24 00:38:13,818] Trial 47 finished with value: 0.5464285714285714 and parameters: {'lr': 0.00047702569233662917, 'dropout': 0.4819598896333599, 'hidden_dim': 512, 'weight_decay': 4.687047364688525e-05, 'label_smoothing': 0.1572964891567379}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-24 00:43:25,737] Trial 48 finished with value: 0.5392857142857143 and parameters: {'lr': 0.0012964193610783992, 'dropout': 0.4596659772538818, 'hidden_dim': 512, 'weight_decay': 1.7160190234424095e-05, 'label_smoothing': 0.144323048625393}. Best is trial 30 with value: 0.5785714285714286.\n",
            "/tmp/ipython-input-1284571758.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "/tmp/ipython-input-1284571758.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
            "/tmp/ipython-input-1284571758.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "/tmp/ipython-input-1284571758.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  label_smoothing = trial.suggest_uniform('label_smoothing', 0.05, 0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "FOLD 1/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 2/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 3/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 4/5\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "FOLD 5/5\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-24 00:48:36,176] Trial 49 finished with value: 0.5392857142857143 and parameters: {'lr': 0.0007709889543562118, 'dropout': 0.41683767888776724, 'hidden_dim': 512, 'weight_decay': 7.926646685693908e-05, 'label_smoothing': 0.13485856190446063}. Best is trial 30 with value: 0.5785714285714286.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'lr': 0.006308297609579304, 'dropout': 0.40732238402293397, 'hidden_dim': 512, 'weight_decay': 2.217794034655606e-05, 'label_smoothing': 0.15558780521663396}\n"
          ]
        }
      ]
    }
  ]
}